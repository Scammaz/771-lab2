{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEdYemXy9dRO"
      },
      "source": [
        "# GTI771 - Apprentissage machine avancé\n",
        "## Département de génie logiciel et des technologies de l’information\n",
        "\n",
        "\n",
        "\n",
        "## Laboratoire 7 - Réseaux de neurones convolutifs (CNN) - classification et régression\n",
        "#### <font color=black> Version 2 - Été 2024 </font>\n",
        "\n",
        "##### <font color=grey> Version 1 - Prof. Alessandro L. Koerich.\n",
        "##### Version 2 - Chargé de lab. Arthur Josi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8xD1CSZ9dRQ"
      },
      "source": [
        "| NOMS                  | CODE PERMANENT  |  PARTICIPATION     |\n",
        "|-----------------------|-----------------|--------------------|\n",
        "| Étudiant1             | Code1           |      0%            |\n",
        "| Étudiant2             | Code2           |      0%            |\n",
        "| Étudiant3             | Code3           |      0%            |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBQRmxE-9dRR"
      },
      "source": [
        "## Introduction\n",
        "Ce laboratoire porte sur l'apprentissage de la représentation (primitives) et du discriminant d'une façon intégrée avec des réseaux neuronaux convolutifs\n",
        "\n",
        "Vous devez proposer des architectures CNN aﬁn de résoudre deux problèmes: prédiction de l'âge de personnes à partir de photos du visage (régression - dataset FG-NET); prédiction des émotions à partir de photos du visage (classification - dataset FER), introduits dans le cadre des laboratoires précédents.\n",
        "\n",
        "L’évaluation de ce laboratoire sera basée sur:\n",
        "- la qualité des réseaux de neurones proposés et utilisés; (10%)\n",
        "- utilisation du protocole et mesures de performance appropriées; (10%)\n",
        "- les réponses aux questions dans ce notebook;(70%)\n",
        "- l'organisation de votre code source (SVP, n'oubliez pas de mettre des commentaires dans le code source!); (10%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSpjd1Bb9dRR"
      },
      "source": [
        "# Modules et bibliotèques python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a9O4Yr29dRS"
      },
      "source": [
        "### Import de bibliotèques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f09finWQ9dRS"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "1. Ajouter les bibliothèques que vous avez utilisées pour compléter ce notebook dans une cellule avec une petite description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "r_WQS-ca9dRS"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # package for scientific computing with Python.\n",
        "import matplotlib.pyplot as plt # 2D plotting library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PjoyMRI9dRT"
      },
      "source": [
        "### Définition des fonctions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRF51_Ku9dRT"
      },
      "outputs": [],
      "source": [
        "def fa():\n",
        "    return 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbMwQKvq9dRT"
      },
      "source": [
        "# Partie 1 - Apprentissage de représentation et régression avec FG-NET (40%)\n",
        "\n",
        "Point de départ: fichier *fg-net-nxm.csv* - images nettoyées et normalisées avec résolution $n$ $\\times$ $m$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eQSHWOC9dRT"
      },
      "source": [
        "## 1a: Données de FG-NET. (10%)\n",
        "\n",
        "###  <font color=blue> À faire: </font>\n",
        "1. Reprenez vos images FG-NET savaugardées dans un fichier *csv*. Vous devez lire ces images et les représenter sous la forme d’une matrice $X\\_data$ aussi que les vecteurs $Y\\_data$ avec les âges (étiquettes) et $Z\\_data$ avec les id des sujets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KrdAqCdL9dRU"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "content/fg-net-4x4-restNET50v2.csv not found.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#data = np.loadtxt('content/fg-net-128x104.csv', delimiter=',',dtype=str)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mloadtxt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent/fg-net-4x4-restNET50v2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m,dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform_str_float\u001b[39m(d):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mfromstring(row, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m d])\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/lib/npyio.py:1373\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1371\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1373\u001b[0m arr \u001b[38;5;241m=\u001b[39m _read(fname, dtype\u001b[38;5;241m=\u001b[39mdtype, comment\u001b[38;5;241m=\u001b[39mcomment, delimiter\u001b[38;5;241m=\u001b[39mdelimiter,\n\u001b[1;32m   1374\u001b[0m             converters\u001b[38;5;241m=\u001b[39mconverters, skiplines\u001b[38;5;241m=\u001b[39mskiprows, usecols\u001b[38;5;241m=\u001b[39musecols,\n\u001b[1;32m   1375\u001b[0m             unpack\u001b[38;5;241m=\u001b[39munpack, ndmin\u001b[38;5;241m=\u001b[39mndmin, encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   1376\u001b[0m             max_rows\u001b[38;5;241m=\u001b[39mmax_rows, quote\u001b[38;5;241m=\u001b[39mquotechar)\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/lib/npyio.py:992\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m    990\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fname)\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 992\u001b[0m     fh \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39m_datasource\u001b[38;5;241m.\u001b[39mopen(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrt\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mencoding)\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    994\u001b[0m         encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fh, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/lib/_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\u001b[38;5;241m.\u001b[39mopen(path, mode, encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/lib/_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    531\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: content/fg-net-4x4-restNET50v2.csv not found."
          ]
        }
      ],
      "source": [
        "#data = np.loadtxt('content/fg-net-128x104.csv', delimiter=',',dtype=str)\n",
        "data = np.loadtxt('content/fg-net-4x4-restNET50v2.csv', delimiter=',',dtype=str)\n",
        "\n",
        "def transform_str_float(d):\n",
        "    return np.array([np.fromstring(row, sep=' ', dtype=float) for row in d])\n",
        "\n",
        "x_data = transform_str_float(data[1:,2])\n",
        "y_data = np.array(data[1:,1], dtype=int)\n",
        "z_data = np.array(data[1:,0], dtype=int)\n",
        "\n",
        "print(f\"fg-net:\\t{x_data.shape[1]} features\")\n",
        "\n",
        "\n",
        "\n",
        "pca = PCA(n_components=1000)\n",
        "x_data_pca = pca.fit_transform(x_data)\n",
        "\n",
        "print(f\"pca:\\t{x_data_pca.shape[1]} features\")\n",
        "\n",
        "print(f\"fg-net:\\t{x_data_pca.shape[0]} samples\")\n",
        "\n",
        "\n",
        "\n",
        "X_data = x_data\n",
        "\n",
        "##Print shape of X_data\n",
        "print(X_data.shape)\n",
        "X_data = np.reshape(X_data, (X_data.shape[0], 4, 4, 1024))\n",
        "print(X_data.shape) \n",
        "\n",
        "##Print shape of y_data\n",
        "print(y_data.shape)\n",
        "\n",
        "##Print shape of z_data\n",
        "print(z_data.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxSOYyoH_JQ6"
      },
      "source": [
        "  2.  **Explications:**\n",
        "\n",
        "Définition du protocole expérimental avec FG-NET.\n",
        "\n",
        "Idéalement, vous devez utiliser le protocole <font color=blue> \"Leave One Subject Out Cross-Validation\" </font> (LOSO).\n",
        "\n",
        "Cependant, en raison des longs temps d'apprentissage des CNNs, un tel protocole expérimental n'est pas réalisable. Par conséquent, vous êtes invité à établir un protocole \"hold-out\" pour l'ensemble de données FG-NET.\n",
        "\n",
        "Je vous suggère une répartition 50% - 20% - 30% entraînement-validation-test. Cependant, vous devez faire cette répartition \"par sujet\" pour vous assurer que les visages d'un même sujet ne sont présents que sur une seule partition.\n",
        "\n",
        "Par exemple, en supposant 10 sujets avec 20 visages chacun. Vous aurez un ensemble d’entraînement avec 5 sujets (sujets A, B, C, D, E - 100 images de visage), un ensemble de validation avec 2 sujets (sujets F, G - 40 images de visage) et un ensemble de tests avec 3 sujets (sujets H, I, J - 60 images de visage).\n",
        "\n",
        "  **A faire:** Créer trois partitions de données à partir des images de FG-NET:\n",
        "    - Ensemble d'entraînement - *D_train* (50% x 82) = 41 sujets\n",
        "    - Ensemble de validation - *D_valid* (20% x 82) = 17 sujets\n",
        "    - Ensemble de tests - *D_test* (30% x 82) = 24 sujets <br><br>\n",
        "    \n",
        "    Ici, vous devez aussi faire attention pour ne changer pas la distribution d'âges dans les partitions de données (stratified sampling)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qob0pDAeAQq0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt7wxtSa_xeY"
      },
      "source": [
        "3. Générez un fichier *fg-net-nxm-split.csv* avec les données nettoyées et normalisées, où $n$ et $m$ représentent la résolution finale des images. En fait, vous devez prendre le fichier *fg-net-nxm.csv* et ajouter, l'usage de chaque image (similaire à FER2013)\n",
        "   - Format du fichier: subject,age,pixels,use\n",
        "      * sujet: integer\n",
        "      * âge: integer\n",
        "      * pixels: integer [0, 255]\n",
        "      * use: nominal [training, validation, test]<br><br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpHvdELj_Xbz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgtbiC2t9dRU"
      },
      "source": [
        "## 1b: Architecture CNN Régression FG-NET. (20%)\n",
        "Point de départ: fichier *fg-net-nxm.csv* or *D_train*, *D_val*, *D_test*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGMTsJFI9dRV"
      },
      "source": [
        "1. Générer des partitions de données pour entraîner le CNN:\n",
        "    - Ensemble d'entraînement: *X_train* et *y_train*\n",
        "    - Ensemble de validation : *X_valid* et *y_val*\n",
        "    - Ensemble de test       : *X_test* et  *y_test* <br><br>\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbU9MMr0AFdM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdgtzbJW9dRV"
      },
      "source": [
        "2. Utiliser Pytorch ou [Tensorflow et Keras](https://www.tensorflow.org/tutorials/keras/regression) pour construire un réseau de neurones convolutifs pour extraire les primitives et faire la regression (end-to-end learning); Proposer une architecture appropriée pour FG-NET : nombre de couches convolutifs (CLs), nombre et dimension des filtres de chaque couche (kernel size), pas (stride), nombre et dimension des couches entièrement connectées (FC), fonctions d'activation de chaque couche, couches supplémentaires comme normalisation de batch, dropout, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c23pnc4BCSt0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybrBi6huCS8C"
      },
      "source": [
        "3. Entraîner et optimiser les paramètres du réseau (modèle 1).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIJcrUCkCpup"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fF3TpusCqRC"
      },
      "source": [
        "5. Entraîner un autre modèle avec \"data augmentation\" pour améliorer la généralisation (modèle 2).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RT88J1zCs_Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO0EMN6-CuFo"
      },
      "source": [
        "6. Faire une brève analyse des résultats et présenter vos considérations et conclusions sur les réseaux de neurones de convolution. Comparer avec les résultats obtenus avec les CNNs avec ceux obtenus dans les laboratoires précédents concernant des modèles de régression (TPs 5 et 6).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lOJaq0zCwOC"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2vOC5-FC12S"
      },
      "source": [
        "| Algorithme            | Paramètres    |  MSE  |  MAE  | ????? |\n",
        "|-----------------------|---------------|-------|-------|-------|\n",
        "| Regr lineaire         | XXX.XX        |XXX.XX |XXX.XX |       |\n",
        "| Regr Ridge            | alpha = 0.1   |123.34 | 10.45 |       |\n",
        "| Regr Lasso            | XXX.XX        |XXX.XX |XXX.XX |       |\n",
        "| Regr ElasticNet       | XXX.XX        |XXX.XX |XXX.XX |       |\n",
        "| MLP 1                 | 512:100:100:1 |XXX.XX |XXX.XX |       |\n",
        "| MLP 2                 | 512:50:1      |XXX.XX |XXX.XX |       |\n",
        "| CNN 1                 | 512:100:100:1 |XXX.XX |XXX.XX |       |\n",
        "| CNN 2 (DA)            | 512:50:1      |XXX.XX |XXX.XX |       |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50IKjUjA9dRW",
        "tags": []
      },
      "source": [
        "## 1c: Fine-tuning d'un CNN pré-entraîné pour FG-NET. (10%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRFasYUO9dRW"
      },
      "source": [
        "1. Récupérer une architecture CNN pré-entraînée disponible dans Pytorch ou Keras pour faire un “transfert de connaissance (transfer learning). Faire un \"fine-tuning\" du modèle choisi sur FG-NET puis expliquer les modifications/adaptations apportées au modèle pré-entraîné (p. ex., description de couches ajoutées ou enlevées pour faire fonctionner le modèle sur vos données)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwSY82L0B1zj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XapvDsbB2Hp"
      },
      "source": [
        "2. Faire une brève analyse des résultats et présenter vos considérations et conclusions sur les réseaux de neurones de convolution. Comparer avec les résultats obtenus avec les CNNs avec ceux obtenus dans les laboratoires précédents concernant des modèles de régression (TPs 5 et 6).\n",
        "\n",
        "| Algorithme            | Paramètres    |  MSE  |  MAE  | ????? |\n",
        "|-----------------------|---------------|-------|-------|-------|\n",
        "| Regr lineaire         | XXX.XX        |XXX.XX |XXX.XX |       |\n",
        "| Regr Ridge            | alpha = 0.1   |123.34 | 10.45 |       |\n",
        "| Regr Lasso            | XXX.XX        |XXX.XX |XXX.XX |       |\n",
        "| Regr ElasticNet       | XXX.XX        |XXX.XX |XXX.XX |       |\n",
        "| MLP 1                 | 512:100:100:1 |XXX.XX |XXX.XX |       |\n",
        "| MLP 2                 | 512:50:1      |XXX.XX |XXX.XX |       |\n",
        "| CNN 1                 | 512:100:100:1 |XXX.XX |XXX.XX |       |\n",
        "| CNN 2 (DA)            | 512:50:1      |XXX.XX |XXX.XX |       |\n",
        "| VGG16 (DA)            | 512:50:1      |XXX.XX |XXX.XX |       |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6xoHujB9dRW"
      },
      "source": [
        "Votre description ici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEjkIFpQ9dRW"
      },
      "source": [
        "# Partie 2 - Apprentissage de représentation et classification avec FER (30%)\n",
        "\n",
        "Point de départ: fichier *fer2013-clean-pre.csv* - images nettoyées et normalisées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg34NTvD9dRW"
      },
      "source": [
        "## 2: Architecture CNN Classification FER2013 (30%)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAfUdA7H9dRX"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "1. Reprenez votre ensemble de données nettoyé et repérez les trois partitions de données: apprentissage, validation et test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "261GRHPP9dRX",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "ferData = np.loadtxt( 'fer2013-clean-pre.csv', delimiter=',', dtype=str )\n",
        "\n",
        "# Images d'entraînement\n",
        "Xtrain = <à compléter>\n",
        "ytrain = <à compléter>\n",
        "\n",
        "# Images de validation\n",
        "Xval = <à compléter>\n",
        "yval = <à compléter>\n",
        "\n",
        "# Images de test\n",
        "Xtest = <à compléter>\n",
        "ytest = <à compléter>\n",
        "\n",
        "print(Xtrain.shape, Xval.shape, Xtest.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YCM3r9X9dRX"
      },
      "source": [
        "2. Utiliser Pytorch ou [Tensorflow et Keras](https://www.tensorflow.org/tutorials/keras/classification) pour construire un réseau de neurones convolutif (classe) qui vous servira par la suite à apprendre une représentation des images de visage (primitives) et faire la classification (end-to-end learning). Vous pouvez reprendre l'architecture de la partie 1 avec quelques adaptations pour qu'il fonctionne sur ce problème.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5LrneqwEcoa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeYxmf8UEdvB"
      },
      "source": [
        "2. Entraîner et optimiser les paramètres du réseau (modèle 1).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_U16QFUVEl7Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCfSsek5EmS2"
      },
      "source": [
        "3. Entraîner un autre modèle avec \"data augmentation\" pour améliorer la généralisation (modèle 2).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bklovNWEop3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5x1lCXHEoUf"
      },
      "source": [
        "4. Prenez le modèle le plus performant pour faire la prédiction sur tous les exemples (apprentissage, validation, test) et rapporter les résultats (comme fait dans les TP1 à TP4 et TP6):<br>\n",
        "   3a. Rapport de classification produit avec *<font color=green>from sklearn.metrics import classification_report</font>*<br>\n",
        "   3b. taux de classification correct sur les trois (3) ensembles de données (sous la forme d'un tableau)<br>\n",
        "   3c. matrice de confusion produite avec *<font color=green> from sklearn.metrics import confusion_matrix</font>* pour les résultats sur l'ensemble de tests (matrice 7 $\\times$ 7 - étiquettes $\\times$ prédictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dP4ZnD_iE0p7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k67_TrJhE0b0"
      },
      "source": [
        "\n",
        "5. Comparez les résultats avec ceux attendus avec le réseau MLP (TP6), les primitives « deep » réduits (TP4), les primitives « deep » (TP3), les primitives globales/locales (TP2) et *template matching* (TP1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xP3GzfW2E5IU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5oG7p4n9dRY"
      },
      "source": [
        "6. Faire une brève analyse des résultats et présenter vos considérations et conclusions sur la pertinence / advantages / désavantages des réseaux neuronaux."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsMw_LT6FKv_"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
