{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHB37PXtdCsO"
      },
      "source": [
        "# GTI771 - Apprentissage machine avancé\n",
        "## Département de génie logiciel et des technologies de l’information\n",
        "\n",
        "\n",
        "\n",
        "## Laboratoire 4 - Réduction de la dimensionnalité de primitives « deep »\n",
        "#### <font color=black> Version 2 - Été 2024 </font>\n",
        "\n",
        "##### <font color=grey> Version 1 - Prof. Alessandro L. Koerich.\n",
        "##### Version 2 - Chargé de lab. Arthur Josi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71maNQzQdCsO"
      },
      "source": [
        "| NOMS                  | CODE PERMANENT                                   |\n",
        "|-----------------------|--------------------------------------------------|\n",
        "| Hugo Rhéaume-Simard   | RHEH93080004                                     |\n",
        "| Laurent Marleau-Gallant             |  MARL05109800                                            |\n",
        "| Yulia Bakaleinik             | BAKY30539705                                            |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzAi_SgZdCsP"
      },
      "source": [
        "## Introduction\n",
        "Les primitives générées par les CNNs peuvent avoir une haute dimensionnalité, des éléments nuls, ainsi que des redondances. En fonction du type sortie choisie (global pooling, flattening, etc.), la dimensionnalité  des vecteurs de primitives en sortie d'un CNNs peut facilement atteindre plusieurs milliers.\n",
        "\n",
        "Dans ce laboratoire, nous allons explorer les algorithmes de réduction de la dimensionnalité sur les vecteurs de primitives générés par des CNNs préentraînés réutilisés comme extracteurs de primitives dans le Laboratoire 3. Pour ce faire, nous allons réduire la dimensionnalité des vecteurs « deep » et réentraîner les arbres de décision du Laboratoire 3.\n",
        "\n",
        "L’évaluation de ce laboratoire sera basée sur:\n",
        "- l'utilisation correcte des algorithmes;\n",
        "- les réponses aux questions de ce notebook;\n",
        "- l'organisation de votre code source (SVP, n'oubliez pas de mettre des commentaires dans le code source!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJp3tcSIdCsP"
      },
      "source": [
        "# Modules et bibliotèques python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czNnYBOadCsP"
      },
      "source": [
        "### Import de bibliotèques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xh6MsNddCsP"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "1. Ajouter les bibliothèques que vous avez utilisées pour compléter ce notebook dans une cellule avec une petite description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UXTuHcMedCsP"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # package for scientific computing with Python.\n",
        "import matplotlib.pyplot as plt # 2D plotting library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgxF95vCdCsP"
      },
      "source": [
        "### Définition des fonctions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hSmIyOcndCsP"
      },
      "outputs": [],
      "source": [
        "def fa():\n",
        "    return 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKMLXH6jdCsQ"
      },
      "source": [
        "# Partie 1 - Ensemble de données\n",
        "\n",
        "Point de départ: *fer2013-clean-deep.csv* ou *fer2013-clean-pre-deep.csv*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqJg3JkGdCsQ"
      },
      "source": [
        "## 1a: Charger le fichier de primitives « deep » du laboratoire 3.\n",
        "\n",
        "###  <font color=blue> À faire: </font>\n",
        "1. Reprenez votre ensemble de données nettoyé et composé des vecteurs de primitives obtenus dans le laboratoire 3 via la meilleure approche parmis les deux evaluées. Repérez les trois partitions de données: apprentissage, validation et test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8lf75fHAdCsQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28657, 2304) (3582, 2304) (3580, 2304)\n"
          ]
        }
      ],
      "source": [
        "# Load data - Au choix:\n",
        "\n",
        "# ferData = np.loadtxt( 'fer2013-clean.csv', delimiter=',', dtype=str )\n",
        "ferData = np.loadtxt( 'content/fer2013-clean-pre.csv', delimiter=',', dtype=str )\n",
        "\n",
        "training_data = ferData[ferData[:, 2] == 'Training']\n",
        "validation_data = ferData[ferData[:, 2] == 'PublicTest']\n",
        "test_data = ferData[ferData[:, 2] == 'PrivateTest']\n",
        "\n",
        "def transform_str_float(d):\n",
        "    return np.array([np.fromstring(row, sep=' ', dtype=float) for row in d])\n",
        "\n",
        "# Training set\n",
        "Xtrain = transform_str_float(training_data[:, 1])\n",
        "ytrain = np.array(training_data[:,0], dtype=np.float32)\n",
        "\n",
        "# Validation set\n",
        "Xval = transform_str_float(validation_data[:, 1])\n",
        "yval = np.array(validation_data[:,0], dtype=np.float32)\n",
        "\n",
        "# # Test set\n",
        "Xtest = transform_str_float(test_data[:, 1])\n",
        "ytest = np.array(test_data[:,0], dtype=np.float32)\n",
        "\n",
        "print(Xtrain.shape, Xval.shape, Xtest.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  Ici on voudrait recevoir les images du fichier CSV des modeles deep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fuhXWd1dCsQ"
      },
      "source": [
        "# Partie 2: Réduction de la dimensionnalité\n",
        "\n",
        "Bibliothèques Python pour la reduction de la dimensionnalité :\n",
        "\n",
        "* [Transformation algorithms](https://scikit-learn.org/stable/modules/decomposition.html#decompositions)\n",
        "* [Feature selection algorithms](https://scikit-learn.org/stable/modules/feature_selection.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc-j5JIUdCsQ"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "1. Choisir un algorithme de `transformation` de primitives et un algorithme de `sélection` des primitives pour réduire la dimensionnalité de vos vecteurs de primitives « deep » pour lesquels vous avez obtenus les meilleurs résultats au laboratoire précédent.\n",
        "2. Expliquer brièvement les algorithmes et surtout les hyperparamètres qui influencent la réduction de la dimensionnalité, et préciser la dimensionalité attendue des vecteurs de primitives réduits.\n",
        "3. Utiliser [T-SNE](https://learnopencv.com/t-sne-for-feature-visualization/) ou [UMAP](https://umap-learn.readthedocs.io/en/latest/plotting.html) comme outils de visualisation des vecteurs de primitives de la base de test (pour des fins de comparaison).\n",
        "4. Générer vos vecteurs « deep » réduits avec ces algorithmes pour l'ensemble de données FER (apprentissage, validation et test).\n",
        "5. Utiliser le même outil de visualisation que pour la question 3 sur les vecteurs \"deep\" réduits puis commenter.\n",
        "6. Sauvegardez vos vecteurs réduits sous la forme d'un fichier 'csv' (p. ex. *fer2013-clean-deepVGG19-chi2.csv* ou *fer2013-clean-pre-deepVGG19-chi2.csv*). Vous n'êtes pas obligé d'utiliser la même structure du fichier original *fer2013.csv*, mais vous devez garder la correspondance (ligne du fichier original et du vecteur de primitives). Vous devez nommer vos fichiers de primitive « deep » réduits en référence au CNN utilisé et à l'algorithme de réduction de la dimensionnalité utilisé, p. ex., *fer2013-clean-deepVGG19-chi2.csv* pour un vecteur CNN VGG19 réduit avec chi2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEEGxZVAdCsQ"
      },
      "source": [
        "#### Résultats et réponses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpmvH-tVdCsQ"
      },
      "source": [
        "Vos réponses et résultats ici:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNS2orp4dCsQ"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lByY5dgTdCsQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Votre code ici\n",
        "\n",
        "## 1. Utiliser PCA pour la transformation des données \n",
        "    # Utiliser un SVD_solver = 'randomized' pour la PCA\n",
        "\n",
        "\n",
        "## 2. Utiliser un algo de selection de modèle pour trouver le meilleur modèle\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Utiliser TSNE pour visualiser les données en 2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejBcg0hUdCsQ"
      },
      "source": [
        "# Partie 3: Entraînement de modèles d'apprentissage machine\n",
        "\n",
        "Vous êtes maintenant prêtes à entraîner / comparer différents modèles permettant la classification à partir des vecteurs de primitives « deep » réduits obtenus en partie 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDui23cRdCsQ"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "1.\n",
        "  a) Comme pour les précédents laboratoires (2 et 3), entraîner et evaluer un [arbre de décision](https://scikit-learn.org/stable/modules/tree.html#tree-classification) de la bibliothèque `scikit-learn` en utilisant les vecteurs de primitives deep réduits via PCA. Utiliser un *grid search* avec deux hyperparamètres pour trouver les meilleures valeurs de ceux-ci.\n",
        "\n",
        "  b) Évaluer  la performance de votre modèle sur les trois sets de données en affichant les taux de classification (dans le tableau en bas du notebook) et afficher entre autre la matrice de confusion sur la base de test.\n",
        "\n",
        "2.\n",
        "  a) Entrainer et évaluer de la même façon le modèle [quadratic discriminant analysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html)  (non linéaire). On utilisera un grid search avec les paramètres suivants:\n",
        "```\n",
        "param_grid = {\n",
        "    'reg_param': [0.0, 0.01, 0.1, 1.0],\n",
        "    'tol': [1e-5, 1e-4, 1e-3, 1e-2]\n",
        "}\n",
        "```\n",
        "  b) Commenter\n",
        "\n",
        "3.\n",
        "  a) Choisir, entraîner et évaluer un modèle linéaire tel que [Logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) ou une des variante de l'algorithme [naive bayes](https://scikit-learn.org/stable/modules/naive_bayes.html) sur les vecteurs de primitives réduits, ou bien (**au choix**) entraîner et évaluer l'algorithme [Linear Discriminant Analysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html) sur les vecteurs non réduits obtenus   \n",
        "\n",
        "  b) Commenter\n",
        "\n",
        "4.\n",
        "  a) Entraîner un modèles de classification [K-Nearest-Neighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) (modèle non paramétrique) en faisant un grid_search sur deux hyperparamètres du modèle puis évaluer celui-ci.\n",
        "\n",
        "  b) Commenter.\n",
        "\n",
        "5. Comparez les différents résultats obtenus via les différents modèles utilisés en présentant vos considérations et conclusions sur les points suivants:\n",
        "\n",
        "  a) La pertinence / avantages / désavantages d’utiliser la réduction de la dimensionnalité\n",
        "\n",
        "  b) Impact sur la performances de l'arbre de décision entraîné dans ce lab par rapport à celui entraîné dans le lab précédent.\n",
        "\n",
        "  c) Comment interprétez-vous les résultats de votre modèle le plus performant entre les différents modèles de classifications utilisés?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_u8jsGHMiBZ"
      },
      "source": [
        "Question bonus: Utiliser la [décomposition du biais et de la variance](https://rasbt.github.io/mlxtend/user_guide/evaluate/bias_variance_decomp/) sur les modèles entraînés afin de mieux comprendre les modèles utilisés, le biais et la variance étant corrélés aux phénomènes de sous-entraînement et de sur-entraînement. On parle souvent du compromis biais-variance (\"bias-variance tradeoff\") lorsque l'on entraîne un modèle de classification (ou de regression), car on cherchera à trouver un juste equilibre entre le biais et la variance afin d'optimiser les performances.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53oIh5eUdCsQ"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqnMishjdCsQ"
      },
      "outputs": [],
      "source": [
        "# Votre code ici\n",
        "\n",
        "#1 Entrainement avec decision tree\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#2 Entrainement avec QDA\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#3 Entrainement avec LDA\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#4 Entrainement avec KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el9n18p2dCsQ"
      },
      "source": [
        "#### Vos résultats ici:\n",
        "\n",
        "Taux de bonnes classification (%) - Ajuster les titres selon vos modèles\n",
        "\n",
        "| Ensemble | modèle TM   |  AD+LBP Global  | AD+LBP Local  | modèle deep 1 + arbre | modèle deep 2 - arbre | modèle deep 1 + PCA + arbre | modèle deep 1 + PCA + QDA | modèle deep 1 + LDA  | modèle deep 1 + PCA + KNN |\n",
        "|----------|-------------|-----------------|---------------|---------------|---------------|----------|-------------|-----------------|---------------|\n",
        "| App | 99,67 |  |  |  |  |  |  |  |  | |\n",
        "| Val      | 89,77       |  |  |  |  |  |  |  |  | |\n",
        "| Test     | 77,99       |  |  |  |  |  |  |  |  | |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_Y4GZDwdCsQ"
      },
      "source": [
        "# Fin"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
