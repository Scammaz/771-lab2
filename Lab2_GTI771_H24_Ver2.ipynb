{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPGJUbXEfY0L"
      },
      "source": [
        "# GTI771 - Apprentissage machine avanc√©\n",
        "## D√©partement de g√©nie logiciel et des technologies de l‚Äôinformation\n",
        "\n",
        "\n",
        "\n",
        "## Laboratoire 2 - Extraction de primitives\n",
        "#### <font color=black> Version 2 - Janvier 2024 </font>\n",
        "\n",
        "##### <font color=grey> Version 1 - Prof. Alessandro L. Koerich.\n",
        "##### Version 2 - Charg√© de lab. Arthur Josi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Zt1vzFvfY0M"
      },
      "source": [
        "| NOMS                  | CODE PERMANENT                                   |\n",
        "|-----------------------|--------------------------------------------------|\n",
        "| √âtudiant1             | Code1                                            |\n",
        "| √âtudiant2             | Code2                                            |\n",
        "| √âtudiant3             | Code3                                            |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZr52AqbfY0N"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Ce deuxi√®me laboratoire porte sur la d√©finition et l‚Äôextraction de primitives sur des visages. Vous aurez deux semaine pour compl√©ter celui-ci.\n",
        "\n",
        "De nouveau, le probl√®me de classification qui vous est pr√©sent√© est le probl√®me [Facial Expression Recognition (FER)](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data), dont le but est de classer des visages dans sept (7) cat√©gories. En vous basant sur les concepts vus en classe et sur acquises en laboratoire, vous devez d√©finir des primitives que vous jugez pertinentes √† extraire sur ces types d‚Äôimages et effectuer l‚Äôextraction de celles-ci sur l‚Äôensemble de donn√©es fournies avec cet √©nonc√©.\n",
        "\n",
        "L‚Äô√©valuation de ce laboratoire sera bas√©e sur:\n",
        "- la qualit√© des algorithmes propos√©s et utilis√©s;\n",
        "- les r√©ponses aux questions dans cette notebook;\n",
        "- l'organisation de votre code source (SVP, n'oubliez pas de mettre des commentaires dans le code source!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "pLH24hiwfY0N"
      },
      "source": [
        "# Modules et bibliot√®ques python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SulKAl9XfY0N"
      },
      "source": [
        "### Import de bibliot√®ques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apQhzHM5fY0N"
      },
      "source": [
        "###  <font color=blue> √Ä faire: </font>\n",
        "1. Ajouter les biblioth√®ques que vous avez utilis√©es pour compl√©ter ce notebook dans une cellule avec une petite description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rY009kxNfY0O"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # package for scientific computing with Python.\n",
        "import matplotlib.pyplot as plt # 2D plotting library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyEAsG9OfY0P"
      },
      "source": [
        "# Partie 1 - Ensemble de donn√©es\n",
        "\n",
        "Point de d√©part: *fer2013-clean.csv* ou *fer2013-clean-pre.csv*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrnkkVytfY0P"
      },
      "source": [
        "## 1a: Charger le fichier de donn√©es nettoy√© et normalis√©\n",
        "\n",
        "###  <font color=blue> √Ä faire: </font>\n",
        "1. Reprenez votre ensemble de donn√©es nettoy√© et rep√©rez les trois partitions de donn√©es: apprentissage, validation et test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_WtAyj7fY0P"
      },
      "outputs": [],
      "source": [
        "# Load data - Au choix:\n",
        "\n",
        "# ferData = np.loadtxt( 'fer2013-clean.csv', delimiter=',', dtype=str )\n",
        "ferData = np.loadtxt( 'content/fer2013-clean-pre.csv', delimiter=',', dtype=str )\n",
        "\n",
        "training_data = ferData[ferData[:, 2] == 'Training']\n",
        "validation_data = ferData[ferData[:, 2] == 'PublicTest']\n",
        "test_data = ferData[ferData[:, 2] == 'PrivateTest']\n",
        "\n",
        "def transform_str_float(d):\n",
        "    return np.array([np.fromstring(row, sep=' ', dtype=float) for row in d])\n",
        "\n",
        "# Training set\n",
        "Xtrain = transform_str_float(training_data[:, 1])\n",
        "ytrain = np.array(training_data[:,0], dtype=np.float32)\n",
        "\n",
        "# Validation set\n",
        "Xval = transform_str_float(validation_data[:, 1])\n",
        "yval = np.array(validation_data[:,0], dtype=np.float32)\n",
        "\n",
        "# # Test set\n",
        "Xtest = transform_str_float(test_data[:, 1])\n",
        "ytest = np.array(test_data[:,0], dtype=np.float32)\n",
        "\n",
        "print(Xtrain.shape, Xval.shape, Xtest.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "Xtrain = Xtrain.reshape( Xtrain.shape[0], 1, 48, 48 ).astype('uint8')\n",
        "Xtest  = Xtest.reshape( Xtest.shape[0], 1, 48, 48 ).astype('uint8')\n",
        "Xval   = Xval.reshape( Xval.shape[0], 1, 48, 48 ).astype('uint8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R8QdBYAfY0Q"
      },
      "source": [
        "# Partie 2: Extraction de primitives\n",
        "\n",
        "Vous devez faire une recherche bibliographique pour trouver quelles sont les primitives qui sont plus souvent utilis√©es pour la reconnaissance des expressions faciales, et pour mieux comprendre leur int√©r√™t. Voici quelques sources et mots-cl√©s pour guider votre recherche:\n",
        "\n",
        "- http://www.inf.ufpr.br/lesoliveira/download/ESWA2013.pdf\n",
        "- https://doi.org/10.1016/j.patrec.2015.06.007\n",
        "- https://doi.org/10.1109/FG.2011.5771374\n",
        "- https://www.hindawi.com/journals/ijbi/2015/267807/\n",
        "- https://link.springer.com/article/10.1007/s00500-020-05550-y\n",
        "- https://ieeexplore.ieee.org/document/9232510/\n",
        "- https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9136619\n",
        "- https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-ipr.2018.6647\n",
        "\n",
        "\n",
        "**Mots-cl√©s**: feature extraction, facial expression recognition, facial emotion recognition.\n",
        "\n",
        "Biblioth√®ques Python pour les algorithmes d'extraction de primitives :\n",
        "* [Scikit-image](https://scikit-image.org/docs/dev/)\n",
        "* [OpenCV](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html)\n",
        "* [Scikit-learn](https://scikit-learn.org/stable/modules/feature_extraction.html)\n",
        "* [BiT](https://pypi.org/project/Bitdesc/)\n",
        "* [E-BiT](https://github.com/stevetmat/BioInspiredFDesc)\n",
        "\n",
        "Exemples d'algorithmes d'extraction de primitive :\n",
        "\n",
        "* LBP, LPQ, Gabor filters, SIFT, SURF, HOG, GLCM, Haralick Moments, BiT, E-BiT, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGB_A2MmfY0Q"
      },
      "source": [
        "## 2a: Choix d'un algorithme d'extraction des primitives\n",
        "\n",
        "###  <font color=blue> √Ä faire: </font>\n",
        "1. Choisir un algorithme d'extraction de primitives\n",
        "  - #### <font color=red> Attention! Les √©quipes doivent utiliser des primitives diff√©rentes! Il n'y a pas de mauvais choix, seulement des approaches diff√©rentes, pas d'inqui√©tude. </font>\n",
        "  - Chaque √©quipe doit poster/publier un message dans le <font color=red>\"forum TP2\"</font> avec son choix\n",
        "  - Premi√®re arriv√©e premi√®re servie!<br><br>\n",
        "2. G√©n√©ralement, les algorithmes d'extraction de primitives ont plusieurs √©tapes. Vous devez √©tudier l'algorithme et la biblioth√®que choisie pour bien comprendre l'algorithme, les primitives qu'il produit, et la mani√®re dont vous devrez coder celui-ci. Aucune r√©ponse n'est attendue pour cette question.\n",
        "3. Nommer l'algorithme choisi et expliquer bri√®vement celui-ci, ses hyperparam√®tres, et le vecteur de sortie (dimension, type de variable)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flJTGl8PfY0Q"
      },
      "source": [
        "#### R√©ponses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BaiEN99fY0R"
      },
      "source": [
        "#### Explication :\n",
        "Les filtres de Gabor sont utilis√©s pour analyser la texture et les caract√©ristiques spatiales des images. Un filtre de Gabor est compos√© d'une fonction sinus avec une fonction gausienne.\n",
        "\n",
        "$G\\left(x,y;\\lambda,\\theta,\\psi,\\sigma,\\gamma \\right) = exp\\left(- {x'^2+\\gamma^2y'^2 \\over 2\\sigma^2} \\right) cos\\left( 2œÄ{x' \\over \\lambda } + \\psi \\right)$\n",
        "\n",
        "o√π :\n",
        "1. $x' = x \\cos \\theta + y \\sin \\theta$\n",
        "2. $y' = - x \\sin \\theta + y \\cos \\theta$\n",
        "\n",
        "#### Hyperparam√®tres :\n",
        "Les principaux hyperparam√®tres des filtres de Gabor sont :\n",
        "\n",
        "1. Lambda (ùúÜ) : La longueur d'onde de la sinuso√Øde, qui d√©termine la fr√©quence de la sinuso√Øde.\n",
        "2. Theta (ùúÉ) : L'orientation de la normale au parall√©logramme, qui d√©finit l'orientation du filtre.\n",
        "3. Psi (ùúì) : La phase de la fonction sinuso√Ødale.\n",
        "4. Sigma (ùúé) : L'√©cart-type de la gaussienne, qui contr√¥le l'√©tendue du filtre.\n",
        "5. Gamma (ùõæ) : Le rapport d'aspect de la gaussienne, qui d√©termine l'√©longation du filtre.\n",
        "\n",
        "#### Vecteur de sortie : \n",
        "Le vecteur de sortie d√©pend des dimensions de l'image et le nombre de filtre appliqu√©s. Dans notre cas o√π les images sont de tailles 48x48, le vecteur de sortie sera de 2304.Votre explication ici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YaNZjygfY0R"
      },
      "source": [
        "## 2b: Extraction globale des primitives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2rsOtaEfY0R"
      },
      "source": [
        "###  <font color=blue> √Ä faire: </font>\n",
        "1. Extraire les primitives choisies des visages (ensembles d'apprentissage, validation et test). Un vecteur de primitives peut √™tre, p. ex. 16 valeurs r√©elles repr√©sentant les sorties des filtres de Gabor, un ensemble de Haar-like features ou plusieurs valeurs r√©elles calcul√©es par les descripteurs de Haralick (p. ex. contraste, homog√©n√©it√©, etc.).\n",
        "  - Chaque image de visage sera alors repr√©sent√©e par un vecteur $d-$dimensionnel.\n",
        "  - Attention! Le r√©sultat des algorithmes d'extraction de primitives doit √™tre des vecteurs de primitives. Il y a des algorithmes qui n√©cessitent d'une √©tape suppl√©mentaire comme calculer les histogrammes de primitives (p. ex. LBP, LPQ, SIFT, etc.)<br><br>\n",
        "\n",
        "2. Sauvegarder les vecteurs de primitives obtenus sous la forme d'un fichier 'csv' (*fer2013-clean-lbp.csv* ou *fer2013-clean-pre-lbp.csv*). N'oubliez pas d'utiliser toujours la m√™me structure que le fichier original *fer2013.csv*. Vous devez nommer vos fichiers de primitive en r√©f√©rence √† la primitive utilis√©e, p. ex., *fer2013-clean-lbp.csv* pour LBP, *fer2013-clean-hog.csv* pour HOG, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds6zb_qAfY0R"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mean_removal(X) -> np.ndarray:\n",
        "    return X - np.mean(X, axis=0)\n",
        "\n",
        "def normalize(X) -> np.ndarray:\n",
        "    return X / 255\n",
        "\n",
        "\n",
        "\n",
        "Xtrain_standardized = normalize(mean_removal(Xtrain))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def build_gabor_kernels(ksize=33, sigma=3.20, lambd=11.0, gamma=2.5, psi=-1, orientations=8, scales=5):\n",
        "    kernels = []\n",
        "    for scale in range(scales):\n",
        "        for theta in np.linspace(0, np.pi, orientations, endpoint=False):\n",
        "            kernel = cv2.getGaborKernel(\n",
        "                (ksize, ksize), sigma +scale , theta, lambd, gamma, psi, ktype=cv2.CV_32F)\n",
        "            kernels.append(kernel)\n",
        "    return kernels\n",
        "\n",
        "def apply_gabor_filters(image, kernels):\n",
        "    filtered_images = []\n",
        "    for kernel in kernels:\n",
        "        filtered_image = cv2.filter2D(image, cv2.CV_8UC3, kernel)\n",
        "        filtered_images.append(filtered_image)\n",
        "    return filtered_images\n",
        "\n",
        "def extract_features(filtered_images):\n",
        "    features = []\n",
        "    for img in filtered_images:\n",
        "        mean = np.mean(img)\n",
        "        variance = np.var(img)\n",
        "        features.append(mean)\n",
        "        features.append(variance)\n",
        "        energy_val = np.sum(img**2)\n",
        "        entropy_val = -np.sum(img * np.log(img + 1e-6))\n",
        "        features.append(energy_val)\n",
        "        features.append(entropy_val)\n",
        "    return features\n",
        "\n",
        "def load_data():\n",
        "    # Placeholder function to load data\n",
        "    # Replace this with actual data loading code\n",
        "    #X = Xtrain # Dummy data\n",
        "    X = Xtrain_standardized[0:10000]\n",
        "    y = ytrain[0:10000]  # Dummy labels (binary classification)\n",
        "    return X, y\n",
        "\n",
        "def evaluate_parameters(params, X, y, orientations, scales):\n",
        "    ksize, sigma, lambd, gamma, psi = params\n",
        "    kernels = build_gabor_kernels(ksize=ksize, sigma=sigma, lambd=lambd, gamma=gamma, psi=psi, orientations=orientations, scales=scales)\n",
        "\n",
        "    X_features = []\n",
        "    for i in range(len(X)):\n",
        "        image = X[i].reshape(48, 48)\n",
        "        filtered_images = apply_gabor_filters(image, kernels)\n",
        "        features = extract_features(filtered_images)\n",
        "        X_features.append(features)\n",
        "\n",
        "    X_features = np.array(X_features)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.20, random_state=42)\n",
        "    pipe = make_pipeline(StandardScaler(), SVC())\n",
        "    pipe.fit(X_train, y_train)\n",
        "    pipe.score(X_test, y_test)\n",
        "    clf = SVC()\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f'Tested Params: ksize={ksize}, sigma={sigma}, lambd={lambd}, gamma={gamma}, psi={psi} => Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "    return accuracy, params\n",
        "\n",
        "def grid_search_gabor_params(X, y, ksize_values, sigma_values, lambd_values, gamma_values, psi_values, orientations=8, scales=5):\n",
        "    best_accuracy = 0\n",
        "    best_params = None\n",
        "\n",
        "    param_sets = [(ksize, sigma, lambd, gamma, psi) \n",
        "                  for ksize in ksize_values \n",
        "                  for sigma in sigma_values \n",
        "                  for lambd in lambd_values \n",
        "                  for gamma in gamma_values \n",
        "                  for psi in psi_values]\n",
        "\n",
        "    # Use joblib to evaluate the parameters in parallel\n",
        "    results = Parallel(n_jobs=-1)(delayed(evaluate_parameters)(params, X, y, orientations, scales) for params in param_sets)\n",
        "    \n",
        "    print(f'Results: {results}')  # Debugging print\n",
        "    \n",
        "    # Find the best parameters based on the highest accuracy\n",
        "    if results:\n",
        "        best_accuracy, best_params = max(results, key=lambda x: x[0])\n",
        "    \n",
        "    print(f'Best Params: {best_params}, Best Accuracy: {best_accuracy}')  # Debugging print\n",
        "    \n",
        "    return best_params, best_accuracy\n",
        "\n",
        "\n",
        "def visualize_kernels(kernels, orientations, scales):\n",
        "    fig, axes = plt.subplots(scales, orientations, figsize=(12, 6))\n",
        "    for i in range(scales):\n",
        "        for j in range(orientations):\n",
        "            kernel = kernels[i * orientations + j]\n",
        "            ax = axes[i, j]\n",
        "            ax.imshow(kernel, cmap='gray')\n",
        "            ax.axis('off')\n",
        "            ax.set_title(f'Scale {i+1}, Orientation {j+1}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load the dataset\n",
        "    X, y = load_data()\n",
        "\n",
        "    # Define the ranges for the Gabor parameters (coarse search)\n",
        "    ksize_values = [31]\n",
        "    sigma_values = [1.9]\n",
        "    lambd_values = [6]\n",
        "    gamma_values = [0.5,1]\n",
        "    psi_values = [3,2.5]\n",
        "\n",
        "    # Perform grid search\n",
        "    best_params, best_accuracy = grid_search_gabor_params(X, y, ksize_values, sigma_values, lambd_values, gamma_values, psi_values, orientations=8, scales=5)\n",
        "\n",
        "    print(f'Best Params: ksize={best_params[0]}, sigma={best_params[1]}, lambd={best_params[2]}, gamma={best_params[3]}, psi={best_params[4]}')\n",
        "    print(f'Best Accuracy: {best_accuracy * 100:.2f}%')\n",
        "\n",
        "    # Visualize an example image and its Gabor filtered responses with best parameters\n",
        "    best_kernels = build_gabor_kernels(ksize=best_params[0], sigma=best_params[1], lambd=best_params[2], gamma=best_params[3], psi=best_params[4], orientations=8, scales=5)\n",
        "    example_image = X[0].reshape(48, 48)\n",
        "    filtered_images = apply_gabor_filters(example_image, best_kernels)\n",
        "\n",
        "    visualize_kernels(best_kernels, orientations=8, scales=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(5, 8, 1)\n",
        "plt.imshow(example_image, cmap='gray')\n",
        "plt.title('Original Image')\n",
        "plt.show()\n",
        "\n",
        "visualize_kernels(filtered_images, orientations=8, scales=5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize all the Gabor kernels\n",
        "visualize_kernels(best_kernels, orientations=8, scales=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvrIqcjfY0S"
      },
      "source": [
        "## 2c: Extraction locale des primitives\n",
        "\n",
        "[Koutlas et Fotiadis (2008)](http://dx.doi.org/10.4018/9781605663142.ch016) ont propos√© un ensemble de 20 points de r√©f√©rence. Selon les auteurs, ces points se situent autour des caract√©ristiques pro√©minentes du visage qui contiennent les informations les plus importantes concernant le mouvement musculaire responsable des expressions faciales.\n",
        "\n",
        "√âtant donn√© que vous ne connaissez pas la localisation de ces points de r√©f√©rence, une mani√®re approxim√©e d‚Äôextraire des informations locales des images de visage consiste √† diviser l'image en $n$ petits zones de dimension √©gale  ($z_0, z_1,... ,z_n$) et d'extraire des primitives de chaque zone. Les primitives extraites de chaque zone sont ensuite concat√©n√©es en un seul vecteur de primitives.\n",
        "\n",
        "![Exemples de FER](https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/04/face_reco_lbps_header.png?lossy=1&strip=1&webp=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iJWa0s3fY0S"
      },
      "source": [
        "###  <font color=blue> √Ä faire: </font>\n",
        "1. Utiliser une grille de dimension √† votre choix (p. ex. $2$$\\times$$2$, $4$$\\times$$4$, $6$$\\times$$6$, ...) de fa√ßon √† cr√©er de zones sur des images.\n",
        "Remarque: La dimension de vos nouveaux ensembles de donn√©es pourrait maintenant √™tre [samples][channels][nb_squares_per_img][width][height].\n",
        "2. R√©p√©tez les pas de 2b, c.-√†-d., √©xtraire les primitives choisies de chaque cellule (zone) (ensembles d'apprentissage, validation et test). Un vecteur de primitives similaire √† celui de la partie 2b sera produit pour chaque zone.\n",
        "3. Concat√©nez s√©quentiellement les vecteurs g√©n√©r√©s pour chaque zone.\n",
        "\n",
        " - Chaque image de visage sera alors repr√©sent√©e par un vecteur de dimension $d$ $\\times$ $nombre\\_de\\_zones$.<br><br>\n",
        "4. Sauvegardez vos vecteurs de primitives sous la forme d'un fichier 'csv' (*fer2013-clean-lbp-zone4x4.csv* ou *fer2013-clean-pre-lbp-zone4x4.csv*). N'oubliez pas d'utiliser toujours la m√™me structure du fichier original *fer2013.csv*. Vous devez nommer vos fichiers de primitive en r√©f√©rence √† la primitive utilis√©e et la dimension de la grille choisie, p. ex., *fer2013-clean-lbp-zone4x4.csv* pour un zonage $4$$\\times$$4$, *fer2013-clean-hog-zone8x8.csv* pour un zonage $8$$\\times$$8$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZvPrRQofY0T"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjAHvPfsfY0T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Get the dimensions of the image\n",
        "height, width = masked_image.shape\n",
        "\n",
        "# Define the number of rows and columns for the grid\n",
        "rows = 4\n",
        "cols = 4\n",
        "\n",
        "# Calculate the size of each zone\n",
        "zone_height = height // rows\n",
        "zone_width = width // cols\n",
        "\n",
        "# Create subplots for each zone\n",
        "fig, axs = plt.subplots(rows, cols, figsize=(10, 10))\n",
        "\n",
        "# Feature extraction function\n",
        "def local_feature_extraction(image, rows=4, cols=4):\n",
        "    height, width = image.shape\n",
        "    zone_height = height // rows\n",
        "    zone_width = width // cols\n",
        "\n",
        "    feature = [[[] for _ in range(cols)] for _ in range(rows)]\n",
        "    \n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            # Calculate the start and end indices for slicing\n",
        "            start_row = i * zone_height\n",
        "            end_row = (i + 1) * zone_height\n",
        "            start_col = j * zone_width\n",
        "            end_col = (j + 1) * zone_width\n",
        "        \n",
        "            # Slice the image to extract the current zone\n",
        "            zone = image[start_row:end_row, start_col:end_col]\n",
        "            \n",
        "            # Calculate features for the zone\n",
        "            mean = np.mean(zone)\n",
        "            variance = np.var(zone)\n",
        "            energy_val = np.sum(zone**2)\n",
        "            entropy_val = -np.sum(zone * np.log(zone + 1e-6))\n",
        "            \n",
        "            # Append features to the list\n",
        "            feature[i][j].append(mean)\n",
        "            feature[i][j].append(variance)\n",
        "            feature[i][j].append(energy_val)\n",
        "            feature[i][j].append(entropy_val)\n",
        "            \n",
        "            # Optional: Display the zone\n",
        "            axs[i, j].imshow(zone, cmap='gray')\n",
        "\n",
        "    return feature\n",
        "\n",
        "# Process each filtered image and collect features\n",
        "info = []\n",
        "for img in filtered_images:\n",
        "    feature = local_feature_extraction(img)\n",
        "    info.append(feature)\n",
        "\n",
        "# Convert the list of features into a NumPy array with the desired structure\n",
        "info_array = np.array(info)\n",
        "\n",
        "# Reshape the array to have the desired dimensions: [num_images, rows, cols, extracted_features]\n",
        "num_images = len(info)\n",
        "rows, cols = len(info[0]), len(info[0][0])\n",
        "extracted_features = len(info[0][0][0])  # Assuming all feature lists have the same length\n",
        "\n",
        "info_array = info_array.reshape((num_images, rows, cols, extracted_features))\n",
        "\n",
        "# To verify the structure\n",
        "print(info_array.shape)\n",
        "\n",
        "\n",
        "print(info_array.flatten().shape)\n",
        "\n",
        "\n",
        "flattened_info_array = info_array.reshape((-1, extracted_features))\n",
        "\n",
        "###NORMALISE\n",
        "min_vals = np.min(flattened_info_array, axis=0)\n",
        "max_vals = np.max(flattened_info_array, axis=0)\n",
        "normalized_flattened_info_array = (flattened_info_array - min_vals) / (max_vals - min_vals)\n",
        "\n",
        "# Reshape back to the original structure\n",
        "normalized_info_array = normalized_flattened_info_array.reshape((num_images, rows, cols, extracted_features))\n",
        "# Reshape back to the original structure\n",
        "normalized_info_array = normalized_flattened_info_array.reshape((num_images, rows, cols, extracted_features))\n",
        "\n",
        "# Convert to a more readable format\n",
        "formatted_info_array = np.around(normalized_info_array, decimals=3)\n",
        "\n",
        "# To verify the structure and values\n",
        "print(\"Shape of formatted_info_array:\", formatted_info_array.shape)\n",
        "print(\"Formatted info array:\\n\", formatted_info_array)\n",
        "\n",
        "# Check that values are within the range [0, 1]\n",
        "print(\"Min value in formatted_info_array:\", np.min(formatted_info_array))\n",
        "print(\"Max value in formatted_info_array:\", np.max(formatted_info_array))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRel8ToPfY0T"
      },
      "source": [
        "# Partie 3: Normalisations des vecteurs de primitive\n",
        "Avant d'entra√Æner un premier mod√®le d'apprentissage automatique avec les vecteurs de primitives (global et local) extrait dans la Partie 2, vous devez faire une normalisation des primitives.\n",
        "\n",
        "La normalisation transforme les caract√©ristiques en √©chelles similaires (modifier la plage des valeurs) pour aider √† am√©liorer les performances et la stabilit√© d'entra√Ænement d'un mod√®le d‚Äôapprentissage machine. Notez que tous les ensembles de donn√©es n'ont pas n√©cessairement besoin d'√™tre normalis√©s. Il n'est n√©cessaire que lorsque les plages d'attributs sont diff√©rentes.\n",
        "\n",
        "Les algorithmes bas√©s sur les mesures de distance telle que $k$-PPV et SVM sont les plus affect√©s par des diff√©rences dans les √©chelles. Les algorithmes d'apprentissage automatique qui utilisent l'algorithme descente de gradient dans l'entra√Ænement tel que la r√©gression lin√©aire et la r√©gression logistique n√©cessitent une mise √† l'√©chelle des donn√©es (m√™me plage des valeurs) pour aider la descente de gradient √† converger plus rapidement vers les minima. D'autre part, les algorithmes bas√©s sur les arbres ne sont pas sensibles √† l'√©chelle des caract√©ristiques. En effet, un arbre de d√©cision ne divise qu'un n≈ìud en fonction d'une seule primitive (√©l√©ment du vecteur), et cette division n'est pas influenc√©e par d'autres √©l√©ments (primitives) du vecteur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_R5P1rufY0T"
      },
      "source": [
        "###  <font color=blue> √Ä faire: </font>\n",
        "1. Vous pouvez retrouver des algorithmes de normalisation de la biblioth√®que 'scikit-learn' [dans l'onglet preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)que vous avez par exemple discut√© en cours et comprendre les diff√©rentes types de normalisation.\n",
        " - Voir aussi l'exemple [Compare the effect of different scalers on data with outliers](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py)<br><br>\n",
        "2. Choisir un algorithme pour normaliser vos vecteurs de primitives.\n",
        "3. Normaliser vos vecteurs d'apprentissage, validation et test.\n",
        "\n",
        " - Attention! Utilisez *fit()* pour les donn√©es d'apprentissage et apr√®s *transform()* sur les trois partitions de donn√©es (apprentissage, validation et test).<br><br>\n",
        "4. Sauvegardez vos vecteurs de primitives sous la forme d'un fichier 'csv' (*fer2013-clean-lbp-zone4x4-norm.csv* ou *fer2013-clean-pre-lbp-zone4x4-norm.csv*).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY4xMr9WfY0T"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdxMqAnmfY0T"
      },
      "outputs": [],
      "source": [
        "# Votre code ici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5bnt7mufY0U"
      },
      "source": [
        "# Partie 4: Entra√Ænement des mod√®le d'apprentissage machine\n",
        "\n",
        "Vous √™tes maintenant pr√™tes √† entra√Æner un premier mod√®le d'apprentissage automatique avec les vecteurs de primitives (global et local) extraites dans la Partie 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rwG_HglfY0U"
      },
      "source": [
        "## 4a: Entra√Æner un arbre de d√©cision avec les primitives globales\n",
        "\n",
        "###  <font color=blue> √Ä faire: </font>\n",
        "1. √âtudiez l'algorithme [arbre de d√©cision](https://scikit-learn.org/stable/modules/tree.html#tree-classification) de la biblioth√®que `scikit-learn` pour bien comprendre les diff√©rents param√®tres qui peuvent affecter l'entra√Ænement, la g√©n√©ralisation et la complexit√© d‚Äôun mod√®le du type arbre de d√©cision.\n",
        "2. √âtudiez les principaux hyperparam√®tres de [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) qui peuvent aider √† am√©liorer sa performance.\n",
        "3. Choisir quelques hyperparam√®tres (au moins 2) et tourner un \"grid search\" sur l'ensemble de validation pour trouver les meilleures valeurs pour ces hyperparam√®tres.\n",
        "\n",
        "- Astuce: Vous avez d√©j√† un ensemble de validation! Alors, c'est pr√©f√©rable (beaucoup plus rapide!) d‚Äôutiliser la biblioth√®que [hypopt](https://pypi.org/project/hypopt/) pour faire le r√©glage des hyperparam√®tres (grid seach)<br><br>\n",
        "\n",
        "4. Une fois que vous avez trouv√© le meilleur mod√®le, utiliser ces mod√®les pour faire la pr√©diction sur tous les exemples (apprentissage, validation, test) et rapporter les r√©sultats (comme fait dans le TP1):<br>\n",
        "4a. Rapport de classification produit avec *<font color=green>from sklearn.metrics import classification_report</font>*<br>\n",
        "4b. taux de classification correct sur les trois (3) ensembles de donn√©es (sous la forme d'un tableau)<br>\n",
        "4c. matrice de confusion produite avec *<font color=green> from sklearn.metrics import confusion_matrix</font>* pour les r√©sultats sur l'ensemble de test (matrice 7 $\\times$ 7 - √©tiqu√©tte $\\times$ pr√©dictions)\n",
        "\n",
        "5. Sauvegarder votre mod√®le dans un fichier *.pkl*. Regarder [model persistence](https://scikit-learn.org/stable/model_persistence.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqaGIvxlfY0U"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FMbV36AfY0U"
      },
      "outputs": [],
      "source": [
        "# Votre code ici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-s_euFqfY0U"
      },
      "source": [
        "## 4b: Entra√Æner un arbre de d√©cision avec les primitives locales\n",
        "###  <font color=blue> √Ä faire: </font>\n",
        "1. Refaire les √©tapes 3 √† 5 de 4a)\n",
        "2. Comparez les r√©sultats avec ceux attendus avec les primitives globales et *template matching* (TP1)\n",
        "3. Faire une br√®ve analyse des r√©sultats et pr√©senter vos consid√©rations et conclusions sur la performance de vos primitives + mod√®les."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjP2WGDlfY0U"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd2dgGiYfY0U"
      },
      "outputs": [],
      "source": [
        "# Votre code ici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa-CZDNnfY0U"
      },
      "source": [
        "#### R√©sultats et r√©sponses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16ynw2bSfY0U"
      },
      "source": [
        "#### Vos r√©pondes et r√©sultats pour 4a) et 4b) ici:\n",
        "\n",
        "##### Exemple:\n",
        "\n",
        "Taux de classification (%)\n",
        "\n",
        "| Ensemble | mod√®le TM   |  AD+LBP Global  | AD+LBP Local  |                                 \n",
        "|----------|-------------|-----------------|---------------|\n",
        "| App      | 99,67       |                 |               |                   \n",
        "| Val      | 89,77       |                 |               |                             \n",
        "| Test     | 77,99       |                 |               |        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyrNyBH4fY0U"
      },
      "source": [
        "# Fin"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
