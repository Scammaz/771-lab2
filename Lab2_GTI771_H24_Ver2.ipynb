{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPGJUbXEfY0L"
      },
      "source": [
        "# GTI771 - Apprentissage machine avancé\n",
        "## Département de génie logiciel et des technologies de l’information\n",
        "\n",
        "\n",
        "\n",
        "## Laboratoire 2 - Extraction de primitives\n",
        "#### <font color=black> Version 2 - Janvier 2024 </font>\n",
        "\n",
        "##### <font color=grey> Version 1 - Prof. Alessandro L. Koerich.\n",
        "##### Version 2 - Chargé de lab. Arthur Josi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Zt1vzFvfY0M"
      },
      "source": [
        "| NOMS                  | CODE PERMANENT                                   |\n",
        "|-----------------------|--------------------------------------------------|\n",
        "| Étudiant1             | Code1                                            |\n",
        "| Étudiant2             | Code2                                            |\n",
        "| Étudiant3             | Code3                                            |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZr52AqbfY0N"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Ce deuxième laboratoire porte sur la définition et l’extraction de primitives sur des visages. Vous aurez deux semaine pour compléter celui-ci.\n",
        "\n",
        "De nouveau, le problème de classification qui vous est présenté est le problème [Facial Expression Recognition (FER)](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data), dont le but est de classer des visages dans sept (7) catégories. En vous basant sur les concepts vus en classe et sur acquises en laboratoire, vous devez définir des primitives que vous jugez pertinentes à extraire sur ces types d’images et effectuer l’extraction de celles-ci sur l’ensemble de données fournies avec cet énoncé.\n",
        "\n",
        "L’évaluation de ce laboratoire sera basée sur:\n",
        "- la qualité des algorithmes proposés et utilisés;\n",
        "- les réponses aux questions dans cette notebook;\n",
        "- l'organisation de votre code source (SVP, n'oubliez pas de mettre des commentaires dans le code source!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "pLH24hiwfY0N"
      },
      "source": [
        "# Modules et bibliotèques python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SulKAl9XfY0N"
      },
      "source": [
        "### Import de bibliotèques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apQhzHM5fY0N"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "1. Ajouter les bibliothèques que vous avez utilisées pour compléter ce notebook dans une cellule avec une petite description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rY009kxNfY0O"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # package for scientific computing with Python.\n",
        "import matplotlib.pyplot as plt # 2D plotting library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyEAsG9OfY0P"
      },
      "source": [
        "# Partie 1 - Ensemble de données\n",
        "\n",
        "Point de départ: *fer2013-clean.csv* ou *fer2013-clean-pre.csv*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrnkkVytfY0P"
      },
      "source": [
        "## 1a: Charger le fichier de données nettoyé et normalisé\n",
        "\n",
        "###  <font color=blue> À faire: </font>\n",
        "1. Reprenez votre ensemble de données nettoyé et repérez les trois partitions de données: apprentissage, validation et test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_WtAyj7fY0P"
      },
      "outputs": [],
      "source": [
        "# Load data - Au choix:\n",
        "# ferData = np.loadtxt( 'fer2013-clean.csv', delimiter=',', dtype=str )\n",
        "ferData = np.loadtxt( 'fer2013-clean-pre.csv', delimiter=',', dtype=str )\n",
        "\n",
        "# Training set\n",
        "Xtrain = <à compléter>\n",
        "ytrain = <à compléter>\n",
        "\n",
        "# Validation set\n",
        "Xval = <à compléter>\n",
        "yval = <à compléter>\n",
        "\n",
        "# Test set\n",
        "Xtest = <à compléter>\n",
        "ytest = <à compléter>\n",
        "\n",
        "print(Xtrain.shape, Xval.shape, Xtest.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R8QdBYAfY0Q"
      },
      "source": [
        "# Partie 2: Extraction de primitives\n",
        "\n",
        "Vous devez faire une recherche bibliographique pour trouver quelles sont les primitives qui sont plus souvent utilisées pour la reconnaissance des expressions faciales, et pour mieux comprendre leur intérêt. Voici quelques sources et mots-clés pour guider votre recherche:\n",
        "\n",
        "- http://www.inf.ufpr.br/lesoliveira/download/ESWA2013.pdf\n",
        "- https://doi.org/10.1016/j.patrec.2015.06.007\n",
        "- https://doi.org/10.1109/FG.2011.5771374\n",
        "- https://www.hindawi.com/journals/ijbi/2015/267807/\n",
        "- https://link.springer.com/article/10.1007/s00500-020-05550-y\n",
        "- https://ieeexplore.ieee.org/document/9232510/\n",
        "- https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9136619\n",
        "- https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-ipr.2018.6647\n",
        "\n",
        "\n",
        "**Mots-clés**: feature extraction, facial expression recognition, facial emotion recognition.\n",
        "\n",
        "Bibliothèques Python pour les algorithmes d'extraction de primitives :\n",
        "* [Scikit-image](https://scikit-image.org/docs/dev/)\n",
        "* [OpenCV](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html)\n",
        "* [Scikit-learn](https://scikit-learn.org/stable/modules/feature_extraction.html)\n",
        "* [BiT](https://pypi.org/project/Bitdesc/)\n",
        "* [E-BiT](https://github.com/stevetmat/BioInspiredFDesc)\n",
        "\n",
        "Exemples d'algorithmes d'extraction de primitive :\n",
        "\n",
        "* LBP, LPQ, Gabor filters, SIFT, SURF, HOG, GLCM, Haralick Moments, BiT, E-BiT, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGB_A2MmfY0Q"
      },
      "source": [
        "## 2a: Choix d'un algorithme d'extraction des primitives\n",
        "\n",
        "###  <font color=blue> À faire: </font>\n",
        "1. Choisir un algorithme d'extraction de primitives\n",
        "  - #### <font color=red> Attention! Les équipes doivent utiliser des primitives différentes! Il n'y a pas de mauvais choix, seulement des approaches différentes, pas d'inquiétude. </font>\n",
        "  - Chaque équipe doit poster/publier un message dans le <font color=red>\"forum TP2\"</font> avec son choix\n",
        "  - Première arrivée première servie!<br><br>\n",
        "2. Généralement, les algorithmes d'extraction de primitives ont plusieurs étapes. Vous devez étudier l'algorithme et la bibliothèque choisie pour bien comprendre l'algorithme, les primitives qu'il produit, et la manière dont vous devrez coder celui-ci. Aucune réponse n'est attendue pour cette question.\n",
        "3. Nommer l'algorithme choisi et expliquer brièvement celui-ci, ses hyperparamètres, et le vecteur de sortie (dimension, type de variable)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flJTGl8PfY0Q"
      },
      "source": [
        "#### Réponses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BaiEN99fY0R"
      },
      "source": [
        "Votre explication ici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YaNZjygfY0R"
      },
      "source": [
        "## 2b: Extraction globale des primitives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2rsOtaEfY0R"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "1. Extraire les primitives choisies des visages (ensembles d'apprentissage, validation et test). Un vecteur de primitives peut être, p. ex. 16 valeurs réelles représentant les sorties des filtres de Gabor, un ensemble de Haar-like features ou plusieurs valeurs réelles calculées par les descripteurs de Haralick (p. ex. contraste, homogénéité, etc.).\n",
        "  - Chaque image de visage sera alors représentée par un vecteur $d-$dimensionnel.\n",
        "  - Attention! Le résultat des algorithmes d'extraction de primitives doit être des vecteurs de primitives. Il y a des algorithmes qui nécessitent d'une étape supplémentaire comme calculer les histogrammes de primitives (p. ex. LBP, LPQ, SIFT, etc.)<br><br>\n",
        "\n",
        "2. Sauvegarder les vecteurs de primitives obtenus sous la forme d'un fichier 'csv' (*fer2013-clean-lbp.csv* ou *fer2013-clean-pre-lbp.csv*). N'oubliez pas d'utiliser toujours la même structure que le fichier original *fer2013.csv*. Vous devez nommer vos fichiers de primitive en référence à la primitive utilisée, p. ex., *fer2013-clean-lbp.csv* pour LBP, *fer2013-clean-hog.csv* pour HOG, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds6zb_qAfY0R"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FePhMvoSfY0S"
      },
      "outputs": [],
      "source": [
        "# Votre code ici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvrIqcjfY0S"
      },
      "source": [
        "## 2c: Extraction locale des primitives\n",
        "\n",
        "[Koutlas et Fotiadis (2008)](http://dx.doi.org/10.4018/9781605663142.ch016) ont proposé un ensemble de 20 points de référence. Selon les auteurs, ces points se situent autour des caractéristiques proéminentes du visage qui contiennent les informations les plus importantes concernant le mouvement musculaire responsable des expressions faciales.\n",
        "\n",
        "Étant donné que vous ne connaissez pas la localisation de ces points de référence, une manière approximée d’extraire des informations locales des images de visage consiste à diviser l'image en $n$ petits zones de dimension égale  ($z_0, z_1,... ,z_n$) et d'extraire des primitives de chaque zone. Les primitives extraites de chaque zone sont ensuite concaténées en un seul vecteur de primitives.\n",
        "\n",
        "![Exemples de FER](https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/04/face_reco_lbps_header.png?lossy=1&strip=1&webp=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iJWa0s3fY0S"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "1. Utiliser une grille de dimension à votre choix (p. ex. $2$$\\times$$2$, $4$$\\times$$4$, $6$$\\times$$6$, ...) de façon à créer de zones sur des images.\n",
        "Remarque: La dimension de vos nouveaux ensembles de données pourrait maintenant être [samples][channels][nb_squares_per_img][width][height].\n",
        "2. Répétez les pas de 2b, c.-à-d., éxtraire les primitives choisies de chaque cellule (zone) (ensembles d'apprentissage, validation et test). Un vecteur de primitives similaire à celui de la partie 2b sera produit pour chaque zone.\n",
        "3. Concaténez séquentiellement les vecteurs générés pour chaque zone.\n",
        "\n",
        " - Chaque image de visage sera alors représentée par un vecteur de dimension $d$ $\\times$ $nombre\\_de\\_zones$.<br><br>\n",
        "4. Sauvegardez vos vecteurs de primitives sous la forme d'un fichier 'csv' (*fer2013-clean-lbp-zone4x4.csv* ou *fer2013-clean-pre-lbp-zone4x4.csv*). N'oubliez pas d'utiliser toujours la même structure du fichier original *fer2013.csv*. Vous devez nommer vos fichiers de primitive en référence à la primitive utilisée et la dimension de la grille choisie, p. ex., *fer2013-clean-lbp-zone4x4.csv* pour un zonage $4$$\\times$$4$, *fer2013-clean-hog-zone8x8.csv* pour un zonage $8$$\\times$$8$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZvPrRQofY0T"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjAHvPfsfY0T"
      },
      "outputs": [],
      "source": [
        "# Votre code ici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRel8ToPfY0T"
      },
      "source": [
        "# Partie 3: Normalisations des vecteurs de primitive\n",
        "Avant d'entraîner un premier modèle d'apprentissage automatique avec les vecteurs de primitives (global et local) extrait dans la Partie 2, vous devez faire une normalisation des primitives.\n",
        "\n",
        "La normalisation transforme les caractéristiques en échelles similaires (modifier la plage des valeurs) pour aider à améliorer les performances et la stabilité d'entraînement d'un modèle d’apprentissage machine. Notez que tous les ensembles de données n'ont pas nécessairement besoin d'être normalisés. Il n'est nécessaire que lorsque les plages d'attributs sont différentes.\n",
        "\n",
        "Les algorithmes basés sur les mesures de distance telle que $k$-PPV et SVM sont les plus affectés par des différences dans les échelles. Les algorithmes d'apprentissage automatique qui utilisent l'algorithme descente de gradient dans l'entraînement tel que la régression linéaire et la régression logistique nécessitent une mise à l'échelle des données (même plage des valeurs) pour aider la descente de gradient à converger plus rapidement vers les minima. D'autre part, les algorithmes basés sur les arbres ne sont pas sensibles à l'échelle des caractéristiques. En effet, un arbre de décision ne divise qu'un nœud en fonction d'une seule primitive (élément du vecteur), et cette division n'est pas influencée par d'autres éléments (primitives) du vecteur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_R5P1rufY0T"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "1. Vous pouvez retrouver des algorithmes de normalisation de la bibliothèque 'scikit-learn' [dans l'onglet preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)que vous avez par exemple discuté en cours et comprendre les différentes types de normalisation.\n",
        " - Voir aussi l'exemple [Compare the effect of different scalers on data with outliers](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py)<br><br>\n",
        "2. Choisir un algorithme pour normaliser vos vecteurs de primitives.\n",
        "3. Normaliser vos vecteurs d'apprentissage, validation et test.\n",
        "\n",
        " - Attention! Utilisez *fit()* pour les données d'apprentissage et après *transform()* sur les trois partitions de données (apprentissage, validation et test).<br><br>\n",
        "4. Sauvegardez vos vecteurs de primitives sous la forme d'un fichier 'csv' (*fer2013-clean-lbp-zone4x4-norm.csv* ou *fer2013-clean-pre-lbp-zone4x4-norm.csv*).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY4xMr9WfY0T"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdxMqAnmfY0T"
      },
      "outputs": [],
      "source": [
        "# Votre code ici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5bnt7mufY0U"
      },
      "source": [
        "# Partie 4: Entraînement des modèle d'apprentissage machine\n",
        "\n",
        "Vous êtes maintenant prêtes à entraîner un premier modèle d'apprentissage automatique avec les vecteurs de primitives (global et local) extraites dans la Partie 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rwG_HglfY0U"
      },
      "source": [
        "## 4a: Entraîner un arbre de décision avec les primitives globales\n",
        "\n",
        "###  <font color=blue> À faire: </font>\n",
        "1. Étudiez l'algorithme [arbre de décision](https://scikit-learn.org/stable/modules/tree.html#tree-classification) de la bibliothèque `scikit-learn` pour bien comprendre les différents paramètres qui peuvent affecter l'entraînement, la généralisation et la complexité d’un modèle du type arbre de décision.\n",
        "2. Étudiez les principaux hyperparamètres de [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) qui peuvent aider à améliorer sa performance.\n",
        "3. Choisir quelques hyperparamètres (au moins 2) et tourner un \"grid search\" sur l'ensemble de validation pour trouver les meilleures valeurs pour ces hyperparamètres.\n",
        "\n",
        "- Astuce: Vous avez déjà un ensemble de validation! Alors, c'est préférable (beaucoup plus rapide!) d’utiliser la bibliothèque [hypopt](https://pypi.org/project/hypopt/) pour faire le réglage des hyperparamètres (grid seach)<br><br>\n",
        "\n",
        "4. Une fois que vous avez trouvé le meilleur modèle, utiliser ces modèles pour faire la prédiction sur tous les exemples (apprentissage, validation, test) et rapporter les résultats (comme fait dans le TP1):<br>\n",
        "4a. Rapport de classification produit avec *<font color=green>from sklearn.metrics import classification_report</font>*<br>\n",
        "4b. taux de classification correct sur les trois (3) ensembles de données (sous la forme d'un tableau)<br>\n",
        "4c. matrice de confusion produite avec *<font color=green> from sklearn.metrics import confusion_matrix</font>* pour les résultats sur l'ensemble de test (matrice 7 $\\times$ 7 - étiquétte $\\times$ prédictions)\n",
        "\n",
        "5. Sauvegarder votre modèle dans un fichier *.pkl*. Regarder [model persistence](https://scikit-learn.org/stable/model_persistence.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqaGIvxlfY0U"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FMbV36AfY0U"
      },
      "outputs": [],
      "source": [
        "# Votre code ici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-s_euFqfY0U"
      },
      "source": [
        "## 4b: Entraîner un arbre de décision avec les primitives locales\n",
        "###  <font color=blue> À faire: </font>\n",
        "1. Refaire les étapes 3 à 5 de 4a)\n",
        "2. Comparez les résultats avec ceux attendus avec les primitives globales et *template matching* (TP1)\n",
        "3. Faire une brève analyse des résultats et présenter vos considérations et conclusions sur la performance de vos primitives + modèles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjP2WGDlfY0U"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd2dgGiYfY0U"
      },
      "outputs": [],
      "source": [
        "# Votre code ici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa-CZDNnfY0U"
      },
      "source": [
        "#### Résultats et résponses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16ynw2bSfY0U"
      },
      "source": [
        "#### Vos répondes et résultats pour 4a) et 4b) ici:\n",
        "\n",
        "##### Exemple:\n",
        "\n",
        "Taux de classification (%)\n",
        "\n",
        "| Ensemble | modèle TM   |  AD+LBP Global  | AD+LBP Local  |                                 \n",
        "|----------|-------------|-----------------|---------------|\n",
        "| App      | 99,67       |                 |               |                   \n",
        "| Val      | 89,77       |                 |               |                             \n",
        "| Test     | 77,99       |                 |               |        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyrNyBH4fY0U"
      },
      "source": [
        "# Fin"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}