{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFjcQZekfQHv"
      },
      "source": [
        "# GTI771 - Apprentissage machine avancé\n",
        "## Département de génie logiciel et des technologies de l’information\n",
        "\n",
        "\n",
        "\n",
        "## Laboratoire 8 - Machine à vecteurs de support (SVM) et régresseur à vecteurs de support (SVR)\n",
        "#### <font color=black> Version 2 - Été 2024 </font>\n",
        "\n",
        "##### <font color=grey> Version 1 - Prof. Alessandro L. Koerich.\n",
        "##### Version 2 - Chargé de lab. Arthur Josi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWQOMVd9fQHx"
      },
      "source": [
        "| NOMS                  | CODE PERMANENT  |  PARTICIPATION     |\n",
        "|-----------------------|-----------------|--------------------|\n",
        "| Hugo Rhéaume-Simard   | RHEH93080004          |    33%            |\n",
        "| Laurent Marleau-Gallant             |  MARL05109800  |      33%            |\n",
        "| Yulia Bakaleinik             | BAKY30539705        |     33%            |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipp-5fVtfQHx"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Ce troisième laboratoire porte sur l’utilisation des machines à vecteurs de support (SVM) et régresseurs à vecteurs de support (SVR).\n",
        "\n",
        "Vous devez proposer des modèles de classification (SVM) et régression (SVR) afin de résoudre deux problèmes: prédiction de l'âge de personnes à partir de photos du visage (régression) (dataset FG-NET); prédiction des émotions à partir de photos du visage (classification) introduites dans le cadre des laboratoires précédents.\n",
        "\n",
        "Vous devrez utiliser les primitives développées aux laboratoires précedents et vous devrez étudier les hyperparamètres des SVMs et SVRs\n",
        "\n",
        "L’évaluation de ce laboratoire sera basée sur:\n",
        "- la qualité des SVMs et SVRs proposés et utilisés; (10%)\n",
        "- utilisation du protocole et mesures de performance appropriées; (10%)\n",
        "- les réponses aux questions dans ce notebook;(70%)\n",
        "- l'organisation de votre code source (SVP, n'oubliez pas de mettre des commentaires dans le code source!); (10%)\n",
        "\n",
        "\n",
        "Votre Jupyter notebook devra contenir les réponses aux questions. Il devra notamment avoir une analyse détaillée des résultats de classification obtenus par les différents modèles et leurs variations d’hyperparamètres."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU8-L5MlfQHy"
      },
      "source": [
        "# Modules et bibliotèques python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnZwMPCnfQHy"
      },
      "source": [
        "### Import de bibliotèques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0i3X99rfQHy"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "Ajouter les bibliothèques que vous avez utilisées pour compléter ce notebook dans une cellule avec une petite description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1PhBzaDvfQHz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.19.0\n",
            "['Module', '_HAS_OPS', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_image_backend', '_internally_replaced_utils', '_is_tracing', '_meta_registrations', '_utils', '_video_backend', 'datasets', 'disable_beta_transforms_warning', 'extension', 'get_image_backend', 'get_video_backend', 'io', 'models', 'ops', 'os', 'set_image_backend', 'set_video_backend', 'torch', 'transforms', 'utils', 'version', 'warnings']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np  # package for scientific computing with Python.\n",
        "import matplotlib.pyplot as plt # 2D plotting library\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import re \n",
        "import face_recognition\n",
        "import cv2\n",
        "from mtcnn import MTCNN\n",
        "\n",
        "import torchvision\n",
        "print(torchvision.__version__)\n",
        "print(dir(torchvision))\n",
        "\n",
        "from skimage import io, exposure, filters, transform, color\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score, top_k_accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgkQOcRmfQH0"
      },
      "source": [
        "### Définition des fonctions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3jO1zyCfQH0"
      },
      "outputs": [],
      "source": [
        "# Cette fonction ne fait rien. Elle ne reçoit aucune variable et retourne 1\n",
        "def fa():\n",
        "    return 1\n",
        "\n",
        "# Vos fonctions:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhpjI7DifQH0"
      },
      "source": [
        "# Partie 1: Classification avec machines à vecteurs de support (SVM)\n",
        "## (FER dataset)\n",
        "\n",
        "Dans cette partie vous devez explorer les <b> différents noyaux du SVM </b> disponibles dans la librarie LIBSVM ([Scikit-learn LibSVM](https://scikit-learn.org/stable/modules/svm.html)) (tels que linéaire, polynomial et RBF).\n",
        "\n",
        "Les machines à vecteurs de support (SVM) sont un ensemble de méthodes d'apprentissage supervisé utilisées pour la classification, la régression et la détection des valeurs aberrantes.\n",
        "\n",
        "Les avantages des machines à vecteurs de support sont:\n",
        "\n",
        "- Efficace dans les espaces de grande dimension.\n",
        "- Toujours efficace dans les cas où le nombre de dimensions est supérieur au nombre d'échantillons.\n",
        "- Utilise un sous-ensemble de points d'apprentissage dans la fonction de décision (appelés vecteurs de support), donc il est également efficace en mémoire.\n",
        "- Polyvalent: différentes fonctions du noyau peuvent être spécifiées pour la fonction de décision. Des noyaux communs sont fournis, mais il est également possible de spécifier des noyaux personnalisés.\n",
        "\n",
        "Les inconvénients des machines vectorielles de support incluent:\n",
        "\n",
        "- Si le nombre de primitives est bien supérieur au nombre d'échantillons, évitez de sur-ajuster dans le choix des fonctions du noyau et le terme de régularisation est crucial.\n",
        "- Les SVM ne fournissent pas directement d'estimations de probabilité, celles-ci sont calculées à l'aide d'une validation croisée coûteuse en cinq fois (voir scores et probabilités, dans [Scikit-learn LibSVM](https://scikit-learn.org/stable/modules/svm.html))\n",
        "\n",
        "Vous devez comparer la performance de ces algorithmes pour les ensemble FER (classification)\n",
        "\n",
        "<b>Attention! Important!</b> N’oubliez pas de normaliser les vecteurs (entrées) entre 0 et 1 ou -1 et +1. Les SVMs sont très sensibles aux données non-normalisées<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KIgOgJgfQH1"
      },
      "source": [
        "## 1a - Ensemble de données FER\n",
        "\n",
        "Point de départ: *fer2013-clean-deep.csv* ou *fer2013-clean-pre-deep.csv*\n",
        "\n",
        "###  <font color=blue> À faire: </font>\n",
        "1. Reprenez votre ensemble de données nettoyé et repérez les trois partitions de données: apprentissage, validation et test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-Kx25eifQH1"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "ferData = np.loadtxt( 'fer2013-clean-pre-deep.csv', delimiter=',', dtype=str )\n",
        "\n",
        "# Training vecteurs\n",
        "Xtrain = <à compléter>\n",
        "ytrain = <à compléter>\n",
        "\n",
        "# Validation vecteurs\n",
        "Xval = <à compléter>\n",
        "yval = <à compléter>\n",
        "\n",
        "# Test vecteurs\n",
        "Xtest = <à compléter>\n",
        "ytest = <à compléter>\n",
        "\n",
        "print(Xtrain.shape, Xval.shape, Xtest.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFs0X_rKfQH3"
      },
      "source": [
        "2. Utiliser [Scikit-learn LibSVM](https://scikit-learn.org/stable/modules/svm.html) pour construire des SVMs qui vous permettront d'apprendre à partir des vecteurs de primitives. Pour cette question, on construira deux modèles, un SVM linéaire et un deuxième modèle avec un noyau à libre choix (polynomial, RBF, sigmoidal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y8l4hRSwYVR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lj4EL0-weOI"
      },
      "source": [
        "3. Comprendre et présenter les différents hyperparamètres qui peuvent affecter l'entraînement, la généralisation et la complexité des modèles définis sur la base de vos lectures.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkMv4OWmGe5d"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_UtDdx1xaZZ"
      },
      "source": [
        "4. Entraîner et optimiser les paramètres des modèles SVM. Utiliser le protocole <font color=blue> \"hold-out\" </font>.\n",
        "- P. ex., pour un SVM linéaire, vous devez optimiser l'hyperparamètre ($C$) avec un grid search. Pour un SVM kernel polynomial vous devez optimiser l'ordre du polynôme ($d$ = 2, 3, etc.) et optimiser l'hyperparamètre ($C$) avec un un grid search ($C$, $d$). Pour un SVM kernel RBF vous devez optimiser les hyperparamètres ($C$ et $\\gamma$)<br>\n",
        "- <b>Astuce </b>: Vous avez déjà un ensemble de validation! Alors, c'est préférable (beaucoup plus rapide!) d’utiliser la librairie [hypopt](https://pypi.org/project/hypopt/) pour faire le réglage des hyperparamètres (grid seach). Comme bon nombre d'entres vous ont eu des problèmes avec la librairie la librairie [hypopt](https://pypi.org/project/hypopt/), n'hésiter pas à faire une validation croisée avec [scikit-Learn GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) qui par défaut fait un 5-CV sur l'ensemble donné (On donnera dans ce cas la base de donnée d'entraitement et de validation en tant qu'une seule base de données).<br><br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lbv9f18xaHp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV8dj2sfxlCq"
      },
      "source": [
        "5. Utiliser ces réseaux pour faire la prédiction sur tous les exemples (apprentissage, validation, test) et rapporter les résultats (comme fait dans les TP1 à TP6):<br>\n",
        "5a. Rapport de classification produit avec *<font color=green>from sklearn.metrics import classification_report</font>*<br>\n",
        "5b. taux de classification correct sur les trois (3) ensembles de données (sous la forme d'un tableau)<br>\n",
        "5c. matrice de confusion produite avec *<font color=green> from sklearn.metrics import confusion_matrix</font>* pour les résultats sur l'ensemble de test (matrice 7 $\\times$ 7 - étiquéttes $\\times$ prédictions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ErUjPCoyALv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUCdcQDYx_SQ"
      },
      "source": [
        "6. Comparez les résultats avec ceux obtenus avec les CNNs (TP6), MLPs (TP5), primitives « deep » réduits (TP4), les primitives « deep » (TP3), les primitives globales/locales (TP2) et *template matching* (TP1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyqOjtnCfQH3"
      },
      "source": [
        "| Ensemble |  TM   |  AD+LBP Glo | AD+LBP Loc | deep 1 | deep 2 | deep 1 $\\chi^2$ | deep 1 PCA | CNN 1 | CNN 2 | CNN Pré | SVM Lin | SVM RBF |                                  \n",
        "|----------|-------|-------------|------------|--------|--------|-----------------|------------|-------|-------|---------|----------|---------|\n",
        "| App      | 99,67 |             |            |        |        |                 |            |       |       |         |        | |             \n",
        "| Val      | 89,77 |             |            |        |        |                 |            |       |       |         |         | |\n",
        "| Test     | 77,99 |             |            |        |        |                 |            |       |       |         | | |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2txLBsMbyB4e"
      },
      "source": [
        "7. Faire une brève analyse des résultats et présenter vos considérations et conclusions sur la pertinence / advantages / désavantages des SVMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru8PuyV-yEuu"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuib7oyFfQH3"
      },
      "source": [
        "# Partie 2: Régression avec machines à vecteurs de support (SVR)\n",
        "## (FG-NET dataset)\n",
        "\n",
        "Dans cette partie vous devez explorer les <b> différents noyaux du SVR </b> disponibles dans la librarie LIBSVM ([Scikit-learn LibSVM](https://scikit-learn.org/stable/modules/svm.html)).\n",
        "Les régresseurs à vecteurs de support (SVR) sont un ensemble de méthodes d'apprentissage supervisé utilisées pour la régression.\n",
        "\n",
        "Les avantages des régresseurs à vecteurs de support sont:\n",
        "\n",
        "- Efficace dans les espaces de grande dimension.\n",
        "- Toujours efficace dans les cas où le nombre de dimensions est supérieur au nombre d'échantillons.\n",
        "- Utilise un sous-ensemble de points d'apprentissage dans la fonction de décision (appelés vecteurs de support), donc il est également efficace en mémoire.\n",
        "- Polyvalent: différentes fonctions du noyau peuvent être spécifiées pour la fonction de décision. Des noyaux communs sont fournis, mais il est également possible de spécifier des noyaux personnalisés.\n",
        "\n",
        "Les inconvénients des machines vectorielles de support incluent:\n",
        "\n",
        "- Si le nombre de primitives est bien supérieur au nombre d'échantillons, évitez de sur-ajuster dans le choix des fonctions du noyau et le terme de régularisation est crucial.\n",
        "\n",
        "Vous devez comparer la performance de ces algorithmes pour l'ensemble FG-NET (régression)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdwF4HTcfQH3"
      },
      "source": [
        "Point de départ: Jeu de primitives produites avec le CNN du TP5, *fg-net-12x12-deepVGG19.csv*.\n",
        "\n",
        "###  <font color=blue> À faire: </font>\n",
        "1. Reprenez votre vecteurs de primitives. Vous devez lire ces vecteurs et les représenter sous la forme d’une matrice $X\\_data$ aussi que les vecteurs $Y\\_data$ avec les âges et $Z\\_data$ avec les id des sujets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_TBzPnjkfQH5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fg-net:\t16384 features\n",
            "(1000, 16384)\n",
            "(1000, 16384)\n",
            "(1000,)\n",
            "(1000,)\n"
          ]
        }
      ],
      "source": [
        "# Votre code ici\n",
        "#data = np.loadtxt('fg-net-128x104.csv.csv', delimiter=',',dtype=str)\n",
        "data = np.loadtxt('content/fg-net-4x4x1024-restNET50v2.csv', delimiter=',',dtype=str)\n",
        "#data = np.loadtxt('content/fg-net-nxm.csv.csv', delimiter=',',dtype=str)\n",
        "\n",
        "\n",
        "def transform_str_float(d):\n",
        "    return np.array([np.fromstring(row, sep=' ', dtype=float) for row in d])\n",
        "\n",
        "x_data = transform_str_float(data[1:,2])\n",
        "y_data = np.array(data[1:,1], dtype=int)\n",
        "z_data = np.array(data[1:,0], dtype=int)\n",
        "\n",
        "print(f\"fg-net:\\t{x_data.shape[1]} features\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_data = x_data\n",
        "\n",
        "##Print shape of X_data\n",
        "print(X_data.shape)\n",
        "print(X_data.shape) \n",
        "\n",
        "##Print shape of y_data\n",
        "print(y_data.shape)\n",
        "\n",
        "##Print shape of z_data\n",
        "print(z_data.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsjJsL1_yz5t"
      },
      "source": [
        "2. Utiliser [Scikit-learn LibSVM](https://scikit-learn.org/stable/modules/svm.html) pour construire des SVRs qui vous permettront d'apprendre à partir des vecteurs de primitives. Pour cette question, on construira deux modèles, un SVM linéaire et un deuxième modèle avec un noyau que vous souhaitez (polynomial, RBF, sigmoidal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1iqBUnEdy_tn"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "#Creer modele linear \n",
        "svr_linear = SVR(kernel='linear', C=1e3,\n",
        "\n",
        "#Creer model noyau indeterminer\n",
        "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyAOBctsfQH5"
      },
      "source": [
        "\n",
        "3. Entraîner et optimiser les paramètres des modèles SVR. Utiliser le protocole <font color=blue> \"hold-out\" </font> comme lors du laboratoire précédent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wvAyYKtmzsqd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Meilleurs paramètres pour SVR linéaire : {'C': 0.1, 'epsilon': 0.1}\n",
            "Meilleurs paramètres pour SVR RBF : {'C': 1000.0, 'epsilon': 0.1, 'gamma': 1e-05}\n",
            "MSE pour le noyau linéaire : 87.90\n",
            "MSE pour le noyau RBF : 76.29\n",
            "MAE pour le noyau linéaire : 7.45\n",
            "MAE pour le noyau RBF : 6.89\n",
            "R2 pour le noyau linéaire : 0.50\n",
            "R2 pour le noyau RBF : 0.56\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Diviser les données en ensembles d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test, z_train, z_test = train_test_split(X_data, y_data, z_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Définir les grilles de paramètres pour les SVR linéaire et RBF\n",
        "param_grid_linear = {\n",
        "    'C': [1,0.1, 1e3],\n",
        "    'epsilon': [0.1, 1e-3, 1e-4]\n",
        "}\n",
        "\n",
        "param_grid_rbf = {\n",
        "    'C': [1, 0.1, 1e3],\n",
        "    'epsilon': [0.1, 1e-3, 1e-4],\n",
        "    'gamma': [0.1, 1e-3, 1e-4, 1e-5]\n",
        "}\n",
        "\n",
        "# Initialiser les modèles SVR\n",
        "svr_linear = SVR(kernel='linear')\n",
        "svr_rbf = SVR(kernel='rbf')\n",
        "\n",
        "# Utiliser GridSearchCV pour trouver les meilleurs paramètres avec validation croisée\n",
        "grid_search_linear = GridSearchCV(svr_linear, param_grid_linear, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search_rbf = GridSearchCV(svr_rbf, param_grid_rbf, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Entraîner les modèles avec GridSearchCV sur l'ensemble d'entraînement\n",
        "grid_search_linear.fit(X_train, y_train)\n",
        "grid_search_rbf.fit(X_train, y_train)\n",
        "\n",
        "# Meilleurs paramètres trouvés par GridSearchCV\n",
        "best_linear = grid_search_linear.best_estimator_\n",
        "best_rbf = grid_search_rbf.best_estimator_\n",
        "\n",
        "# Prédire avec les meilleurs modèles sur l'ensemble de test\n",
        "y_pred_linear = best_linear.predict(X_test)\n",
        "y_pred_rbf = best_rbf.predict(X_test)\n",
        "\n",
        "# Évaluer les performances des modèles sur l'ensemble de test\n",
        "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
        "mse_rbf = mean_squared_error(y_test, y_pred_rbf)\n",
        "mae_linear = mean_absolute_error(y_test, y_pred_linear)\n",
        "mae_rbf = mean_absolute_error(y_test, y_pred_rbf)\n",
        "r2_linear = r2_score(y_test, y_pred_linear)\n",
        "r2_rbf = r2_score(y_test, y_pred_rbf)\n",
        "\n",
        "print(f\"Meilleurs paramètres pour SVR linéaire : {grid_search_linear.best_params_}\")\n",
        "print(f\"Meilleurs paramètres pour SVR RBF : {grid_search_rbf.best_params_}\")\n",
        "print(f\"MSE pour le noyau linéaire : {mse_linear:.2f}\")\n",
        "print(f\"MSE pour le noyau RBF : {mse_rbf:.2f}\")\n",
        "print(f\"MAE pour le noyau linéaire : {mae_linear:.2f}\")\n",
        "print(f\"MAE pour le noyau RBF : {mae_rbf:.2f}\")\n",
        "print(f\"R2 pour le noyau linéaire : {r2_linear:.2f}\")\n",
        "print(f\"R2 pour le noyau RBF : {r2_rbf:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCqT3qCJzteD"
      },
      "source": [
        "\n",
        "5. Comparez les résultats en les ajoutant au tableau suivant avec ceux obtenus via CNNs (TP7), MLPs (TP6), et régression linéaire (TP5)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNwQTAthzxhd"
      },
      "source": [
        "| Algorithme            | Paramètres    |  MSE  |  MAE  | ????? |\n",
        "|-----------------------|---------------|-------|-------|-------|\n",
        "| Regr lineaire         | XXX.XX        |XXX.XX |XXX.XX |       |\n",
        "| Regr Ridge            | alpha = 0.1   |123.34 | 10.45 |       |\n",
        "| Regr Lasso            | XXX.XX        |XXX.XX |XXX.XX |       |\n",
        "| Regr ElasticNet       | XXX.XX        |XXX.XX |XXX.XX |       |\n",
        "| MLP 1                 | 512:100:100:1 |XXX.XX |XXX.XX |       |\n",
        "| MLP 2                 | 512:50:1      |XXX.XX |XXX.XX |       |\n",
        "| CNN 1                 | 512:100:100:1 |XXX.XX |XXX.XX |       |\n",
        "| CNN 2 (DA)            | 512:50:1      |XXX.XX |XXX.XX |       |\n",
        "| VGG16 (DA)            | 512:50:1      |XXX.XX |XXX.XX |       |\n",
        "| SVR linéaire       | C=1,e=3          | 10.45 |       |       |\n",
        "| SVR RBF            | C=256, e=2, g=0.5| XXX.XX| XXX.XX|       |         \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxV16Ipvzz3A"
      },
      "source": [
        "6. Faire une brève analyse des résultats et présenter vos considérations et conclusions sur la pertinence / advantages / désavantages des SVRs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYTR7OJKz2EH"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubGIDoJZfQH6"
      },
      "source": [
        "# Fin"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
