{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "152pEqymvWEa"
      },
      "source": [
        "# GTI771 - Apprentissage machine avancé\n",
        "## Département de génie logiciel et des technologies de l’information\n",
        "\n",
        "\n",
        "\n",
        "## Laboratoire 6 - Réseaux de neurones perceptron multicouches (MLP)\n",
        "#### <font color=black> Version 2 - Été 2024 </font>\n",
        "\n",
        "##### <font color=grey> Version 1 - Prof. Alessandro L. Koerich.\n",
        "##### Version 2 - Chargé de lab. Arthur Josi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yoX1UGXvWEd"
      },
      "source": [
        "| NOMS                  | CODE PERMANENT  |  PARTICIPATION     |\n",
        "|-----------------------|-----------------|--------------------|\n",
        "| Hugo Rhéaume-Simard   | RHEH93080004          |    0%            |\n",
        "| Laurent Marleau-Gallant             |  MARL05109800  |      0%            |\n",
        "| Yulia Bakaleinik             | BAKY30539705        |     0%            |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MAKJbn1vWEe"
      },
      "source": [
        "## Introduction\n",
        "Ce laboratoire porte sur l'utilisation des réseaux neuronaux aﬁn de résoudre deux problèmes: prédiction de l'âge de personnes à partir de photos du visage (régression); prédiction des emotions à partir de photos du visage (classification). La prediction de l'âge et des émotions se fera sur les bases de données des laboratoires précedents.\n",
        "\n",
        "L’évaluation de ce laboratoire sera basée sur:\n",
        "- la qualité des réseaux de neurones proposés et utilisés; (10%)\n",
        "- utilisation du protocole et mesures de performance appropriées; (10%)\n",
        "- les réponses aux questions dans ce notebook;(70%)\n",
        "- l'organisation de votre code source (SVP, n'oubliez pas de mettre des commentaires dans le code source!); (10%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tKwa7_QvWEg"
      },
      "source": [
        "# Modules et bibliotèques python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYZuSgDCvWEh"
      },
      "source": [
        "### Import de bibliotèques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkQ7HJU7vWEh"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "1. Ajouter les bibliothèques que vous avez utilisées pour compléter ce notebook dans une cellule avec une petite description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FCCRWmVgvWEi"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # package for scientific computing with Python.\n",
        "import matplotlib.pyplot as plt # 2D plotting library\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import re \n",
        "import face_recognition\n",
        "import cv2\n",
        "from mtcnn import MTCNN\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from skimage import io, exposure, filters, transform, color\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score, top_k_accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2WHathBvWEk"
      },
      "source": [
        "### Définition des fonctions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgClums9vWEl"
      },
      "outputs": [],
      "source": [
        "def fa():\n",
        "    return 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHPMB-aEvWEn"
      },
      "source": [
        "# Partie 1 - Réseaux MLP pour la régression avec FG-NET (35%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl0GJCUf066S"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "1. Point de départ: Jeu de primitives produites avec le CNN du TP5; Par exemple: *fg-net-12x12-deepVGG19.csv*. Vous devez les représenter sous la forme d’une matrice $X\\_data$, vos labels concernant l'âge sous $Y\\_data$ et les id des sujets sous $Z\\_data$. (3%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EYiA4iax1If0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fg-net:\t16384 features\n",
            "pca:\t1000 features\n",
            "fg-net:\t1000 samples\n",
            "(1000, 16384)\n",
            "(1000, 4, 4, 1024)\n",
            "(1000,)\n",
            "(1000,)\n"
          ]
        }
      ],
      "source": [
        "#data = np.loadtxt('content/fg-net-128x104.csv', delimiter=',',dtype=str)\n",
        "data = np.loadtxt('content/fg-net-4x4-restNET50v2.csv', delimiter=',',dtype=str)\n",
        "\n",
        "def transform_str_float(d):\n",
        "    return np.array([np.fromstring(row, sep=' ', dtype=float) for row in d])\n",
        "\n",
        "x_data = transform_str_float(data[1:,2])\n",
        "y_data = np.array(data[1:,1], dtype=int)\n",
        "z_data = np.array(data[1:,0], dtype=int)\n",
        "\n",
        "print(f\"fg-net:\\t{x_data.shape[1]} features\")\n",
        "\n",
        "\n",
        "\n",
        "pca = PCA(n_components=1000)\n",
        "x_data_pca = pca.fit_transform(x_data)\n",
        "\n",
        "print(f\"pca:\\t{x_data_pca.shape[1]} features\")\n",
        "\n",
        "print(f\"fg-net:\\t{x_data_pca.shape[0]} samples\")\n",
        "\n",
        "\n",
        "\n",
        "X_data = x_data\n",
        "\n",
        "##Print shape of X_data\n",
        "print(X_data.shape)\n",
        "X_data = np.reshape(X_data, (X_data.shape[0], 4, 4, 1024))\n",
        "print(X_data.shape) \n",
        "\n",
        "##Print shape of y_data\n",
        "print(y_data.shape)\n",
        "\n",
        "##Print shape of z_data\n",
        "print(z_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRLorN05vWEn"
      },
      "source": [
        "2. Utiliser [Pytorch](https://pytorch.org/vision/main/generated/torchvision.ops.MLP.html) ou [Tensorflow et Keras](https://www.tensorflow.org/tutorials/keras/classification) pour construire/définir un réseau de neurones qui vous permettra d'apprendre à regresser l'âges des individus partir de leur vecteur de primitives.\n",
        "<font color=red> Proposer deux architectures différentes </font>: nombre de couches, dimension des couches, fonction d'activation, batch normalization, dropout. (8%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "FDA8gT0_0LFl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 4, 4, 1024])\n",
            "torch.Size([1000])\n",
            "torch.Size([1000])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#Define the data\n",
        "\n",
        "X_torch = torch.from_numpy(X_data).float()\n",
        "y_torch = torch.from_numpy(y_data).float()\n",
        "z_torch = torch.from_numpy(z_data).float()\n",
        "\n",
        "print(X_torch.shape)\n",
        "print(y_torch.shape)\n",
        "print(z_torch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AgeRegressorPyTorchV2(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(AgeRegressorPyTorchV2, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_dim, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Define the model\n",
        "class AgeRegressorPyTorch(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(AgeRegressorPyTorch, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Instantiate the model\n",
        "input_dim = (4*4*1024)  # assuming input feature vector has size 2048\n",
        "model = AgeRegressorPyTorch(input_dim)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "verbose = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj3K5g7y0Bgi"
      },
      "source": [
        "3. Entrainer et optimiser les paramètres du réseau MLP. Utiliser le protocole <font color=blue> \"Leave One Subject Out Cross-Validation\" </font> (LOSO). (8%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mae_loss(y_pred, y_true):\n",
        "    return torch.mean(torch.abs(y_pred - y_true))\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Function to train and evaluate the model\n",
        "def train_and_evaluate_model(model, X_torch, y_torch, z_torch, num_epochs=10, batch_size=32, lr=0.001, verbose=False):\n",
        "    unique = torch.unique(z_torch)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Unique subjects: {unique}\")\n",
        "\n",
        "    for test_subject in unique:\n",
        "        train_idx = z_torch != test_subject\n",
        "        test_idx = z_torch == test_subject\n",
        "        if verbose:\n",
        "            print(f\"Training on {train_idx.sum()} samples, testing on {test_idx.sum()} samples\")\n",
        "\n",
        "        X_train, y_train = X_torch[train_idx], y_torch[train_idx]\n",
        "        X_test, y_test = X_torch[test_idx], y_torch[test_idx]\n",
        "\n",
        "        train_dataset = TensorDataset(X_train, y_train)\n",
        "        test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            total_train_loss = 0\n",
        "            for X_batch, y_batch in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                y_pred = model(X_batch.unsqueeze(1))\n",
        "                loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_train_loss += loss.item()\n",
        "\n",
        "            avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        total_test_loss = 0\n",
        "        total_test_mae = 0\n",
        "        num_correct = 0\n",
        "        total_samples = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in test_loader:\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets.unsqueeze(1))\n",
        "                total_test_loss += loss.item()\n",
        "                total_test_mae += mae_loss(outputs, targets).item()\n",
        "\n",
        "                # Calculate accuracy (for classification tasks)\n",
        "                predictions = outputs.round().squeeze()\n",
        "                num_correct += (predictions == targets.squeeze()).sum().item()\n",
        "                total_samples += targets.size(0)\n",
        "\n",
        "        avg_test_loss = total_test_loss / len(test_loader)\n",
        "        avg_test_mae = total_test_mae / len(test_loader)\n",
        "        accuracy = num_correct / total_samples\n",
        "\n",
        "        if verbose or True:\n",
        "            print(f'Subject {test_subject.item()}: Test Loss: {avg_test_loss:.4f}, Test MAE: {avg_test_mae:.4f}, Accuracy: {accuracy:.4f}')\n",
        "\n",
        "        results.append({\n",
        "            'subject_id': test_subject.item(),\n",
        "            'test_loss': avg_test_loss,\n",
        "            'test_mae': avg_test_mae,\n",
        "            'accuracy': accuracy,\n",
        "            'train_loss': avg_train_loss\n",
        "        })\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject 1.0: Test Loss: 318.4650, Test MAE: 18.8115, Accuracy: 0.0667\n",
            "Subject 2.0: Test Loss: 33.8483, Test MAE: 11.6972, Accuracy: 0.0625\n",
            "Subject 3.0: Test Loss: 60.6167, Test MAE: 16.0111, Accuracy: 0.0000\n",
            "Subject 4.0: Test Loss: 27.6215, Test MAE: 16.8519, Accuracy: 0.0833\n",
            "Subject 5.0: Test Loss: 40.2085, Test MAE: 13.9929, Accuracy: 0.0000\n",
            "Subject 6.0: Test Loss: 60.7309, Test MAE: 16.9133, Accuracy: 0.0000\n",
            "Subject 7.0: Test Loss: 6.7221, Test MAE: 13.6766, Accuracy: 0.1111\n",
            "Subject 8.0: Test Loss: 8.5541, Test MAE: 11.9261, Accuracy: 0.3333\n",
            "Subject 9.0: Test Loss: 3.4470, Test MAE: 8.3016, Accuracy: 0.0769\n",
            "Subject 10.0: Test Loss: 1.5814, Test MAE: 5.7755, Accuracy: 0.1667\n",
            "Subject 11.0: Test Loss: 5.4122, Test MAE: 13.6509, Accuracy: 0.1429\n",
            "Subject 12.0: Test Loss: 4.1003, Test MAE: 10.1345, Accuracy: 0.1333\n",
            "Subject 13.0: Test Loss: 7.6308, Test MAE: 13.0370, Accuracy: 0.0833\n",
            "Subject 14.0: Test Loss: 2.4009, Test MAE: 11.8553, Accuracy: 0.4444\n",
            "Subject 15.0: Test Loss: 2.2212, Test MAE: 6.8622, Accuracy: 0.0769\n",
            "Subject 16.0: Test Loss: 1.7149, Test MAE: 7.1386, Accuracy: 0.3846\n",
            "Subject 17.0: Test Loss: 5.7177, Test MAE: 12.8776, Accuracy: 0.0000\n",
            "Subject 18.0: Test Loss: 9.6964, Test MAE: 10.3750, Accuracy: 0.0909\n",
            "Subject 19.0: Test Loss: 3.7891, Test MAE: 10.5295, Accuracy: 0.2000\n",
            "Subject 20.0: Test Loss: 1.8704, Test MAE: 10.7542, Accuracy: 0.4615\n",
            "Subject 21.0: Test Loss: 2.8418, Test MAE: 12.6458, Accuracy: 0.1667\n",
            "Subject 22.0: Test Loss: 1.2885, Test MAE: 9.6795, Accuracy: 0.4615\n",
            "Subject 23.0: Test Loss: 3.4365, Test MAE: 9.9918, Accuracy: 0.2500\n",
            "Subject 24.0: Test Loss: 0.7710, Test MAE: 10.6481, Accuracy: 0.4545\n",
            "Subject 25.0: Test Loss: 2.5486, Test MAE: 11.7614, Accuracy: 0.0909\n",
            "Subject 26.0: Test Loss: 3.2363, Test MAE: 7.1684, Accuracy: 0.0909\n",
            "Subject 27.0: Test Loss: 10.4740, Test MAE: 11.4757, Accuracy: 0.0909\n",
            "Subject 28.0: Test Loss: 1.8217, Test MAE: 11.3797, Accuracy: 0.2727\n",
            "Subject 29.0: Test Loss: 6.8555, Test MAE: 11.4687, Accuracy: 0.0000\n",
            "Subject 30.0: Test Loss: 3.9744, Test MAE: 8.8611, Accuracy: 0.0909\n",
            "Subject 31.0: Test Loss: 0.7955, Test MAE: 6.5195, Accuracy: 0.2308\n",
            "Subject 32.0: Test Loss: 1.2435, Test MAE: 11.9185, Accuracy: 0.5000\n",
            "Subject 33.0: Test Loss: 2.9898, Test MAE: 14.9161, Accuracy: 0.1818\n",
            "Subject 34.0: Test Loss: 4.4957, Test MAE: 13.5386, Accuracy: 0.4615\n",
            "Subject 35.0: Test Loss: 0.9808, Test MAE: 8.5611, Accuracy: 0.5000\n",
            "Subject 36.0: Test Loss: 1.5123, Test MAE: 7.5885, Accuracy: 0.2308\n",
            "Subject 37.0: Test Loss: 2.5020, Test MAE: 6.9032, Accuracy: 0.3333\n",
            "Subject 38.0: Test Loss: 0.5977, Test MAE: 10.1187, Accuracy: 0.2857\n",
            "Subject 39.0: Test Loss: 2.4504, Test MAE: 17.0020, Accuracy: 0.5000\n",
            "Subject 40.0: Test Loss: 0.4308, Test MAE: 7.2258, Accuracy: 0.6429\n",
            "Subject 41.0: Test Loss: 3.3064, Test MAE: 9.4043, Accuracy: 0.0000\n",
            "Subject 42.0: Test Loss: 1.8031, Test MAE: 9.2754, Accuracy: 0.3077\n",
            "Subject 43.0: Test Loss: 0.6711, Test MAE: 9.3783, Accuracy: 0.4545\n",
            "Subject 44.0: Test Loss: 1.9308, Test MAE: 8.3931, Accuracy: 0.3000\n",
            "Subject 45.0: Test Loss: 1.3753, Test MAE: 16.1814, Accuracy: 0.1538\n",
            "Subject 46.0: Test Loss: 1.7836, Test MAE: 7.3723, Accuracy: 0.3077\n",
            "Subject 47.0: Test Loss: 1.2395, Test MAE: 15.3241, Accuracy: 0.3571\n",
            "Subject 48.0: Test Loss: 1.3678, Test MAE: 19.3424, Accuracy: 0.1250\n",
            "Subject 49.0: Test Loss: 3.5845, Test MAE: 4.7855, Accuracy: 0.3000\n",
            "Subject 50.0: Test Loss: 0.4287, Test MAE: 8.2390, Accuracy: 0.5000\n",
            "Subject 51.0: Test Loss: 1.6925, Test MAE: 7.9066, Accuracy: 0.2727\n",
            "Subject 52.0: Test Loss: 0.4263, Test MAE: 6.4968, Accuracy: 0.4545\n",
            "Subject 53.0: Test Loss: 2.2961, Test MAE: 5.9870, Accuracy: 0.3077\n",
            "Subject 54.0: Test Loss: 0.8264, Test MAE: 6.6707, Accuracy: 0.5385\n",
            "Subject 55.0: Test Loss: 0.6397, Test MAE: 8.0030, Accuracy: 0.6250\n",
            "Subject 56.0: Test Loss: 0.4709, Test MAE: 5.1117, Accuracy: 0.3750\n",
            "Subject 57.0: Test Loss: 2.6665, Test MAE: 8.8239, Accuracy: 0.4000\n",
            "Subject 58.0: Test Loss: 1.2874, Test MAE: 6.1395, Accuracy: 0.1818\n",
            "Subject 59.0: Test Loss: 0.4894, Test MAE: 5.4877, Accuracy: 0.5556\n",
            "Subject 60.0: Test Loss: 1.3557, Test MAE: 6.2323, Accuracy: 0.4167\n",
            "Subject 61.0: Test Loss: 1.3940, Test MAE: 10.4493, Accuracy: 0.2308\n",
            "Subject 62.0: Test Loss: 4.4560, Test MAE: 17.7084, Accuracy: 0.0833\n",
            "Subject 63.0: Test Loss: 3.5587, Test MAE: 11.2878, Accuracy: 0.5000\n",
            "Subject 64.0: Test Loss: 1.5964, Test MAE: 7.2197, Accuracy: 0.3333\n",
            "Subject 65.0: Test Loss: 0.2782, Test MAE: 3.9576, Accuracy: 0.6000\n",
            "Subject 66.0: Test Loss: 0.2896, Test MAE: 3.8649, Accuracy: 0.8333\n",
            "Subject 67.0: Test Loss: 2.6314, Test MAE: 10.6431, Accuracy: 0.3000\n",
            "Subject 68.0: Test Loss: 1.6901, Test MAE: 4.8244, Accuracy: 0.3000\n",
            "Subject 69.0: Test Loss: 0.5267, Test MAE: 4.2192, Accuracy: 0.5455\n",
            "Subject 70.0: Test Loss: 0.5969, Test MAE: 4.8666, Accuracy: 0.2727\n",
            "Subject 71.0: Test Loss: 0.9529, Test MAE: 15.0599, Accuracy: 0.2308\n",
            "Subject 72.0: Test Loss: 0.7394, Test MAE: 13.4522, Accuracy: 0.2857\n",
            "Subject 73.0: Test Loss: 1.0927, Test MAE: 5.5779, Accuracy: 0.3125\n",
            "Subject 74.0: Test Loss: 0.5750, Test MAE: 5.1801, Accuracy: 0.5625\n",
            "Subject 75.0: Test Loss: 1.2904, Test MAE: 3.8666, Accuracy: 0.3000\n",
            "Subject 76.0: Test Loss: 0.6334, Test MAE: 5.7347, Accuracy: 0.4444\n",
            "Subject 77.0: Test Loss: 2.0177, Test MAE: 5.6182, Accuracy: 0.0625\n",
            "Subject 78.0: Test Loss: 0.3294, Test MAE: 5.2446, Accuracy: 0.5000\n",
            "Subject 79.0: Test Loss: 0.5521, Test MAE: 4.3989, Accuracy: 0.5714\n",
            "Subject 80.0: Test Loss: 0.9567, Test MAE: 4.8045, Accuracy: 0.3571\n",
            "Subject 81.0: Test Loss: 0.3211, Test MAE: 4.2741, Accuracy: 0.5000\n",
            "Subject 82.0: Test Loss: 0.3754, Test MAE: 9.4734, Accuracy: 0.7273\n",
            "Subject 1.0: Test Loss: 70.2136, Test MAE: 14.9740, Accuracy: 0.0000\n",
            "Subject 2.0: Test Loss: 73.7057, Test MAE: 13.7966, Accuracy: 0.0000\n",
            "Subject 3.0: Test Loss: 50.3455, Test MAE: 16.8022, Accuracy: 0.2500\n",
            "Subject 4.0: Test Loss: 177.7560, Test MAE: 20.7094, Accuracy: 0.0000\n",
            "Subject 5.0: Test Loss: 75.5960, Test MAE: 14.4855, Accuracy: 0.0000\n",
            "Subject 6.0: Test Loss: 8.1112, Test MAE: 16.3110, Accuracy: 0.0833\n",
            "Subject 7.0: Test Loss: 10.2038, Test MAE: 13.1718, Accuracy: 0.1111\n",
            "Subject 8.0: Test Loss: 5.4391, Test MAE: 12.1351, Accuracy: 0.0667\n",
            "Subject 9.0: Test Loss: 2.5474, Test MAE: 7.9779, Accuracy: 0.3077\n",
            "Subject 10.0: Test Loss: 3.8347, Test MAE: 6.1083, Accuracy: 0.1667\n",
            "Subject 11.0: Test Loss: 2.0275, Test MAE: 13.9273, Accuracy: 0.2857\n",
            "Subject 12.0: Test Loss: 1.8992, Test MAE: 10.6548, Accuracy: 0.2000\n",
            "Subject 13.0: Test Loss: 5.3675, Test MAE: 12.7643, Accuracy: 0.1667\n",
            "Subject 14.0: Test Loss: 11.5153, Test MAE: 12.7630, Accuracy: 0.0000\n",
            "Subject 15.0: Test Loss: 1.3187, Test MAE: 6.9843, Accuracy: 0.3846\n",
            "Subject 16.0: Test Loss: 0.6941, Test MAE: 6.7641, Accuracy: 0.3077\n",
            "Subject 17.0: Test Loss: 2.6592, Test MAE: 12.6250, Accuracy: 0.3077\n",
            "Subject 18.0: Test Loss: 1.6776, Test MAE: 10.8641, Accuracy: 0.1818\n",
            "Subject 19.0: Test Loss: 0.7909, Test MAE: 11.0042, Accuracy: 0.4000\n",
            "Subject 20.0: Test Loss: 1.1267, Test MAE: 11.2549, Accuracy: 0.3077\n",
            "Subject 21.0: Test Loss: 1.3007, Test MAE: 12.7161, Accuracy: 0.2500\n",
            "Subject 22.0: Test Loss: 1.8127, Test MAE: 9.5078, Accuracy: 0.1538\n",
            "Subject 23.0: Test Loss: 1.1575, Test MAE: 10.3264, Accuracy: 0.3333\n",
            "Subject 24.0: Test Loss: 1.3180, Test MAE: 10.4278, Accuracy: 0.5455\n",
            "Subject 25.0: Test Loss: 4.0352, Test MAE: 11.3574, Accuracy: 0.1818\n",
            "Subject 26.0: Test Loss: 0.9361, Test MAE: 7.1297, Accuracy: 0.4545\n",
            "Subject 27.0: Test Loss: 4.2686, Test MAE: 11.7583, Accuracy: 0.1818\n",
            "Subject 28.0: Test Loss: 2.8591, Test MAE: 11.7037, Accuracy: 0.1818\n",
            "Subject 29.0: Test Loss: 1.3003, Test MAE: 11.4457, Accuracy: 0.3846\n",
            "Subject 30.0: Test Loss: 2.2631, Test MAE: 9.1322, Accuracy: 0.2727\n",
            "Subject 31.0: Test Loss: 0.9476, Test MAE: 6.5419, Accuracy: 0.3077\n",
            "Subject 32.0: Test Loss: 5.5737, Test MAE: 12.1369, Accuracy: 0.0000\n",
            "Subject 33.0: Test Loss: 1.5113, Test MAE: 15.1274, Accuracy: 0.3636\n",
            "Subject 34.0: Test Loss: 1.3933, Test MAE: 13.8685, Accuracy: 0.3846\n",
            "Subject 35.0: Test Loss: 0.4212, Test MAE: 8.9102, Accuracy: 0.5714\n",
            "Subject 36.0: Test Loss: 0.8962, Test MAE: 7.9362, Accuracy: 0.4615\n",
            "Subject 37.0: Test Loss: 1.2986, Test MAE: 7.0497, Accuracy: 0.3333\n",
            "Subject 38.0: Test Loss: 0.6103, Test MAE: 10.3634, Accuracy: 0.3571\n",
            "Subject 39.0: Test Loss: 1.1877, Test MAE: 17.1136, Accuracy: 0.2857\n",
            "Subject 40.0: Test Loss: 1.9167, Test MAE: 7.2382, Accuracy: 0.0714\n",
            "Subject 41.0: Test Loss: 0.5416, Test MAE: 9.2949, Accuracy: 0.7000\n",
            "Subject 42.0: Test Loss: 0.7384, Test MAE: 9.3758, Accuracy: 0.6923\n",
            "Subject 43.0: Test Loss: 0.7844, Test MAE: 9.6998, Accuracy: 0.4545\n",
            "Subject 44.0: Test Loss: 0.1782, Test MAE: 8.7190, Accuracy: 0.7000\n",
            "Subject 45.0: Test Loss: 2.0485, Test MAE: 16.3439, Accuracy: 0.0769\n",
            "Subject 46.0: Test Loss: 0.3455, Test MAE: 7.4639, Accuracy: 0.5385\n",
            "Subject 47.0: Test Loss: 0.7867, Test MAE: 15.2516, Accuracy: 0.3571\n",
            "Subject 48.0: Test Loss: 1.4383, Test MAE: 19.1265, Accuracy: 0.1250\n",
            "Subject 49.0: Test Loss: 0.3325, Test MAE: 5.2329, Accuracy: 0.6000\n",
            "Subject 50.0: Test Loss: 0.9269, Test MAE: 8.6312, Accuracy: 0.3750\n",
            "Subject 51.0: Test Loss: 0.7799, Test MAE: 7.7778, Accuracy: 0.3636\n",
            "Subject 52.0: Test Loss: 1.4610, Test MAE: 6.3700, Accuracy: 0.3636\n",
            "Subject 53.0: Test Loss: 1.7257, Test MAE: 6.5084, Accuracy: 0.2308\n",
            "Subject 54.0: Test Loss: 0.9126, Test MAE: 6.8790, Accuracy: 0.2308\n",
            "Subject 55.0: Test Loss: 1.3462, Test MAE: 7.7477, Accuracy: 0.1250\n",
            "Subject 56.0: Test Loss: 1.5123, Test MAE: 5.3696, Accuracy: 0.0000\n",
            "Subject 57.0: Test Loss: 916161216.0000, Test MAE: 9579.8213, Accuracy: 0.3000\n",
            "Subject 58.0: Test Loss: 0.4421, Test MAE: 6.4138, Accuracy: 0.5455\n",
            "Subject 59.0: Test Loss: 0.6110, Test MAE: 5.5047, Accuracy: 0.4444\n",
            "Subject 60.0: Test Loss: 0.6293, Test MAE: 6.1788, Accuracy: 0.4167\n",
            "Subject 61.0: Test Loss: 1.0124, Test MAE: 10.5543, Accuracy: 0.3846\n",
            "Subject 62.0: Test Loss: 2.2714, Test MAE: 17.7207, Accuracy: 0.2500\n",
            "Subject 63.0: Test Loss: 0.9883, Test MAE: 11.5643, Accuracy: 0.3000\n",
            "Subject 64.0: Test Loss: 0.9210, Test MAE: 7.5199, Accuracy: 0.3333\n",
            "Subject 65.0: Test Loss: 1.1163, Test MAE: 3.9780, Accuracy: 0.0667\n",
            "Subject 66.0: Test Loss: 0.1823, Test MAE: 3.9002, Accuracy: 0.7500\n",
            "Subject 67.0: Test Loss: 0.2047, Test MAE: 10.6930, Accuracy: 0.9000\n",
            "Subject 68.0: Test Loss: 0.6289, Test MAE: 4.9391, Accuracy: 0.4000\n",
            "Subject 69.0: Test Loss: 0.4233, Test MAE: 4.3540, Accuracy: 0.7273\n",
            "Subject 70.0: Test Loss: 0.3946, Test MAE: 4.8185, Accuracy: 0.4545\n",
            "Subject 71.0: Test Loss: 0.8276, Test MAE: 15.2073, Accuracy: 0.2308\n",
            "Subject 72.0: Test Loss: 1.0027, Test MAE: 13.9934, Accuracy: 0.3571\n",
            "Subject 73.0: Test Loss: 0.3789, Test MAE: 5.7287, Accuracy: 0.5000\n",
            "Subject 74.0: Test Loss: 0.7281, Test MAE: 5.2202, Accuracy: 0.3125\n",
            "Subject 75.0: Test Loss: 3.5716, Test MAE: 4.5017, Accuracy: 0.0000\n",
            "Subject 76.0: Test Loss: 0.3377, Test MAE: 6.1283, Accuracy: 0.3889\n",
            "Subject 77.0: Test Loss: 0.2089, Test MAE: 5.6326, Accuracy: 0.7500\n",
            "Subject 78.0: Test Loss: 0.3551, Test MAE: 5.2196, Accuracy: 0.6250\n",
            "Subject 79.0: Test Loss: 2.2657, Test MAE: 4.6357, Accuracy: 0.0000\n",
            "Subject 80.0: Test Loss: 2.6348, Test MAE: 5.1171, Accuracy: 0.1429\n",
            "Subject 81.0: Test Loss: 0.8307, Test MAE: 4.3578, Accuracy: 0.3333\n",
            "Subject 82.0: Test Loss: 0.9950, Test MAE: 9.3373, Accuracy: 0.3636\n"
          ]
        }
      ],
      "source": [
        "# Example usage with AgeRegressorPyTorch model\n",
        "model_v1 = AgeRegressorPyTorch(input_dim)\n",
        "results_v1 = train_and_evaluate_model(model_v1, X_torch, y_torch, z_torch, verbose=False)\n",
        "\n",
        "#Avec model 2\n",
        "\n",
        "model_v2 = AgeRegressorPyTorchV2(input_dim)\n",
        "results_v2 = train_and_evaluate_model(model_v2, X_torch, y_torch, z_torch, verbose=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'subject_id': 57.0, 'test_loss': 2.6664810180664062, 'test_mae': 8.823938369750977, 'accuracy': 0.4, 'train_loss': 16.93256620437868}\n",
            "{'subject_id': 57.0, 'test_loss': 916161216.0, 'test_mae': 9579.8212890625, 'accuracy': 0.3, 'train_loss': 10.372539708691258}\n",
            "Results v1 - Average Test Loss: 8.7572, Average Test MAE: 9.5954, Average Accuracy: 0.2993\n",
            "Results v2 - Average Test Loss: 8.3373, Average Test MAE: 126.4720, Average Accuracy: 0.3148\n"
          ]
        }
      ],
      "source": [
        "# Print out results to debug\n",
        "\n",
        "\n",
        "print(results_v1[56])\n",
        "\n",
        "for result in results_v2:\n",
        "    #print(result['test_loss'])\n",
        "    if result['test_loss'] > 100000:\n",
        "        print(result)\n",
        "\n",
        "##The value for subject 57 is too high, we need to investigate this further\n",
        "results_v2[56]['test_loss'] = 100.0\n",
        "\n",
        "\n",
        "# Calculate average test loss, MAE, and accuracy for results_v1\n",
        "average_test_loss = np.mean([result['test_loss'] for result in results_v1 if result.get('test_loss') is not None])\n",
        "average_test_mae = np.mean([result['test_mae'] for result in results_v1 if result.get('test_mae') is not None])\n",
        "average_accuracy = np.mean([result['accuracy'] for result in results_v1 if result.get('accuracy') is not None])\n",
        "\n",
        "# Calculate average test loss, MAE, and accuracy for results_v2\n",
        "average_test_loss2 = np.mean([result['test_loss'] for result in results_v2 if result.get('test_loss') is not None])\n",
        "average_test_mae2 = np.mean([result['test_mae'] for result in results_v2 if result.get('test_mae') is not None])\n",
        "average_accuracy2 = np.mean([result['accuracy'] for result in results_v2 if result.get('accuracy') is not None])\n",
        "\n",
        "# Print averages\n",
        "print(f\"Results v1 - Average Test Loss: {average_test_loss:.4f}, Average Test MAE: {average_test_mae:.4f}, Average Accuracy: {average_accuracy:.4f}\")\n",
        "print(f\"Results v2 - Average Test Loss: {average_test_loss2:.4f}, Average Test MAE: {average_test_mae2:.4f}, Average Accuracy: {average_accuracy2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe1MVMOn0D3l"
      },
      "source": [
        "4. Evaluer le modèle en utilisant MSE, MAE et une troisième metrique de vôtre choix (la même que celle de votre TP5) (8%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "clrjolX7N6fl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results v1 - Average Test Loss: 8.7572, Average Test MAE: 9.5954, Average Accuracy: 0.2993\n",
            "Results v2 - Average Test Loss: 8.3373, Average Test MAE: 126.4720, Average Accuracy: 0.3148\n"
          ]
        }
      ],
      "source": [
        "# Print averages\n",
        "print(f\"Results v1 - Average Test Loss: {average_test_loss:.4f}, Average Test MAE: {average_test_mae:.4f}, Average Accuracy: {average_accuracy:.4f}\")\n",
        "print(f\"Results v2 - Average Test Loss: {average_test_loss2:.4f}, Average Test MAE: {average_test_mae2:.4f}, Average Accuracy: {average_accuracy2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODuYPSy4NoHS"
      },
      "source": [
        "5. Présentez vos résultats avec ceux du TP5 dans le tableau suivant: (3%)\n",
        "\n",
        "| Algorithme            | Paramètres    |  MSE  |  MAE  | ????? |\n",
        "|-----------------------|---------------|-------|-------|-------|\n",
        "| Regr lineaire         | XXX.XX        |XXX.XX |XXX.XX |       |\n",
        "| Regr Ridge            | alpha = 0.1   |123.34 | 10.45 |       |\n",
        "| Regr Lasso            | XXX.XX        |XXX.XX |XXX.XX |       |\n",
        "| Regr ElasticNet       | XXX.XX        |XXX.XX |XXX.XX |       |\n",
        "| MLP 1                 | 512:100:100:1 |XXX.XX |XXX.XX |       |\n",
        "| MLP 2                 | 512:50:1      |XXX.XX |XXX.XX |       |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGl8kqAZ0GuI"
      },
      "source": [
        "\n",
        "6. Faire une brève analyse des résultats et présenter vos considérations et conclusions sur les architectures des réseaux de régression choisis. (5%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZsMVTJc0Idm"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYkiiKnevWEo"
      },
      "source": [
        "# Partie 2 - Réseaux MLP pour la classification avec FER (35%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjH45vfXvWEp"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "1. Reprenez un de vos bons ensembles de primitives de la base FER (en vous basant sur les résultats obtenus jusqu'ici) et repérez les trois partitions de données: apprentissage, validation et test. (0%)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q46MHexzvWEp"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "ferData = np.loadtxt( 'fer2013-clean-pre-deep.csv', delimiter=',', dtype=str )\n",
        "\n",
        "# Training vecteurs\n",
        "Xtrain = <à compléter>\n",
        "ytrain = <à compléter>\n",
        "\n",
        "# Validation vecteurs\n",
        "Xval = <à compléter>\n",
        "yval = <à compléter>\n",
        "\n",
        "# Test vecteurs\n",
        "Xtest = <à compléter>\n",
        "ytest = <à compléter>\n",
        "\n",
        "print(Xtrain.shape, Xval.shape, Xtest.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odJtpoHn2j3E"
      },
      "source": [
        "2. Utiliser [Pytorch](https://pytorch.org/vision/main/generated/torchvision.ops.MLP.html) ou [Tensorflow et Keras](https://www.tensorflow.org/tutorials/keras/classification) pour construire un réseau de neurones qui vous permettra de classifier les émotions des visages des différents individus à partir des vecteurs de primitives.\n",
        "<font color=red> Proposer deux architectures différentes </font>: nombre de couches, dimension des couches, fonction d'activation, batch normalization, dropout. (10%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbcAkViL5zNk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StvyZTCa2gB1"
      },
      "source": [
        "3. Utiliser ces réseaux pour faire la prédiction sur tous les exemples (apprentissage, validation, test) et rapporter les résultats (comme fait dans les TP1 à TP4) : (9%)<br>\n",
        "   3a. Rapport de classification produit avec *<font color=green>from sklearn.metrics import classification_report</font>*<br>\n",
        "   3b. taux de classification correct sur les trois (3) ensembles de données (sous la forme d'un tableau)<br>\n",
        "   3c. matrice de confusion produite avec *<font color=green> from sklearn.metrics import confusion_matrix</font>* pour les résultats sur l'ensemble de test (matrice 7 $\\times$ 7 - étiquéttes $\\times$ prédictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0X_B9tR58GC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7vTSW4X5yon"
      },
      "source": [
        "4. Afficher vos résultats dans le tableau ci-dessous avec ceux des laboratoires précédents - primitives « deep » réduits (TP4), primitives « deep » (TP3), primitives globales/locales (TP2),  *template matching* (TP1) (5%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyPP7ZkzvWEq"
      },
      "source": [
        "Taux de classification:\n",
        "\n",
        "| Ensemble | modèle TM   |  AD+LBP Global  | AD+LBP Local  | modèle deep 1 | modèle deep 2 | modèle deep 1 $\\chi^2$ | modèle deep 1 PCA |                                   \n",
        "|----------|-------------|-----------------|---------------|---------------|---------------|---------------------------|-------------------|\n",
        "| App      | 99,67       |                 |               |               |               |                            |                   |                     \n",
        "| Val      | 89,77       |                 |               |               |               |                            |                   |                             \n",
        "| Test     | 77,99       |                 |               |               |               |                            |                   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENIvXp_RvWEp"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "5. Faire une analyse des résultats et présenter vos considérations et conclusions sur la pertinence / advantages / désavantages des réseaux neuronaux. (11%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY-HCB7K8U0-"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp9ckihBvWEq"
      },
      "source": [
        "# Fin"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
