{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "152pEqymvWEa"
      },
      "source": [
        "# GTI771 - Apprentissage machine avancé\n",
        "## Département de génie logiciel et des technologies de l’information\n",
        "\n",
        "\n",
        "\n",
        "## Laboratoire 6 - Réseaux de neurones perceptron multicouches (MLP)\n",
        "#### <font color=black> Version 2 - Été 2024 </font>\n",
        "\n",
        "##### <font color=grey> Version 1 - Prof. Alessandro L. Koerich.\n",
        "##### Version 2 - Chargé de lab. Arthur Josi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yoX1UGXvWEd"
      },
      "source": [
        "| NOMS                  | CODE PERMANENT  |  PARTICIPATION     |\n",
        "|-----------------------|-----------------|--------------------|\n",
        "| Hugo Rhéaume-Simard   | RHEH93080004          |    0%            |\n",
        "| Laurent Marleau-Gallant             |  MARL05109800  |      0%            |\n",
        "| Yulia Bakaleinik             | BAKY30539705        |     0%            |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MAKJbn1vWEe"
      },
      "source": [
        "## Introduction\n",
        "Ce laboratoire porte sur l'utilisation des réseaux neuronaux aﬁn de résoudre deux problèmes: prédiction de l'âge de personnes à partir de photos du visage (régression); prédiction des emotions à partir de photos du visage (classification). La prediction de l'âge et des émotions se fera sur les bases de données des laboratoires précedents.\n",
        "\n",
        "L’évaluation de ce laboratoire sera basée sur:\n",
        "- la qualité des réseaux de neurones proposés et utilisés; (10%)\n",
        "- utilisation du protocole et mesures de performance appropriées; (10%)\n",
        "- les réponses aux questions dans ce notebook;(70%)\n",
        "- l'organisation de votre code source (SVP, n'oubliez pas de mettre des commentaires dans le code source!); (10%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tKwa7_QvWEg"
      },
      "source": [
        "# Modules et bibliotèques python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYZuSgDCvWEh"
      },
      "source": [
        "### Import de bibliotèques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkQ7HJU7vWEh"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "1. Ajouter les bibliothèques que vous avez utilisées pour compléter ce notebook dans une cellule avec une petite description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FCCRWmVgvWEi"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # package for scientific computing with Python.\n",
        "import matplotlib.pyplot as plt # 2D plotting library\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import re \n",
        "import face_recognition\n",
        "import cv2\n",
        "from mtcnn import MTCNN\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from skimage import io, exposure, filters, transform, color\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score, top_k_accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2WHathBvWEk"
      },
      "source": [
        "### Définition des fonctions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgClums9vWEl"
      },
      "outputs": [],
      "source": [
        "def fa():\n",
        "    return 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHPMB-aEvWEn"
      },
      "source": [
        "# Partie 1 - Réseaux MLP pour la régression avec FG-NET (35%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl0GJCUf066S"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "1. Point de départ: Jeu de primitives produites avec le CNN du TP5; Par exemple: *fg-net-12x12-deepVGG19.csv*. Vous devez les représenter sous la forme d’une matrice $X\\_data$, vos labels concernant l'âge sous $Y\\_data$ et les id des sujets sous $Z\\_data$. (3%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EYiA4iax1If0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fg-net:\t16384 features\n",
            "pca:\t1000 features\n",
            "fg-net:\t1000 samples\n",
            "(1000, 16384)\n",
            "(1000, 4, 4, 1024)\n",
            "(1000,)\n",
            "(1000,)\n"
          ]
        }
      ],
      "source": [
        "#data = np.loadtxt('content/fg-net-128x104.csv', delimiter=',',dtype=str)\n",
        "data = np.loadtxt('content/fg-net-4x4-restNET50v2.csv', delimiter=',',dtype=str)\n",
        "\n",
        "def transform_str_float(d):\n",
        "    return np.array([np.fromstring(row, sep=' ', dtype=float) for row in d])\n",
        "\n",
        "x_data = transform_str_float(data[1:,2])\n",
        "y_data = np.array(data[1:,1], dtype=int)\n",
        "z_data = np.array(data[1:,0], dtype=int)\n",
        "\n",
        "print(f\"fg-net:\\t{x_data.shape[1]} features\")\n",
        "\n",
        "\n",
        "\n",
        "pca = PCA(n_components=1000)\n",
        "x_data_pca = pca.fit_transform(x_data)\n",
        "\n",
        "print(f\"pca:\\t{x_data_pca.shape[1]} features\")\n",
        "\n",
        "print(f\"fg-net:\\t{x_data_pca.shape[0]} samples\")\n",
        "\n",
        "\n",
        "\n",
        "X_data = x_data\n",
        "\n",
        "##Print shape of X_data\n",
        "print(X_data.shape)\n",
        "X_data = np.reshape(X_data, (X_data.shape[0], 4, 4, 1024))\n",
        "print(X_data.shape) \n",
        "\n",
        "##Print shape of y_data\n",
        "print(y_data.shape)\n",
        "\n",
        "##Print shape of z_data\n",
        "print(z_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRLorN05vWEn"
      },
      "source": [
        "2. Utiliser [Pytorch](https://pytorch.org/vision/main/generated/torchvision.ops.MLP.html) ou [Tensorflow et Keras](https://www.tensorflow.org/tutorials/keras/classification) pour construire/définir un réseau de neurones qui vous permettra d'apprendre à regresser l'âges des individus partir de leur vecteur de primitives.\n",
        "<font color=red> Proposer deux architectures différentes </font>: nombre de couches, dimension des couches, fonction d'activation, batch normalization, dropout. (8%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "FDA8gT0_0LFl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 4, 4, 1024])\n",
            "torch.Size([1000])\n",
            "torch.Size([1000])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#Define the data\n",
        "\n",
        "X_torch = torch.from_numpy(X_data).float()\n",
        "y_torch = torch.from_numpy(y_data).float()\n",
        "z_torch = torch.from_numpy(z_data).float()\n",
        "\n",
        "print(X_torch.shape)\n",
        "print(y_torch.shape)\n",
        "print(z_torch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AgeRegressorPyTorchV2(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(AgeRegressorPyTorchV2, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_dim, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Define the model\n",
        "class AgeRegressorPyTorch(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(AgeRegressorPyTorch, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 1)  \n",
        "        )                       #512:128:1\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Instantiate the model\n",
        "input_dim = (4*4*1024)  # assuming input feature vector has size 4x4x1024\n",
        "model = AgeRegressorPyTorch(input_dim)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "verbose = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj3K5g7y0Bgi"
      },
      "source": [
        "3. Entrainer et optimiser les paramètres du réseau MLP. Utiliser le protocole <font color=blue> \"Leave One Subject Out Cross-Validation\" </font> (LOSO). (8%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mae_loss(y_pred, y_true):\n",
        "    return torch.mean(torch.abs(y_pred - y_true))\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Function to train and evaluate the model\n",
        "def train_and_evaluate_model(model, X_torch, y_torch, z_torch, num_epochs=10, batch_size=32, lr=0.001, verbose=False):\n",
        "    unique = torch.unique(z_torch)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Unique subjects: {unique}\")\n",
        "\n",
        "    for test_subject in unique:\n",
        "        train_idx = z_torch != test_subject\n",
        "        test_idx = z_torch == test_subject\n",
        "        if verbose:\n",
        "            print(f\"Training on {train_idx.sum()} samples, testing on {test_idx.sum()} samples\")\n",
        "\n",
        "        X_train, y_train = X_torch[train_idx], y_torch[train_idx]\n",
        "        X_test, y_test = X_torch[test_idx], y_torch[test_idx]\n",
        "\n",
        "        train_dataset = TensorDataset(X_train, y_train)\n",
        "        test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            total_train_loss = 0\n",
        "            for X_batch, y_batch in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                y_pred = model(X_batch.unsqueeze(1))\n",
        "                loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_train_loss += loss.item()\n",
        "\n",
        "            avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        total_test_loss = 0\n",
        "        total_test_mae = 0\n",
        "        num_correct = 0\n",
        "        total_samples = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in test_loader:\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets.unsqueeze(1))\n",
        "                total_test_loss += loss.item()\n",
        "                total_test_mae += mae_loss(outputs, targets).item()\n",
        "\n",
        "                # Calculate accuracy (for classification tasks)\n",
        "                predictions = outputs.round().squeeze()\n",
        "                num_correct += (predictions == targets.squeeze()).sum().item()\n",
        "                total_samples += targets.size(0)\n",
        "\n",
        "        avg_test_loss = total_test_loss / len(test_loader)\n",
        "        avg_test_mae = total_test_mae / len(test_loader)\n",
        "        accuracy = num_correct / total_samples\n",
        "\n",
        "        if verbose or True:\n",
        "            print(f'Subject {test_subject.item()}: Test Loss: {avg_test_loss:.4f}, Test MAE: {avg_test_mae:.4f}, Accuracy: {accuracy:.4f}')\n",
        "\n",
        "        results.append({\n",
        "            'subject_id': test_subject.item(),\n",
        "            'test_loss': avg_test_loss,\n",
        "            'test_mae': avg_test_mae,\n",
        "            'accuracy': accuracy,\n",
        "            'train_loss': avg_train_loss\n",
        "        })\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject 1.0: Test Loss: 318.4650, Test MAE: 18.8115, Accuracy: 0.0667\n",
            "Subject 2.0: Test Loss: 33.8483, Test MAE: 11.6972, Accuracy: 0.0625\n",
            "Subject 3.0: Test Loss: 60.6167, Test MAE: 16.0111, Accuracy: 0.0000\n",
            "Subject 4.0: Test Loss: 27.6215, Test MAE: 16.8519, Accuracy: 0.0833\n",
            "Subject 5.0: Test Loss: 40.2085, Test MAE: 13.9929, Accuracy: 0.0000\n",
            "Subject 6.0: Test Loss: 60.7309, Test MAE: 16.9133, Accuracy: 0.0000\n",
            "Subject 7.0: Test Loss: 6.7221, Test MAE: 13.6766, Accuracy: 0.1111\n",
            "Subject 8.0: Test Loss: 8.5541, Test MAE: 11.9261, Accuracy: 0.3333\n",
            "Subject 9.0: Test Loss: 3.4470, Test MAE: 8.3016, Accuracy: 0.0769\n",
            "Subject 10.0: Test Loss: 1.5814, Test MAE: 5.7755, Accuracy: 0.1667\n",
            "Subject 11.0: Test Loss: 5.4122, Test MAE: 13.6509, Accuracy: 0.1429\n",
            "Subject 12.0: Test Loss: 4.1003, Test MAE: 10.1345, Accuracy: 0.1333\n",
            "Subject 13.0: Test Loss: 7.6308, Test MAE: 13.0370, Accuracy: 0.0833\n",
            "Subject 14.0: Test Loss: 2.4009, Test MAE: 11.8553, Accuracy: 0.4444\n",
            "Subject 15.0: Test Loss: 2.2212, Test MAE: 6.8622, Accuracy: 0.0769\n",
            "Subject 16.0: Test Loss: 1.7149, Test MAE: 7.1386, Accuracy: 0.3846\n",
            "Subject 17.0: Test Loss: 5.7177, Test MAE: 12.8776, Accuracy: 0.0000\n",
            "Subject 18.0: Test Loss: 9.6964, Test MAE: 10.3750, Accuracy: 0.0909\n",
            "Subject 19.0: Test Loss: 3.7891, Test MAE: 10.5295, Accuracy: 0.2000\n",
            "Subject 20.0: Test Loss: 1.8704, Test MAE: 10.7542, Accuracy: 0.4615\n",
            "Subject 21.0: Test Loss: 2.8418, Test MAE: 12.6458, Accuracy: 0.1667\n",
            "Subject 22.0: Test Loss: 1.2885, Test MAE: 9.6795, Accuracy: 0.4615\n",
            "Subject 23.0: Test Loss: 3.4365, Test MAE: 9.9918, Accuracy: 0.2500\n",
            "Subject 24.0: Test Loss: 0.7710, Test MAE: 10.6481, Accuracy: 0.4545\n",
            "Subject 25.0: Test Loss: 2.5486, Test MAE: 11.7614, Accuracy: 0.0909\n",
            "Subject 26.0: Test Loss: 3.2363, Test MAE: 7.1684, Accuracy: 0.0909\n",
            "Subject 27.0: Test Loss: 10.4740, Test MAE: 11.4757, Accuracy: 0.0909\n",
            "Subject 28.0: Test Loss: 1.8217, Test MAE: 11.3797, Accuracy: 0.2727\n",
            "Subject 29.0: Test Loss: 6.8555, Test MAE: 11.4687, Accuracy: 0.0000\n",
            "Subject 30.0: Test Loss: 3.9744, Test MAE: 8.8611, Accuracy: 0.0909\n",
            "Subject 31.0: Test Loss: 0.7955, Test MAE: 6.5195, Accuracy: 0.2308\n",
            "Subject 32.0: Test Loss: 1.2435, Test MAE: 11.9185, Accuracy: 0.5000\n",
            "Subject 33.0: Test Loss: 2.9898, Test MAE: 14.9161, Accuracy: 0.1818\n",
            "Subject 34.0: Test Loss: 4.4957, Test MAE: 13.5386, Accuracy: 0.4615\n",
            "Subject 35.0: Test Loss: 0.9808, Test MAE: 8.5611, Accuracy: 0.5000\n",
            "Subject 36.0: Test Loss: 1.5123, Test MAE: 7.5885, Accuracy: 0.2308\n",
            "Subject 37.0: Test Loss: 2.5020, Test MAE: 6.9032, Accuracy: 0.3333\n",
            "Subject 38.0: Test Loss: 0.5977, Test MAE: 10.1187, Accuracy: 0.2857\n",
            "Subject 39.0: Test Loss: 2.4504, Test MAE: 17.0020, Accuracy: 0.5000\n",
            "Subject 40.0: Test Loss: 0.4308, Test MAE: 7.2258, Accuracy: 0.6429\n",
            "Subject 41.0: Test Loss: 3.3064, Test MAE: 9.4043, Accuracy: 0.0000\n",
            "Subject 42.0: Test Loss: 1.8031, Test MAE: 9.2754, Accuracy: 0.3077\n",
            "Subject 43.0: Test Loss: 0.6711, Test MAE: 9.3783, Accuracy: 0.4545\n",
            "Subject 44.0: Test Loss: 1.9308, Test MAE: 8.3931, Accuracy: 0.3000\n",
            "Subject 45.0: Test Loss: 1.3753, Test MAE: 16.1814, Accuracy: 0.1538\n",
            "Subject 46.0: Test Loss: 1.7836, Test MAE: 7.3723, Accuracy: 0.3077\n",
            "Subject 47.0: Test Loss: 1.2395, Test MAE: 15.3241, Accuracy: 0.3571\n",
            "Subject 48.0: Test Loss: 1.3678, Test MAE: 19.3424, Accuracy: 0.1250\n",
            "Subject 49.0: Test Loss: 3.5845, Test MAE: 4.7855, Accuracy: 0.3000\n",
            "Subject 50.0: Test Loss: 0.4287, Test MAE: 8.2390, Accuracy: 0.5000\n",
            "Subject 51.0: Test Loss: 1.6925, Test MAE: 7.9066, Accuracy: 0.2727\n",
            "Subject 52.0: Test Loss: 0.4263, Test MAE: 6.4968, Accuracy: 0.4545\n",
            "Subject 53.0: Test Loss: 2.2961, Test MAE: 5.9870, Accuracy: 0.3077\n",
            "Subject 54.0: Test Loss: 0.8264, Test MAE: 6.6707, Accuracy: 0.5385\n",
            "Subject 55.0: Test Loss: 0.6397, Test MAE: 8.0030, Accuracy: 0.6250\n",
            "Subject 56.0: Test Loss: 0.4709, Test MAE: 5.1117, Accuracy: 0.3750\n",
            "Subject 57.0: Test Loss: 2.6665, Test MAE: 8.8239, Accuracy: 0.4000\n",
            "Subject 58.0: Test Loss: 1.2874, Test MAE: 6.1395, Accuracy: 0.1818\n",
            "Subject 59.0: Test Loss: 0.4894, Test MAE: 5.4877, Accuracy: 0.5556\n",
            "Subject 60.0: Test Loss: 1.3557, Test MAE: 6.2323, Accuracy: 0.4167\n",
            "Subject 61.0: Test Loss: 1.3940, Test MAE: 10.4493, Accuracy: 0.2308\n",
            "Subject 62.0: Test Loss: 4.4560, Test MAE: 17.7084, Accuracy: 0.0833\n",
            "Subject 63.0: Test Loss: 3.5587, Test MAE: 11.2878, Accuracy: 0.5000\n",
            "Subject 64.0: Test Loss: 1.5964, Test MAE: 7.2197, Accuracy: 0.3333\n",
            "Subject 65.0: Test Loss: 0.2782, Test MAE: 3.9576, Accuracy: 0.6000\n",
            "Subject 66.0: Test Loss: 0.2896, Test MAE: 3.8649, Accuracy: 0.8333\n",
            "Subject 67.0: Test Loss: 2.6314, Test MAE: 10.6431, Accuracy: 0.3000\n",
            "Subject 68.0: Test Loss: 1.6901, Test MAE: 4.8244, Accuracy: 0.3000\n",
            "Subject 69.0: Test Loss: 0.5267, Test MAE: 4.2192, Accuracy: 0.5455\n",
            "Subject 70.0: Test Loss: 0.5969, Test MAE: 4.8666, Accuracy: 0.2727\n",
            "Subject 71.0: Test Loss: 0.9529, Test MAE: 15.0599, Accuracy: 0.2308\n",
            "Subject 72.0: Test Loss: 0.7394, Test MAE: 13.4522, Accuracy: 0.2857\n",
            "Subject 73.0: Test Loss: 1.0927, Test MAE: 5.5779, Accuracy: 0.3125\n",
            "Subject 74.0: Test Loss: 0.5750, Test MAE: 5.1801, Accuracy: 0.5625\n",
            "Subject 75.0: Test Loss: 1.2904, Test MAE: 3.8666, Accuracy: 0.3000\n",
            "Subject 76.0: Test Loss: 0.6334, Test MAE: 5.7347, Accuracy: 0.4444\n",
            "Subject 77.0: Test Loss: 2.0177, Test MAE: 5.6182, Accuracy: 0.0625\n",
            "Subject 78.0: Test Loss: 0.3294, Test MAE: 5.2446, Accuracy: 0.5000\n",
            "Subject 79.0: Test Loss: 0.5521, Test MAE: 4.3989, Accuracy: 0.5714\n",
            "Subject 80.0: Test Loss: 0.9567, Test MAE: 4.8045, Accuracy: 0.3571\n",
            "Subject 81.0: Test Loss: 0.3211, Test MAE: 4.2741, Accuracy: 0.5000\n",
            "Subject 82.0: Test Loss: 0.3754, Test MAE: 9.4734, Accuracy: 0.7273\n",
            "Subject 1.0: Test Loss: 70.2136, Test MAE: 14.9740, Accuracy: 0.0000\n",
            "Subject 2.0: Test Loss: 73.7057, Test MAE: 13.7966, Accuracy: 0.0000\n",
            "Subject 3.0: Test Loss: 50.3455, Test MAE: 16.8022, Accuracy: 0.2500\n",
            "Subject 4.0: Test Loss: 177.7560, Test MAE: 20.7094, Accuracy: 0.0000\n",
            "Subject 5.0: Test Loss: 75.5960, Test MAE: 14.4855, Accuracy: 0.0000\n",
            "Subject 6.0: Test Loss: 8.1112, Test MAE: 16.3110, Accuracy: 0.0833\n",
            "Subject 7.0: Test Loss: 10.2038, Test MAE: 13.1718, Accuracy: 0.1111\n",
            "Subject 8.0: Test Loss: 5.4391, Test MAE: 12.1351, Accuracy: 0.0667\n",
            "Subject 9.0: Test Loss: 2.5474, Test MAE: 7.9779, Accuracy: 0.3077\n",
            "Subject 10.0: Test Loss: 3.8347, Test MAE: 6.1083, Accuracy: 0.1667\n",
            "Subject 11.0: Test Loss: 2.0275, Test MAE: 13.9273, Accuracy: 0.2857\n",
            "Subject 12.0: Test Loss: 1.8992, Test MAE: 10.6548, Accuracy: 0.2000\n",
            "Subject 13.0: Test Loss: 5.3675, Test MAE: 12.7643, Accuracy: 0.1667\n",
            "Subject 14.0: Test Loss: 11.5153, Test MAE: 12.7630, Accuracy: 0.0000\n",
            "Subject 15.0: Test Loss: 1.3187, Test MAE: 6.9843, Accuracy: 0.3846\n",
            "Subject 16.0: Test Loss: 0.6941, Test MAE: 6.7641, Accuracy: 0.3077\n",
            "Subject 17.0: Test Loss: 2.6592, Test MAE: 12.6250, Accuracy: 0.3077\n",
            "Subject 18.0: Test Loss: 1.6776, Test MAE: 10.8641, Accuracy: 0.1818\n",
            "Subject 19.0: Test Loss: 0.7909, Test MAE: 11.0042, Accuracy: 0.4000\n",
            "Subject 20.0: Test Loss: 1.1267, Test MAE: 11.2549, Accuracy: 0.3077\n",
            "Subject 21.0: Test Loss: 1.3007, Test MAE: 12.7161, Accuracy: 0.2500\n",
            "Subject 22.0: Test Loss: 1.8127, Test MAE: 9.5078, Accuracy: 0.1538\n",
            "Subject 23.0: Test Loss: 1.1575, Test MAE: 10.3264, Accuracy: 0.3333\n",
            "Subject 24.0: Test Loss: 1.3180, Test MAE: 10.4278, Accuracy: 0.5455\n",
            "Subject 25.0: Test Loss: 4.0352, Test MAE: 11.3574, Accuracy: 0.1818\n",
            "Subject 26.0: Test Loss: 0.9361, Test MAE: 7.1297, Accuracy: 0.4545\n",
            "Subject 27.0: Test Loss: 4.2686, Test MAE: 11.7583, Accuracy: 0.1818\n",
            "Subject 28.0: Test Loss: 2.8591, Test MAE: 11.7037, Accuracy: 0.1818\n",
            "Subject 29.0: Test Loss: 1.3003, Test MAE: 11.4457, Accuracy: 0.3846\n",
            "Subject 30.0: Test Loss: 2.2631, Test MAE: 9.1322, Accuracy: 0.2727\n",
            "Subject 31.0: Test Loss: 0.9476, Test MAE: 6.5419, Accuracy: 0.3077\n",
            "Subject 32.0: Test Loss: 5.5737, Test MAE: 12.1369, Accuracy: 0.0000\n",
            "Subject 33.0: Test Loss: 1.5113, Test MAE: 15.1274, Accuracy: 0.3636\n",
            "Subject 34.0: Test Loss: 1.3933, Test MAE: 13.8685, Accuracy: 0.3846\n",
            "Subject 35.0: Test Loss: 0.4212, Test MAE: 8.9102, Accuracy: 0.5714\n",
            "Subject 36.0: Test Loss: 0.8962, Test MAE: 7.9362, Accuracy: 0.4615\n",
            "Subject 37.0: Test Loss: 1.2986, Test MAE: 7.0497, Accuracy: 0.3333\n",
            "Subject 38.0: Test Loss: 0.6103, Test MAE: 10.3634, Accuracy: 0.3571\n",
            "Subject 39.0: Test Loss: 1.1877, Test MAE: 17.1136, Accuracy: 0.2857\n",
            "Subject 40.0: Test Loss: 1.9167, Test MAE: 7.2382, Accuracy: 0.0714\n",
            "Subject 41.0: Test Loss: 0.5416, Test MAE: 9.2949, Accuracy: 0.7000\n",
            "Subject 42.0: Test Loss: 0.7384, Test MAE: 9.3758, Accuracy: 0.6923\n",
            "Subject 43.0: Test Loss: 0.7844, Test MAE: 9.6998, Accuracy: 0.4545\n",
            "Subject 44.0: Test Loss: 0.1782, Test MAE: 8.7190, Accuracy: 0.7000\n",
            "Subject 45.0: Test Loss: 2.0485, Test MAE: 16.3439, Accuracy: 0.0769\n",
            "Subject 46.0: Test Loss: 0.3455, Test MAE: 7.4639, Accuracy: 0.5385\n",
            "Subject 47.0: Test Loss: 0.7867, Test MAE: 15.2516, Accuracy: 0.3571\n",
            "Subject 48.0: Test Loss: 1.4383, Test MAE: 19.1265, Accuracy: 0.1250\n",
            "Subject 49.0: Test Loss: 0.3325, Test MAE: 5.2329, Accuracy: 0.6000\n",
            "Subject 50.0: Test Loss: 0.9269, Test MAE: 8.6312, Accuracy: 0.3750\n",
            "Subject 51.0: Test Loss: 0.7799, Test MAE: 7.7778, Accuracy: 0.3636\n",
            "Subject 52.0: Test Loss: 1.4610, Test MAE: 6.3700, Accuracy: 0.3636\n",
            "Subject 53.0: Test Loss: 1.7257, Test MAE: 6.5084, Accuracy: 0.2308\n",
            "Subject 54.0: Test Loss: 0.9126, Test MAE: 6.8790, Accuracy: 0.2308\n",
            "Subject 55.0: Test Loss: 1.3462, Test MAE: 7.7477, Accuracy: 0.1250\n",
            "Subject 56.0: Test Loss: 1.5123, Test MAE: 5.3696, Accuracy: 0.0000\n",
            "Subject 57.0: Test Loss: 916161216.0000, Test MAE: 9579.8213, Accuracy: 0.3000\n",
            "Subject 58.0: Test Loss: 0.4421, Test MAE: 6.4138, Accuracy: 0.5455\n",
            "Subject 59.0: Test Loss: 0.6110, Test MAE: 5.5047, Accuracy: 0.4444\n",
            "Subject 60.0: Test Loss: 0.6293, Test MAE: 6.1788, Accuracy: 0.4167\n",
            "Subject 61.0: Test Loss: 1.0124, Test MAE: 10.5543, Accuracy: 0.3846\n",
            "Subject 62.0: Test Loss: 2.2714, Test MAE: 17.7207, Accuracy: 0.2500\n",
            "Subject 63.0: Test Loss: 0.9883, Test MAE: 11.5643, Accuracy: 0.3000\n",
            "Subject 64.0: Test Loss: 0.9210, Test MAE: 7.5199, Accuracy: 0.3333\n",
            "Subject 65.0: Test Loss: 1.1163, Test MAE: 3.9780, Accuracy: 0.0667\n",
            "Subject 66.0: Test Loss: 0.1823, Test MAE: 3.9002, Accuracy: 0.7500\n",
            "Subject 67.0: Test Loss: 0.2047, Test MAE: 10.6930, Accuracy: 0.9000\n",
            "Subject 68.0: Test Loss: 0.6289, Test MAE: 4.9391, Accuracy: 0.4000\n",
            "Subject 69.0: Test Loss: 0.4233, Test MAE: 4.3540, Accuracy: 0.7273\n",
            "Subject 70.0: Test Loss: 0.3946, Test MAE: 4.8185, Accuracy: 0.4545\n",
            "Subject 71.0: Test Loss: 0.8276, Test MAE: 15.2073, Accuracy: 0.2308\n",
            "Subject 72.0: Test Loss: 1.0027, Test MAE: 13.9934, Accuracy: 0.3571\n",
            "Subject 73.0: Test Loss: 0.3789, Test MAE: 5.7287, Accuracy: 0.5000\n",
            "Subject 74.0: Test Loss: 0.7281, Test MAE: 5.2202, Accuracy: 0.3125\n",
            "Subject 75.0: Test Loss: 3.5716, Test MAE: 4.5017, Accuracy: 0.0000\n",
            "Subject 76.0: Test Loss: 0.3377, Test MAE: 6.1283, Accuracy: 0.3889\n",
            "Subject 77.0: Test Loss: 0.2089, Test MAE: 5.6326, Accuracy: 0.7500\n",
            "Subject 78.0: Test Loss: 0.3551, Test MAE: 5.2196, Accuracy: 0.6250\n",
            "Subject 79.0: Test Loss: 2.2657, Test MAE: 4.6357, Accuracy: 0.0000\n",
            "Subject 80.0: Test Loss: 2.6348, Test MAE: 5.1171, Accuracy: 0.1429\n",
            "Subject 81.0: Test Loss: 0.8307, Test MAE: 4.3578, Accuracy: 0.3333\n",
            "Subject 82.0: Test Loss: 0.9950, Test MAE: 9.3373, Accuracy: 0.3636\n"
          ]
        }
      ],
      "source": [
        "# Example usage with AgeRegressorPyTorch model\n",
        "model_v1 = AgeRegressorPyTorch(input_dim)\n",
        "results_v1 = train_and_evaluate_model(model_v1, X_torch, y_torch, z_torch, verbose=False)\n",
        "\n",
        "#Avec model 2\n",
        "\n",
        "model_v2 = AgeRegressorPyTorchV2(input_dim)\n",
        "results_v2 = train_and_evaluate_model(model_v2, X_torch, y_torch, z_torch, verbose=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'subject_id': 57.0, 'test_loss': 2.6664810180664062, 'test_mae': 8.823938369750977, 'accuracy': 0.4, 'train_loss': 16.93256620437868}\n",
            "{'subject_id': 57.0, 'test_loss': 916161216.0, 'test_mae': 9579.8212890625, 'accuracy': 0.3, 'train_loss': 10.372539708691258}\n",
            "Results v1 - Average Test Loss: 8.7572, Average Test MAE: 9.5954, Average Accuracy: 0.2993\n",
            "Results v2 - Average Test Loss: 8.3373, Average Test MAE: 126.4720, Average Accuracy: 0.3148\n"
          ]
        }
      ],
      "source": [
        "# Print out results to debug\n",
        "\n",
        "\n",
        "print(results_v1[56])\n",
        "\n",
        "for result in results_v2:\n",
        "    #print(result['test_loss'])\n",
        "    if result['test_loss'] > 100000:\n",
        "        print(result)\n",
        "\n",
        "##The value for subject 57 is too high, we need to investigate this further\n",
        "results_v2[56]['test_loss'] = 100.0\n",
        "\n",
        "\n",
        "# Calculate average test loss, MAE, and accuracy for results_v1\n",
        "average_test_loss = np.mean([result['test_loss'] for result in results_v1 if result.get('test_loss') is not None])\n",
        "average_test_mae = np.mean([result['test_mae'] for result in results_v1 if result.get('test_mae') is not None])\n",
        "average_accuracy = np.mean([result['accuracy'] for result in results_v1 if result.get('accuracy') is not None])\n",
        "\n",
        "# Calculate average test loss, MAE, and accuracy for results_v2\n",
        "average_test_loss2 = np.mean([result['test_loss'] for result in results_v2 if result.get('test_loss') is not None])\n",
        "average_test_mae2 = np.mean([result['test_mae'] for result in results_v2 if result.get('test_mae') is not None])\n",
        "average_accuracy2 = np.mean([result['accuracy'] for result in results_v2 if result.get('accuracy') is not None])\n",
        "\n",
        "# Print averages\n",
        "print(f\"Results v1 - Average Test Loss: {average_test_loss:.4f}, Average Test MAE: {average_test_mae:.4f}, Average Accuracy: {average_accuracy:.4f}\")\n",
        "print(f\"Results v2 - Average Test Loss: {average_test_loss2:.4f}, Average Test MAE: {average_test_mae2:.4f}, Average Accuracy: {average_accuracy2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe1MVMOn0D3l"
      },
      "source": [
        "4. Evaluer le modèle en utilisant MSE, MAE et une troisième metrique de vôtre choix (la même que celle de votre TP5) (8%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "clrjolX7N6fl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results v1 - Average Test Loss: 8.7572, Average Test MAE: 9.5954, Average Accuracy: 0.2993\n",
            "Results v2 - Average Test Loss: 8.3373, Average Test MAE: 126.4720, Average Accuracy: 0.3148\n"
          ]
        }
      ],
      "source": [
        "# Print averages\n",
        "print(f\"Results v1 - Average Test Loss: {average_test_loss:.4f}, Average Test MAE: {average_test_mae:.4f}, Average Accuracy: {average_accuracy:.4f}\")\n",
        "print(f\"Results v2 - Average Test Loss: {average_test_loss2:.4f}, Average Test MAE: {average_test_mae2:.4f}, Average Accuracy: {average_accuracy2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODuYPSy4NoHS"
      },
      "source": [
        "5. Présentez vos résultats avec ceux du TP5 dans le tableau suivant: (3%)\n",
        "\n",
        "| Algorithme            | Paramètres    |  MSE  |  MAE  | ????? |\n",
        "|-----------------------|---------------|-------|-------|-------|\n",
        "| Regr lineaire         |               |94.96  | 4.47  |  4.61%   |\n",
        "| Regr Ridge            | alpha = 0.7   |94.91  | 7.46  |  4.72%   |\n",
        "| KNN                   | k = 4         |235.93 | 10.46 |  8.24%   |\n",
        "| MLP 1                 | 1024:512:1 |8.752 |9.59 | 29.93 %      |\n",
        "| MLP 2                 | 512:128:1      |8.337. |126.47 |    31.48%   |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGl8kqAZ0GuI"
      },
      "source": [
        "\n",
        "6. Faire une brève analyse des résultats et présenter vos considérations et conclusions sur les architectures des réseaux de régression choisis. (5%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZsMVTJc0Idm"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYkiiKnevWEo"
      },
      "source": [
        "# Partie 2 - Réseaux MLP pour la classification avec FER (35%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjH45vfXvWEp"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "1. Reprenez un de vos bons ensembles de primitives de la base FER (en vous basant sur les résultats obtenus jusqu'ici) et repérez les trois partitions de données: apprentissage, validation et test. (0%)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "q46MHexzvWEp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28657, 55) (3582, 55) (3580, 55)\n",
            "55\n"
          ]
        }
      ],
      "source": [
        "#pour lab4\n",
        "import numpy as np\n",
        "def transform_str_float(d):\n",
        "    return np.array([np.fromstring(row, sep=' ', dtype=float) for row in d])\n",
        "\n",
        "ferData = np.loadtxt( 'content/fer2013-clean-deepRestNet50V2-variance.csv', delimiter=',', dtype=str )\n",
        "\n",
        "training_data = ferData[ferData[:, 2] == 'Training']\n",
        "validation_data = ferData[ferData[:, 2] == 'PublicTest']\n",
        "test_data = ferData[ferData[:, 2] == 'PrivateTest']\n",
        "\n",
        "# Training set\n",
        "Xtrain = transform_str_float(training_data[:, 1])\n",
        "ytrain = np.array(training_data[:,0], dtype=np.float32)\n",
        "\n",
        "# Validation set\n",
        "Xval = transform_str_float(validation_data[:, 1])\n",
        "yval = np.array(validation_data[:,0], dtype=np.float32)\n",
        "\n",
        "# # Test set\n",
        "Xtest = transform_str_float(test_data[:, 1])\n",
        "ytest = np.array(test_data[:,0], dtype=np.float32)\n",
        "\n",
        "print(Xtrain.shape, Xval.shape, Xtest.shape)\n",
        "\n",
        "dim = Xtrain.shape[1]\n",
        "print(dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odJtpoHn2j3E"
      },
      "source": [
        "2. Utiliser [Pytorch](https://pytorch.org/vision/main/generated/torchvision.ops.MLP.html) ou [Tensorflow et Keras](https://www.tensorflow.org/tutorials/keras/classification) pour construire un réseau de neurones qui vous permettra de classifier les émotions des visages des différents individus à partir des vecteurs de primitives.\n",
        "<font color=red> Proposer deux architectures différentes </font>: nombre de couches, dimension des couches, fonction d'activation, batch normalization, dropout. (10%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mbcAkViL5zNk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Laurent\\Documents\\GitHub\\771-lab2\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Model 1 avec 4 couches\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(units=128, activation='relu', input_dim=dim))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.5))\n",
        "\n",
        "model1.add(Dense(units=64, activation='relu'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.5))\n",
        "\n",
        "model1.add(Dense(units=32, activation='relu'))\n",
        "model1.add(BatchNormalization())\n",
        "\n",
        "model1.add(Dense(units=7, activation='softmax')) \n",
        "\n",
        "model1.compile(optimizer='adam', \n",
        "               loss='sparse_categorical_crossentropy', \n",
        "               metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Laurent\\Documents\\GitHub\\771-lab2\\.venv\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import LeakyReLU\n",
        "\n",
        "# Model 2 avec  couches\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(units=256, input_dim=dim))\n",
        "model2.add(LeakyReLU(alpha=0.1))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.4))\n",
        "\n",
        "model2.add(Dense(units=128))\n",
        "model2.add(LeakyReLU(alpha=0.1))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.4))\n",
        "\n",
        "model2.add(Dense(units=64, activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.3))\n",
        "\n",
        "model2.add(Dense(units=32, activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "model2.add(Dense(units=16, activation='relu'))\n",
        "\n",
        "model2.add(Dense(units=7, activation='softmax'))  # Assuming 7 classes for emotions\n",
        "\n",
        "model2.compile(optimizer='adam', \n",
        "               loss='sparse_categorical_crossentropy', \n",
        "               metrics=['accuracy'])  # Corrected here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.2705 - loss: 1.9638 - val_accuracy: 0.4668 - val_loss: 1.3986\n",
            "Epoch 2/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - accuracy: 0.4257 - loss: 1.4891 - val_accuracy: 0.4958 - val_loss: 1.3120\n",
            "Epoch 3/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - accuracy: 0.4601 - loss: 1.4095 - val_accuracy: 0.5098 - val_loss: 1.2829\n",
            "Epoch 4/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4751 - loss: 1.3746 - val_accuracy: 0.5159 - val_loss: 1.2656\n",
            "Epoch 5/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4861 - loss: 1.3492 - val_accuracy: 0.5148 - val_loss: 1.2583\n",
            "Epoch 6/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4930 - loss: 1.3362 - val_accuracy: 0.5232 - val_loss: 1.2473\n",
            "Epoch 7/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4973 - loss: 1.3305 - val_accuracy: 0.5271 - val_loss: 1.2394\n",
            "Epoch 8/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4973 - loss: 1.3071 - val_accuracy: 0.5299 - val_loss: 1.2323\n",
            "Epoch 9/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 967us/step - accuracy: 0.5041 - loss: 1.3097 - val_accuracy: 0.5346 - val_loss: 1.2261\n",
            "Epoch 10/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 0.5022 - loss: 1.3009 - val_accuracy: 0.5371 - val_loss: 1.2230\n",
            "Epoch 11/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5116 - loss: 1.2882 - val_accuracy: 0.5346 - val_loss: 1.2178\n",
            "Epoch 12/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995us/step - accuracy: 0.5071 - loss: 1.2959 - val_accuracy: 0.5382 - val_loss: 1.2150\n",
            "Epoch 13/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5141 - loss: 1.2757 - val_accuracy: 0.5427 - val_loss: 1.2089\n",
            "Epoch 14/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5151 - loss: 1.2809 - val_accuracy: 0.5402 - val_loss: 1.2121\n",
            "Epoch 15/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5131 - loss: 1.2755 - val_accuracy: 0.5405 - val_loss: 1.2135\n",
            "Epoch 16/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5120 - loss: 1.2751 - val_accuracy: 0.5391 - val_loss: 1.2093\n",
            "Epoch 17/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5185 - loss: 1.2590 - val_accuracy: 0.5419 - val_loss: 1.2036\n",
            "Epoch 18/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5186 - loss: 1.2609 - val_accuracy: 0.5408 - val_loss: 1.1988\n",
            "Epoch 19/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5222 - loss: 1.2562 - val_accuracy: 0.5500 - val_loss: 1.1999\n",
            "Epoch 20/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 0.5182 - loss: 1.2664 - val_accuracy: 0.5430 - val_loss: 1.2022\n",
            "Epoch 21/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 0.5234 - loss: 1.2600 - val_accuracy: 0.5466 - val_loss: 1.1974\n",
            "Epoch 22/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - accuracy: 0.5257 - loss: 1.2541 - val_accuracy: 0.5433 - val_loss: 1.2000\n",
            "Epoch 23/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - accuracy: 0.5236 - loss: 1.2581 - val_accuracy: 0.5427 - val_loss: 1.1999\n",
            "Epoch 24/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 904us/step - accuracy: 0.5246 - loss: 1.2481 - val_accuracy: 0.5455 - val_loss: 1.2003\n",
            "Epoch 25/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - accuracy: 0.5295 - loss: 1.2477 - val_accuracy: 0.5500 - val_loss: 1.1983\n",
            "Epoch 26/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5172 - loss: 1.2567 - val_accuracy: 0.5494 - val_loss: 1.1951\n",
            "Epoch 27/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5240 - loss: 1.2453 - val_accuracy: 0.5461 - val_loss: 1.1953\n",
            "Epoch 28/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5313 - loss: 1.2451 - val_accuracy: 0.5519 - val_loss: 1.1929\n",
            "Epoch 29/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5272 - loss: 1.2497 - val_accuracy: 0.5525 - val_loss: 1.1933\n",
            "Epoch 30/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5267 - loss: 1.2474 - val_accuracy: 0.5508 - val_loss: 1.1915\n",
            "Epoch 31/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 939us/step - accuracy: 0.5295 - loss: 1.2448 - val_accuracy: 0.5475 - val_loss: 1.1917\n",
            "Epoch 32/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 0.5318 - loss: 1.2484 - val_accuracy: 0.5497 - val_loss: 1.1905\n",
            "Epoch 33/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 987us/step - accuracy: 0.5345 - loss: 1.2385 - val_accuracy: 0.5483 - val_loss: 1.1923\n",
            "Epoch 34/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 954us/step - accuracy: 0.5348 - loss: 1.2381 - val_accuracy: 0.5567 - val_loss: 1.1910\n",
            "Epoch 35/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.5299 - loss: 1.2365 - val_accuracy: 0.5542 - val_loss: 1.1855\n",
            "Epoch 36/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1000us/step - accuracy: 0.5308 - loss: 1.2504 - val_accuracy: 0.5522 - val_loss: 1.1853\n",
            "Epoch 37/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5370 - loss: 1.2242 - val_accuracy: 0.5542 - val_loss: 1.1876\n",
            "Epoch 38/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5379 - loss: 1.2268 - val_accuracy: 0.5508 - val_loss: 1.1930\n",
            "Epoch 39/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5346 - loss: 1.2304 - val_accuracy: 0.5553 - val_loss: 1.1895\n",
            "Epoch 40/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5361 - loss: 1.2337 - val_accuracy: 0.5558 - val_loss: 1.1894\n",
            "Epoch 41/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5328 - loss: 1.2338 - val_accuracy: 0.5556 - val_loss: 1.1863\n",
            "Epoch 42/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 964us/step - accuracy: 0.5341 - loss: 1.2292 - val_accuracy: 0.5564 - val_loss: 1.1874\n",
            "Epoch 43/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - accuracy: 0.5429 - loss: 1.2160 - val_accuracy: 0.5553 - val_loss: 1.1852\n",
            "Epoch 44/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 0.5371 - loss: 1.2311 - val_accuracy: 0.5522 - val_loss: 1.1899\n",
            "Epoch 45/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 0.5377 - loss: 1.2291 - val_accuracy: 0.5547 - val_loss: 1.1849\n",
            "Epoch 46/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - accuracy: 0.5337 - loss: 1.2237 - val_accuracy: 0.5561 - val_loss: 1.1823\n",
            "Epoch 47/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 951us/step - accuracy: 0.5332 - loss: 1.2330 - val_accuracy: 0.5578 - val_loss: 1.1839\n",
            "Epoch 48/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5372 - loss: 1.2297 - val_accuracy: 0.5578 - val_loss: 1.1821\n",
            "Epoch 49/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5407 - loss: 1.2208 - val_accuracy: 0.5597 - val_loss: 1.1839\n",
            "Epoch 50/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5303 - loss: 1.2250 - val_accuracy: 0.5572 - val_loss: 1.1837\n",
            "Epoch 51/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5345 - loss: 1.2220 - val_accuracy: 0.5558 - val_loss: 1.1834\n",
            "Epoch 52/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5390 - loss: 1.2209 - val_accuracy: 0.5611 - val_loss: 1.1810\n",
            "Epoch 53/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - accuracy: 0.5431 - loss: 1.2101 - val_accuracy: 0.5597 - val_loss: 1.1821\n",
            "Epoch 54/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 0.5433 - loss: 1.2164 - val_accuracy: 0.5606 - val_loss: 1.1795\n",
            "Epoch 55/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 0.5383 - loss: 1.2115 - val_accuracy: 0.5586 - val_loss: 1.1786\n",
            "Epoch 56/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - accuracy: 0.5352 - loss: 1.2273 - val_accuracy: 0.5631 - val_loss: 1.1780\n",
            "Epoch 57/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 0.5405 - loss: 1.2221 - val_accuracy: 0.5659 - val_loss: 1.1758\n",
            "Epoch 58/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 0.5386 - loss: 1.2217 - val_accuracy: 0.5634 - val_loss: 1.1768\n",
            "Epoch 59/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5400 - loss: 1.2243 - val_accuracy: 0.5597 - val_loss: 1.1763\n",
            "Epoch 60/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5418 - loss: 1.2138 - val_accuracy: 0.5595 - val_loss: 1.1772\n",
            "Epoch 61/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5380 - loss: 1.2237 - val_accuracy: 0.5650 - val_loss: 1.1811\n",
            "Epoch 62/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5462 - loss: 1.2090 - val_accuracy: 0.5637 - val_loss: 1.1785\n",
            "Epoch 63/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5401 - loss: 1.2206 - val_accuracy: 0.5623 - val_loss: 1.1765\n",
            "Epoch 64/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917us/step - accuracy: 0.5389 - loss: 1.2118 - val_accuracy: 0.5642 - val_loss: 1.1758\n",
            "Epoch 65/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 0.5404 - loss: 1.2119 - val_accuracy: 0.5625 - val_loss: 1.1701\n",
            "Epoch 66/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 0.5458 - loss: 1.2177 - val_accuracy: 0.5617 - val_loss: 1.1736\n",
            "Epoch 67/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 0.5392 - loss: 1.2163 - val_accuracy: 0.5634 - val_loss: 1.1721\n",
            "Epoch 68/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 0.5473 - loss: 1.2066 - val_accuracy: 0.5575 - val_loss: 1.1751\n",
            "Epoch 69/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - accuracy: 0.5440 - loss: 1.2094 - val_accuracy: 0.5620 - val_loss: 1.1728\n",
            "Epoch 70/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5374 - loss: 1.2187 - val_accuracy: 0.5639 - val_loss: 1.1748\n",
            "Epoch 71/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5363 - loss: 1.2168 - val_accuracy: 0.5637 - val_loss: 1.1735\n",
            "Epoch 72/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 994us/step - accuracy: 0.5406 - loss: 1.2247 - val_accuracy: 0.5578 - val_loss: 1.1764\n",
            "Epoch 73/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5390 - loss: 1.2041 - val_accuracy: 0.5570 - val_loss: 1.1760\n",
            "Epoch 74/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5411 - loss: 1.2112 - val_accuracy: 0.5575 - val_loss: 1.1771\n",
            "Epoch 75/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 954us/step - accuracy: 0.5482 - loss: 1.2072 - val_accuracy: 0.5592 - val_loss: 1.1762\n",
            "Epoch 76/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 0.5438 - loss: 1.2081 - val_accuracy: 0.5595 - val_loss: 1.1762\n",
            "Epoch 77/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 0.5468 - loss: 1.2064 - val_accuracy: 0.5556 - val_loss: 1.1753\n",
            "Epoch 78/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 0.5455 - loss: 1.2078 - val_accuracy: 0.5567 - val_loss: 1.1729\n",
            "Epoch 79/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 0.5474 - loss: 1.2096 - val_accuracy: 0.5581 - val_loss: 1.1713\n",
            "Epoch 80/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 0.5414 - loss: 1.2156 - val_accuracy: 0.5564 - val_loss: 1.1749\n",
            "Epoch 81/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 0.5396 - loss: 1.2069 - val_accuracy: 0.5592 - val_loss: 1.1714\n",
            "Epoch 82/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 973us/step - accuracy: 0.5409 - loss: 1.2176 - val_accuracy: 0.5623 - val_loss: 1.1718\n",
            "Epoch 83/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5474 - loss: 1.1973 - val_accuracy: 0.5650 - val_loss: 1.1678\n",
            "Epoch 84/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5458 - loss: 1.1992 - val_accuracy: 0.5617 - val_loss: 1.1689\n",
            "Epoch 85/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5471 - loss: 1.2023 - val_accuracy: 0.5617 - val_loss: 1.1728\n",
            "Epoch 86/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5452 - loss: 1.2017 - val_accuracy: 0.5634 - val_loss: 1.1697\n",
            "Epoch 87/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 930us/step - accuracy: 0.5402 - loss: 1.2115 - val_accuracy: 0.5625 - val_loss: 1.1731\n",
            "Epoch 88/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 0.5490 - loss: 1.2025 - val_accuracy: 0.5625 - val_loss: 1.1699\n",
            "Epoch 89/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 924us/step - accuracy: 0.5433 - loss: 1.2097 - val_accuracy: 0.5611 - val_loss: 1.1714\n",
            "Epoch 90/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 0.5473 - loss: 1.1991 - val_accuracy: 0.5597 - val_loss: 1.1704\n",
            "Epoch 91/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 0.5487 - loss: 1.1996 - val_accuracy: 0.5620 - val_loss: 1.1700\n",
            "Epoch 92/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 0.5383 - loss: 1.2060 - val_accuracy: 0.5597 - val_loss: 1.1702\n",
            "Epoch 93/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5495 - loss: 1.2034 - val_accuracy: 0.5609 - val_loss: 1.1696\n",
            "Epoch 94/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 999us/step - accuracy: 0.5458 - loss: 1.1994 - val_accuracy: 0.5581 - val_loss: 1.1701\n",
            "Epoch 95/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5446 - loss: 1.2032 - val_accuracy: 0.5642 - val_loss: 1.1670\n",
            "Epoch 96/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 996us/step - accuracy: 0.5486 - loss: 1.2036 - val_accuracy: 0.5611 - val_loss: 1.1697\n",
            "Epoch 97/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5496 - loss: 1.1883 - val_accuracy: 0.5645 - val_loss: 1.1695\n",
            "Epoch 98/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 958us/step - accuracy: 0.5485 - loss: 1.2010 - val_accuracy: 0.5609 - val_loss: 1.1647\n",
            "Epoch 99/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.5462 - loss: 1.1973 - val_accuracy: 0.5611 - val_loss: 1.1705\n",
            "Epoch 100/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 0.5528 - loss: 1.2014 - val_accuracy: 0.5620 - val_loss: 1.1700\n",
            "Epoch 101/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 0.5513 - loss: 1.1920 - val_accuracy: 0.5628 - val_loss: 1.1689\n",
            "Epoch 102/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 0.5473 - loss: 1.1998 - val_accuracy: 0.5648 - val_loss: 1.1682\n",
            "Epoch 103/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 0.5478 - loss: 1.1943 - val_accuracy: 0.5662 - val_loss: 1.1679\n",
            "Epoch 104/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 0.5509 - loss: 1.1965 - val_accuracy: 0.5642 - val_loss: 1.1665\n",
            "Epoch 105/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 992us/step - accuracy: 0.5462 - loss: 1.1985 - val_accuracy: 0.5609 - val_loss: 1.1681\n",
            "Epoch 106/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5440 - loss: 1.2094 - val_accuracy: 0.5578 - val_loss: 1.1669\n",
            "Epoch 107/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5516 - loss: 1.1965 - val_accuracy: 0.5597 - val_loss: 1.1695\n",
            "Epoch 108/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5438 - loss: 1.2064 - val_accuracy: 0.5637 - val_loss: 1.1659\n",
            "Epoch 109/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5569 - loss: 1.1889 - val_accuracy: 0.5631 - val_loss: 1.1660\n",
            "Epoch 110/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 0.5448 - loss: 1.1991 - val_accuracy: 0.5620 - val_loss: 1.1680\n",
            "Epoch 111/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - accuracy: 0.5533 - loss: 1.1901 - val_accuracy: 0.5586 - val_loss: 1.1726\n",
            "Epoch 112/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 0.5445 - loss: 1.2025 - val_accuracy: 0.5595 - val_loss: 1.1680\n",
            "Epoch 113/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 0.5547 - loss: 1.1907 - val_accuracy: 0.5611 - val_loss: 1.1690\n",
            "Epoch 114/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 0.5436 - loss: 1.1997 - val_accuracy: 0.5614 - val_loss: 1.1675\n",
            "Epoch 115/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 0.5569 - loss: 1.1841 - val_accuracy: 0.5637 - val_loss: 1.1680\n",
            "Epoch 116/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995us/step - accuracy: 0.5501 - loss: 1.1946 - val_accuracy: 0.5639 - val_loss: 1.1667\n",
            "Epoch 117/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5458 - loss: 1.2000 - val_accuracy: 0.5645 - val_loss: 1.1659\n",
            "Epoch 118/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5470 - loss: 1.2012 - val_accuracy: 0.5609 - val_loss: 1.1682\n",
            "Epoch 119/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5443 - loss: 1.2011 - val_accuracy: 0.5600 - val_loss: 1.1662\n",
            "Epoch 120/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5518 - loss: 1.1954 - val_accuracy: 0.5567 - val_loss: 1.1645\n",
            "Epoch 121/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5484 - loss: 1.1925 - val_accuracy: 0.5592 - val_loss: 1.1669\n",
            "Epoch 122/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 0.5474 - loss: 1.2051 - val_accuracy: 0.5637 - val_loss: 1.1689\n",
            "Epoch 123/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 0.5525 - loss: 1.1878 - val_accuracy: 0.5595 - val_loss: 1.1685\n",
            "Epoch 124/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 904us/step - accuracy: 0.5498 - loss: 1.1985 - val_accuracy: 0.5589 - val_loss: 1.1687\n",
            "Epoch 125/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 0.5497 - loss: 1.1944 - val_accuracy: 0.5597 - val_loss: 1.1696\n",
            "Epoch 126/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 0.5485 - loss: 1.1977 - val_accuracy: 0.5600 - val_loss: 1.1670\n",
            "Epoch 127/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 0.5475 - loss: 1.1999 - val_accuracy: 0.5639 - val_loss: 1.1660\n",
            "Epoch 128/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5458 - loss: 1.2014 - val_accuracy: 0.5667 - val_loss: 1.1657\n",
            "Epoch 129/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5492 - loss: 1.1971 - val_accuracy: 0.5558 - val_loss: 1.1714\n",
            "Epoch 130/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5496 - loss: 1.1943 - val_accuracy: 0.5575 - val_loss: 1.1693\n",
            "Epoch 131/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5516 - loss: 1.1906 - val_accuracy: 0.5614 - val_loss: 1.1685\n",
            "Epoch 132/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5550 - loss: 1.1990 - val_accuracy: 0.5628 - val_loss: 1.1674\n",
            "Epoch 133/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 0.5498 - loss: 1.1980 - val_accuracy: 0.5572 - val_loss: 1.1676\n",
            "Epoch 134/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 0.5509 - loss: 1.1882 - val_accuracy: 0.5572 - val_loss: 1.1662\n",
            "Epoch 135/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881us/step - accuracy: 0.5502 - loss: 1.1936 - val_accuracy: 0.5567 - val_loss: 1.1700\n",
            "Epoch 136/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 0.5498 - loss: 1.1930 - val_accuracy: 0.5572 - val_loss: 1.1710\n",
            "Epoch 137/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 0.5529 - loss: 1.1872 - val_accuracy: 0.5650 - val_loss: 1.1656\n",
            "Epoch 138/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.5542 - loss: 1.1861 - val_accuracy: 0.5639 - val_loss: 1.1659\n",
            "Epoch 139/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942us/step - accuracy: 0.5444 - loss: 1.1990 - val_accuracy: 0.5597 - val_loss: 1.1695\n",
            "Epoch 140/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986us/step - accuracy: 0.5522 - loss: 1.1903 - val_accuracy: 0.5614 - val_loss: 1.1669\n",
            "Epoch 141/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5503 - loss: 1.1893 - val_accuracy: 0.5614 - val_loss: 1.1654\n",
            "Epoch 142/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5498 - loss: 1.1902 - val_accuracy: 0.5631 - val_loss: 1.1651\n",
            "Epoch 143/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5449 - loss: 1.1955 - val_accuracy: 0.5656 - val_loss: 1.1653\n",
            "Epoch 144/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5579 - loss: 1.1846 - val_accuracy: 0.5637 - val_loss: 1.1658\n",
            "Epoch 145/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 0.5490 - loss: 1.1914 - val_accuracy: 0.5617 - val_loss: 1.1678\n",
            "Epoch 146/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 0.5528 - loss: 1.1796 - val_accuracy: 0.5578 - val_loss: 1.1661\n",
            "Epoch 147/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5470 - loss: 1.1924 - val_accuracy: 0.5617 - val_loss: 1.1642\n",
            "Epoch 148/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5487 - loss: 1.1936 - val_accuracy: 0.5567 - val_loss: 1.1645\n",
            "Epoch 149/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 0.5526 - loss: 1.1834 - val_accuracy: 0.5578 - val_loss: 1.1681\n",
            "Epoch 150/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5552 - loss: 1.1868 - val_accuracy: 0.5606 - val_loss: 1.1664\n",
            "Epoch 151/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5458 - loss: 1.2002 - val_accuracy: 0.5614 - val_loss: 1.1628\n",
            "Epoch 152/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5428 - loss: 1.1965 - val_accuracy: 0.5623 - val_loss: 1.1627\n",
            "Epoch 153/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5516 - loss: 1.1940 - val_accuracy: 0.5645 - val_loss: 1.1640\n",
            "Epoch 154/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5496 - loss: 1.1932 - val_accuracy: 0.5620 - val_loss: 1.1657\n",
            "Epoch 155/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5546 - loss: 1.1885 - val_accuracy: 0.5609 - val_loss: 1.1650\n",
            "Epoch 156/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5508 - loss: 1.1891 - val_accuracy: 0.5620 - val_loss: 1.1646\n",
            "Epoch 157/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5513 - loss: 1.1839 - val_accuracy: 0.5611 - val_loss: 1.1650\n",
            "Epoch 158/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995us/step - accuracy: 0.5593 - loss: 1.1768 - val_accuracy: 0.5664 - val_loss: 1.1640\n",
            "Epoch 159/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 0.5550 - loss: 1.1828 - val_accuracy: 0.5656 - val_loss: 1.1647\n",
            "Epoch 160/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5576 - loss: 1.1880 - val_accuracy: 0.5642 - val_loss: 1.1633\n",
            "Epoch 161/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5533 - loss: 1.1827 - val_accuracy: 0.5667 - val_loss: 1.1641\n",
            "Epoch 162/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5639 - loss: 1.1767 - val_accuracy: 0.5631 - val_loss: 1.1634\n",
            "Epoch 163/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5558 - loss: 1.1865 - val_accuracy: 0.5623 - val_loss: 1.1653\n",
            "Epoch 164/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5589 - loss: 1.1848 - val_accuracy: 0.5586 - val_loss: 1.1653\n",
            "Epoch 165/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5601 - loss: 1.1807 - val_accuracy: 0.5603 - val_loss: 1.1632\n",
            "Epoch 166/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - accuracy: 0.5472 - loss: 1.1943 - val_accuracy: 0.5637 - val_loss: 1.1638\n",
            "Epoch 167/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 0.5534 - loss: 1.1976 - val_accuracy: 0.5664 - val_loss: 1.1653\n",
            "Epoch 168/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5584 - loss: 1.1825 - val_accuracy: 0.5614 - val_loss: 1.1634\n",
            "Epoch 169/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5554 - loss: 1.1865 - val_accuracy: 0.5611 - val_loss: 1.1649\n",
            "Epoch 170/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5527 - loss: 1.1830 - val_accuracy: 0.5592 - val_loss: 1.1635\n",
            "Epoch 171/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5539 - loss: 1.1852 - val_accuracy: 0.5670 - val_loss: 1.1637\n",
            "Epoch 172/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5569 - loss: 1.1807 - val_accuracy: 0.5611 - val_loss: 1.1635\n",
            "Epoch 173/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5533 - loss: 1.1878 - val_accuracy: 0.5625 - val_loss: 1.1622\n",
            "Epoch 174/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 999us/step - accuracy: 0.5503 - loss: 1.1955 - val_accuracy: 0.5662 - val_loss: 1.1628\n",
            "Epoch 175/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5533 - loss: 1.1815 - val_accuracy: 0.5642 - val_loss: 1.1627\n",
            "Epoch 176/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5489 - loss: 1.1923 - val_accuracy: 0.5611 - val_loss: 1.1631\n",
            "Epoch 177/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 0.5578 - loss: 1.1851 - val_accuracy: 0.5648 - val_loss: 1.1633\n",
            "Epoch 178/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 0.5498 - loss: 1.1925 - val_accuracy: 0.5609 - val_loss: 1.1635\n",
            "Epoch 179/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 0.5521 - loss: 1.1923 - val_accuracy: 0.5634 - val_loss: 1.1619\n",
            "Epoch 180/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - accuracy: 0.5586 - loss: 1.1772 - val_accuracy: 0.5659 - val_loss: 1.1604\n",
            "Epoch 181/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - accuracy: 0.5543 - loss: 1.1887 - val_accuracy: 0.5650 - val_loss: 1.1653\n",
            "Epoch 182/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 0.5528 - loss: 1.1850 - val_accuracy: 0.5620 - val_loss: 1.1664\n",
            "Epoch 183/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5574 - loss: 1.1830 - val_accuracy: 0.5639 - val_loss: 1.1671\n",
            "Epoch 184/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5516 - loss: 1.1864 - val_accuracy: 0.5653 - val_loss: 1.1643\n",
            "Epoch 185/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5542 - loss: 1.1877 - val_accuracy: 0.5656 - val_loss: 1.1637\n",
            "Epoch 186/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5517 - loss: 1.1872 - val_accuracy: 0.5614 - val_loss: 1.1652\n",
            "Epoch 187/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5585 - loss: 1.1811 - val_accuracy: 0.5628 - val_loss: 1.1639\n",
            "Epoch 188/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 954us/step - accuracy: 0.5557 - loss: 1.1853 - val_accuracy: 0.5611 - val_loss: 1.1658\n",
            "Epoch 189/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 0.5530 - loss: 1.1832 - val_accuracy: 0.5634 - val_loss: 1.1652\n",
            "Epoch 190/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 987us/step - accuracy: 0.5575 - loss: 1.1727 - val_accuracy: 0.5631 - val_loss: 1.1640\n",
            "Epoch 191/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5526 - loss: 1.1867 - val_accuracy: 0.5620 - val_loss: 1.1651\n",
            "Epoch 192/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 925us/step - accuracy: 0.5505 - loss: 1.1874 - val_accuracy: 0.5642 - val_loss: 1.1635\n",
            "Epoch 193/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5570 - loss: 1.1763 - val_accuracy: 0.5653 - val_loss: 1.1624\n",
            "Epoch 194/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5504 - loss: 1.1872 - val_accuracy: 0.5653 - val_loss: 1.1640\n",
            "Epoch 195/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5550 - loss: 1.1816 - val_accuracy: 0.5662 - val_loss: 1.1636\n",
            "Epoch 196/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5488 - loss: 1.1834 - val_accuracy: 0.5690 - val_loss: 1.1603\n",
            "Epoch 197/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5538 - loss: 1.1879 - val_accuracy: 0.5676 - val_loss: 1.1630\n",
            "Epoch 198/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5562 - loss: 1.1857 - val_accuracy: 0.5656 - val_loss: 1.1608\n",
            "Epoch 199/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5589 - loss: 1.1704 - val_accuracy: 0.5678 - val_loss: 1.1628\n",
            "Epoch 200/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5561 - loss: 1.1812 - val_accuracy: 0.5625 - val_loss: 1.1650\n"
          ]
        }
      ],
      "source": [
        "train = model1.fit(Xtrain, ytrain, \n",
        "                      epochs=200, \n",
        "                      batch_size=32, \n",
        "                      validation_data=(Xval, yval))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3054 - loss: 1.7883 - val_accuracy: 0.4964 - val_loss: 1.3299\n",
            "Epoch 2/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4615 - loss: 1.4083 - val_accuracy: 0.5109 - val_loss: 1.2751\n",
            "Epoch 3/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4870 - loss: 1.3448 - val_accuracy: 0.5215 - val_loss: 1.2604\n",
            "Epoch 4/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4949 - loss: 1.3265 - val_accuracy: 0.5288 - val_loss: 1.2431\n",
            "Epoch 5/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5017 - loss: 1.3088 - val_accuracy: 0.5276 - val_loss: 1.2391\n",
            "Epoch 6/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5168 - loss: 1.2831 - val_accuracy: 0.5307 - val_loss: 1.2304\n",
            "Epoch 7/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5122 - loss: 1.2836 - val_accuracy: 0.5385 - val_loss: 1.2219\n",
            "Epoch 8/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5127 - loss: 1.2722 - val_accuracy: 0.5413 - val_loss: 1.2079\n",
            "Epoch 9/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5197 - loss: 1.2583 - val_accuracy: 0.5424 - val_loss: 1.2121\n",
            "Epoch 10/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5319 - loss: 1.2395 - val_accuracy: 0.5491 - val_loss: 1.2037\n",
            "Epoch 11/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5278 - loss: 1.2481 - val_accuracy: 0.5405 - val_loss: 1.2010\n",
            "Epoch 12/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5342 - loss: 1.2333 - val_accuracy: 0.5489 - val_loss: 1.1973\n",
            "Epoch 13/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5350 - loss: 1.2254 - val_accuracy: 0.5489 - val_loss: 1.1890\n",
            "Epoch 14/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5279 - loss: 1.2429 - val_accuracy: 0.5438 - val_loss: 1.1934\n",
            "Epoch 15/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5363 - loss: 1.2250 - val_accuracy: 0.5489 - val_loss: 1.1865\n",
            "Epoch 16/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5376 - loss: 1.2181 - val_accuracy: 0.5556 - val_loss: 1.1898\n",
            "Epoch 17/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5383 - loss: 1.2219 - val_accuracy: 0.5542 - val_loss: 1.1826\n",
            "Epoch 18/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5367 - loss: 1.2207 - val_accuracy: 0.5536 - val_loss: 1.1776\n",
            "Epoch 19/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5441 - loss: 1.2097 - val_accuracy: 0.5653 - val_loss: 1.1717\n",
            "Epoch 20/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5397 - loss: 1.2144 - val_accuracy: 0.5542 - val_loss: 1.1851\n",
            "Epoch 21/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5440 - loss: 1.2011 - val_accuracy: 0.5553 - val_loss: 1.1742\n",
            "Epoch 22/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5396 - loss: 1.2047 - val_accuracy: 0.5603 - val_loss: 1.1745\n",
            "Epoch 23/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5411 - loss: 1.1980 - val_accuracy: 0.5575 - val_loss: 1.1745\n",
            "Epoch 24/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5476 - loss: 1.1942 - val_accuracy: 0.5614 - val_loss: 1.1735\n",
            "Epoch 25/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5475 - loss: 1.1989 - val_accuracy: 0.5637 - val_loss: 1.1662\n",
            "Epoch 26/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5422 - loss: 1.2031 - val_accuracy: 0.5625 - val_loss: 1.1708\n",
            "Epoch 27/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5565 - loss: 1.1861 - val_accuracy: 0.5645 - val_loss: 1.1758\n",
            "Epoch 28/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5524 - loss: 1.1858 - val_accuracy: 0.5653 - val_loss: 1.1680\n",
            "Epoch 29/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5523 - loss: 1.1823 - val_accuracy: 0.5648 - val_loss: 1.1672\n",
            "Epoch 30/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5521 - loss: 1.1898 - val_accuracy: 0.5706 - val_loss: 1.1637\n",
            "Epoch 31/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5557 - loss: 1.1698 - val_accuracy: 0.5678 - val_loss: 1.1670\n",
            "Epoch 32/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5524 - loss: 1.1835 - val_accuracy: 0.5625 - val_loss: 1.1770\n",
            "Epoch 33/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5505 - loss: 1.1810 - val_accuracy: 0.5614 - val_loss: 1.1628\n",
            "Epoch 34/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5506 - loss: 1.1811 - val_accuracy: 0.5600 - val_loss: 1.1623\n",
            "Epoch 35/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5573 - loss: 1.1752 - val_accuracy: 0.5625 - val_loss: 1.1633\n",
            "Epoch 36/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5574 - loss: 1.1726 - val_accuracy: 0.5542 - val_loss: 1.1699\n",
            "Epoch 37/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5574 - loss: 1.1751 - val_accuracy: 0.5611 - val_loss: 1.1601\n",
            "Epoch 38/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5585 - loss: 1.1707 - val_accuracy: 0.5589 - val_loss: 1.1657\n",
            "Epoch 39/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5590 - loss: 1.1744 - val_accuracy: 0.5684 - val_loss: 1.1571\n",
            "Epoch 40/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5651 - loss: 1.1608 - val_accuracy: 0.5628 - val_loss: 1.1616\n",
            "Epoch 41/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5534 - loss: 1.1728 - val_accuracy: 0.5631 - val_loss: 1.1570\n",
            "Epoch 42/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5652 - loss: 1.1589 - val_accuracy: 0.5611 - val_loss: 1.1552\n",
            "Epoch 43/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5636 - loss: 1.1636 - val_accuracy: 0.5639 - val_loss: 1.1578\n",
            "Epoch 44/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5611 - loss: 1.1521 - val_accuracy: 0.5673 - val_loss: 1.1520\n",
            "Epoch 45/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5609 - loss: 1.1590 - val_accuracy: 0.5684 - val_loss: 1.1526\n",
            "Epoch 46/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5611 - loss: 1.1583 - val_accuracy: 0.5678 - val_loss: 1.1548\n",
            "Epoch 47/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5632 - loss: 1.1577 - val_accuracy: 0.5664 - val_loss: 1.1509\n",
            "Epoch 48/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5662 - loss: 1.1600 - val_accuracy: 0.5701 - val_loss: 1.1545\n",
            "Epoch 49/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5637 - loss: 1.1585 - val_accuracy: 0.5715 - val_loss: 1.1525\n",
            "Epoch 50/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5679 - loss: 1.1493 - val_accuracy: 0.5639 - val_loss: 1.1544\n",
            "Epoch 51/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5655 - loss: 1.1556 - val_accuracy: 0.5709 - val_loss: 1.1528\n",
            "Epoch 52/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5603 - loss: 1.1603 - val_accuracy: 0.5723 - val_loss: 1.1525\n",
            "Epoch 53/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5633 - loss: 1.1612 - val_accuracy: 0.5698 - val_loss: 1.1519\n",
            "Epoch 54/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5579 - loss: 1.1750 - val_accuracy: 0.5670 - val_loss: 1.1563\n",
            "Epoch 55/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5652 - loss: 1.1470 - val_accuracy: 0.5717 - val_loss: 1.1528\n",
            "Epoch 56/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5659 - loss: 1.1456 - val_accuracy: 0.5681 - val_loss: 1.1540\n",
            "Epoch 57/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5634 - loss: 1.1627 - val_accuracy: 0.5751 - val_loss: 1.1556\n",
            "Epoch 58/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5656 - loss: 1.1513 - val_accuracy: 0.5734 - val_loss: 1.1525\n",
            "Epoch 59/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5689 - loss: 1.1501 - val_accuracy: 0.5695 - val_loss: 1.1512\n",
            "Epoch 60/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5710 - loss: 1.1409 - val_accuracy: 0.5748 - val_loss: 1.1501\n",
            "Epoch 61/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5676 - loss: 1.1466 - val_accuracy: 0.5776 - val_loss: 1.1500\n",
            "Epoch 62/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5664 - loss: 1.1509 - val_accuracy: 0.5745 - val_loss: 1.1493\n",
            "Epoch 63/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5719 - loss: 1.1373 - val_accuracy: 0.5726 - val_loss: 1.1472\n",
            "Epoch 64/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5652 - loss: 1.1557 - val_accuracy: 0.5706 - val_loss: 1.1492\n",
            "Epoch 65/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5713 - loss: 1.1379 - val_accuracy: 0.5737 - val_loss: 1.1463\n",
            "Epoch 66/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5710 - loss: 1.1458 - val_accuracy: 0.5757 - val_loss: 1.1419\n",
            "Epoch 67/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5601 - loss: 1.1535 - val_accuracy: 0.5751 - val_loss: 1.1432\n",
            "Epoch 68/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5749 - loss: 1.1333 - val_accuracy: 0.5704 - val_loss: 1.1444\n",
            "Epoch 69/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5684 - loss: 1.1418 - val_accuracy: 0.5717 - val_loss: 1.1507\n",
            "Epoch 70/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5760 - loss: 1.1379 - val_accuracy: 0.5704 - val_loss: 1.1515\n",
            "Epoch 71/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5747 - loss: 1.1291 - val_accuracy: 0.5748 - val_loss: 1.1473\n",
            "Epoch 72/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5729 - loss: 1.1289 - val_accuracy: 0.5740 - val_loss: 1.1454\n",
            "Epoch 73/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5722 - loss: 1.1334 - val_accuracy: 0.5676 - val_loss: 1.1458\n",
            "Epoch 74/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5726 - loss: 1.1346 - val_accuracy: 0.5709 - val_loss: 1.1512\n",
            "Epoch 75/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5726 - loss: 1.1390 - val_accuracy: 0.5659 - val_loss: 1.1513\n",
            "Epoch 76/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5734 - loss: 1.1321 - val_accuracy: 0.5678 - val_loss: 1.1495\n",
            "Epoch 77/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5690 - loss: 1.1414 - val_accuracy: 0.5706 - val_loss: 1.1492\n",
            "Epoch 78/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5747 - loss: 1.1359 - val_accuracy: 0.5723 - val_loss: 1.1475\n",
            "Epoch 79/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5698 - loss: 1.1368 - val_accuracy: 0.5717 - val_loss: 1.1452\n",
            "Epoch 80/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5758 - loss: 1.1269 - val_accuracy: 0.5762 - val_loss: 1.1399\n",
            "Epoch 81/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5768 - loss: 1.1331 - val_accuracy: 0.5757 - val_loss: 1.1432\n",
            "Epoch 82/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5726 - loss: 1.1333 - val_accuracy: 0.5798 - val_loss: 1.1416\n",
            "Epoch 83/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5707 - loss: 1.1364 - val_accuracy: 0.5715 - val_loss: 1.1476\n",
            "Epoch 84/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5693 - loss: 1.1395 - val_accuracy: 0.5748 - val_loss: 1.1456\n",
            "Epoch 85/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5737 - loss: 1.1286 - val_accuracy: 0.5743 - val_loss: 1.1448\n",
            "Epoch 86/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5772 - loss: 1.1289 - val_accuracy: 0.5773 - val_loss: 1.1431\n",
            "Epoch 87/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5782 - loss: 1.1290 - val_accuracy: 0.5759 - val_loss: 1.1462\n",
            "Epoch 88/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5739 - loss: 1.1282 - val_accuracy: 0.5720 - val_loss: 1.1398\n",
            "Epoch 89/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5754 - loss: 1.1317 - val_accuracy: 0.5678 - val_loss: 1.1469\n",
            "Epoch 90/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5730 - loss: 1.1300 - val_accuracy: 0.5838 - val_loss: 1.1427\n",
            "Epoch 91/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5792 - loss: 1.1263 - val_accuracy: 0.5779 - val_loss: 1.1410\n",
            "Epoch 92/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5740 - loss: 1.1342 - val_accuracy: 0.5818 - val_loss: 1.1391\n",
            "Epoch 93/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5809 - loss: 1.1237 - val_accuracy: 0.5782 - val_loss: 1.1397\n",
            "Epoch 94/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5758 - loss: 1.1256 - val_accuracy: 0.5748 - val_loss: 1.1459\n",
            "Epoch 95/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5791 - loss: 1.1282 - val_accuracy: 0.5743 - val_loss: 1.1424\n",
            "Epoch 96/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5769 - loss: 1.1241 - val_accuracy: 0.5717 - val_loss: 1.1398\n",
            "Epoch 97/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5731 - loss: 1.1272 - val_accuracy: 0.5734 - val_loss: 1.1401\n",
            "Epoch 98/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5760 - loss: 1.1265 - val_accuracy: 0.5765 - val_loss: 1.1431\n",
            "Epoch 99/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5669 - loss: 1.1419 - val_accuracy: 0.5726 - val_loss: 1.1440\n",
            "Epoch 100/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5658 - loss: 1.1452 - val_accuracy: 0.5712 - val_loss: 1.1398\n",
            "Epoch 101/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5769 - loss: 1.1243 - val_accuracy: 0.5729 - val_loss: 1.1461\n",
            "Epoch 102/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5755 - loss: 1.1303 - val_accuracy: 0.5734 - val_loss: 1.1430\n",
            "Epoch 103/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5821 - loss: 1.1137 - val_accuracy: 0.5743 - val_loss: 1.1426\n",
            "Epoch 104/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5852 - loss: 1.1150 - val_accuracy: 0.5726 - val_loss: 1.1500\n",
            "Epoch 105/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5792 - loss: 1.1291 - val_accuracy: 0.5695 - val_loss: 1.1418\n",
            "Epoch 106/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5759 - loss: 1.1342 - val_accuracy: 0.5704 - val_loss: 1.1458\n",
            "Epoch 107/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5753 - loss: 1.1289 - val_accuracy: 0.5712 - val_loss: 1.1442\n",
            "Epoch 108/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5779 - loss: 1.1151 - val_accuracy: 0.5740 - val_loss: 1.1379\n",
            "Epoch 109/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5814 - loss: 1.1231 - val_accuracy: 0.5664 - val_loss: 1.1451\n",
            "Epoch 110/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5795 - loss: 1.1239 - val_accuracy: 0.5717 - val_loss: 1.1412\n",
            "Epoch 111/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5786 - loss: 1.1172 - val_accuracy: 0.5692 - val_loss: 1.1440\n",
            "Epoch 112/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5799 - loss: 1.1182 - val_accuracy: 0.5737 - val_loss: 1.1412\n",
            "Epoch 113/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5736 - loss: 1.1281 - val_accuracy: 0.5715 - val_loss: 1.1432\n",
            "Epoch 114/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5759 - loss: 1.1271 - val_accuracy: 0.5698 - val_loss: 1.1385\n",
            "Epoch 115/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5815 - loss: 1.1171 - val_accuracy: 0.5731 - val_loss: 1.1411\n",
            "Epoch 116/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5778 - loss: 1.1224 - val_accuracy: 0.5704 - val_loss: 1.1440\n",
            "Epoch 117/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5805 - loss: 1.1231 - val_accuracy: 0.5731 - val_loss: 1.1395\n",
            "Epoch 118/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5784 - loss: 1.1179 - val_accuracy: 0.5698 - val_loss: 1.1408\n",
            "Epoch 119/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5771 - loss: 1.1230 - val_accuracy: 0.5704 - val_loss: 1.1413\n",
            "Epoch 120/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5827 - loss: 1.1182 - val_accuracy: 0.5715 - val_loss: 1.1398\n",
            "Epoch 121/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5774 - loss: 1.1341 - val_accuracy: 0.5704 - val_loss: 1.1393\n",
            "Epoch 122/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5853 - loss: 1.1082 - val_accuracy: 0.5737 - val_loss: 1.1399\n",
            "Epoch 123/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5809 - loss: 1.1098 - val_accuracy: 0.5773 - val_loss: 1.1411\n",
            "Epoch 124/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5826 - loss: 1.1227 - val_accuracy: 0.5704 - val_loss: 1.1454\n",
            "Epoch 125/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5772 - loss: 1.1344 - val_accuracy: 0.5771 - val_loss: 1.1417\n",
            "Epoch 126/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5854 - loss: 1.1121 - val_accuracy: 0.5709 - val_loss: 1.1327\n",
            "Epoch 127/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5867 - loss: 1.1089 - val_accuracy: 0.5790 - val_loss: 1.1381\n",
            "Epoch 128/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5849 - loss: 1.1061 - val_accuracy: 0.5804 - val_loss: 1.1372\n",
            "Epoch 129/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5802 - loss: 1.1153 - val_accuracy: 0.5804 - val_loss: 1.1406\n",
            "Epoch 130/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5851 - loss: 1.1048 - val_accuracy: 0.5773 - val_loss: 1.1342\n",
            "Epoch 131/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5785 - loss: 1.1208 - val_accuracy: 0.5782 - val_loss: 1.1375\n",
            "Epoch 132/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5880 - loss: 1.1030 - val_accuracy: 0.5762 - val_loss: 1.1396\n",
            "Epoch 133/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5852 - loss: 1.1099 - val_accuracy: 0.5748 - val_loss: 1.1296\n",
            "Epoch 134/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5837 - loss: 1.1086 - val_accuracy: 0.5790 - val_loss: 1.1331\n",
            "Epoch 135/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5829 - loss: 1.1137 - val_accuracy: 0.5801 - val_loss: 1.1317\n",
            "Epoch 136/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5829 - loss: 1.1053 - val_accuracy: 0.5762 - val_loss: 1.1393\n",
            "Epoch 137/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5833 - loss: 1.1201 - val_accuracy: 0.5759 - val_loss: 1.1393\n",
            "Epoch 138/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5835 - loss: 1.1154 - val_accuracy: 0.5784 - val_loss: 1.1453\n",
            "Epoch 139/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5854 - loss: 1.1131 - val_accuracy: 0.5745 - val_loss: 1.1398\n",
            "Epoch 140/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5796 - loss: 1.1142 - val_accuracy: 0.5706 - val_loss: 1.1431\n",
            "Epoch 141/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5833 - loss: 1.1091 - val_accuracy: 0.5751 - val_loss: 1.1395\n",
            "Epoch 142/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5820 - loss: 1.1121 - val_accuracy: 0.5748 - val_loss: 1.1412\n",
            "Epoch 143/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5806 - loss: 1.1199 - val_accuracy: 0.5790 - val_loss: 1.1340\n",
            "Epoch 144/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5842 - loss: 1.1112 - val_accuracy: 0.5765 - val_loss: 1.1383\n",
            "Epoch 145/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5833 - loss: 1.1147 - val_accuracy: 0.5734 - val_loss: 1.1395\n",
            "Epoch 146/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5796 - loss: 1.1201 - val_accuracy: 0.5706 - val_loss: 1.1395\n",
            "Epoch 147/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5834 - loss: 1.1216 - val_accuracy: 0.5757 - val_loss: 1.1351\n",
            "Epoch 148/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5741 - loss: 1.1293 - val_accuracy: 0.5793 - val_loss: 1.1357\n",
            "Epoch 149/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5869 - loss: 1.0992 - val_accuracy: 0.5751 - val_loss: 1.1371\n",
            "Epoch 150/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5844 - loss: 1.1100 - val_accuracy: 0.5782 - val_loss: 1.1390\n",
            "Epoch 151/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5825 - loss: 1.1165 - val_accuracy: 0.5751 - val_loss: 1.1417\n",
            "Epoch 152/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5874 - loss: 1.1095 - val_accuracy: 0.5723 - val_loss: 1.1400\n",
            "Epoch 153/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5843 - loss: 1.1057 - val_accuracy: 0.5715 - val_loss: 1.1357\n",
            "Epoch 154/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5864 - loss: 1.1012 - val_accuracy: 0.5754 - val_loss: 1.1364\n",
            "Epoch 155/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5793 - loss: 1.1190 - val_accuracy: 0.5790 - val_loss: 1.1371\n",
            "Epoch 156/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5847 - loss: 1.1154 - val_accuracy: 0.5737 - val_loss: 1.1406\n",
            "Epoch 157/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5780 - loss: 1.1196 - val_accuracy: 0.5798 - val_loss: 1.1392\n",
            "Epoch 158/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5832 - loss: 1.1179 - val_accuracy: 0.5765 - val_loss: 1.1335\n",
            "Epoch 159/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5852 - loss: 1.1065 - val_accuracy: 0.5734 - val_loss: 1.1378\n",
            "Epoch 160/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5876 - loss: 1.0975 - val_accuracy: 0.5757 - val_loss: 1.1379\n",
            "Epoch 161/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5824 - loss: 1.1071 - val_accuracy: 0.5776 - val_loss: 1.1363\n",
            "Epoch 162/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5832 - loss: 1.1076 - val_accuracy: 0.5798 - val_loss: 1.1326\n",
            "Epoch 163/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5815 - loss: 1.1082 - val_accuracy: 0.5796 - val_loss: 1.1361\n",
            "Epoch 164/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5838 - loss: 1.1151 - val_accuracy: 0.5840 - val_loss: 1.1332\n",
            "Epoch 165/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5849 - loss: 1.1133 - val_accuracy: 0.5810 - val_loss: 1.1306\n",
            "Epoch 166/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5840 - loss: 1.1098 - val_accuracy: 0.5798 - val_loss: 1.1344\n",
            "Epoch 167/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5857 - loss: 1.1089 - val_accuracy: 0.5857 - val_loss: 1.1303\n",
            "Epoch 168/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5857 - loss: 1.1013 - val_accuracy: 0.5812 - val_loss: 1.1325\n",
            "Epoch 169/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5835 - loss: 1.1154 - val_accuracy: 0.5818 - val_loss: 1.1302\n",
            "Epoch 170/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5894 - loss: 1.1009 - val_accuracy: 0.5832 - val_loss: 1.1372\n",
            "Epoch 171/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5859 - loss: 1.1068 - val_accuracy: 0.5790 - val_loss: 1.1324\n",
            "Epoch 172/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5798 - loss: 1.1102 - val_accuracy: 0.5757 - val_loss: 1.1347\n",
            "Epoch 173/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5835 - loss: 1.1086 - val_accuracy: 0.5818 - val_loss: 1.1317\n",
            "Epoch 174/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5927 - loss: 1.0927 - val_accuracy: 0.5779 - val_loss: 1.1332\n",
            "Epoch 175/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5773 - loss: 1.1165 - val_accuracy: 0.5762 - val_loss: 1.1367\n",
            "Epoch 176/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5899 - loss: 1.1039 - val_accuracy: 0.5810 - val_loss: 1.1304\n",
            "Epoch 177/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5881 - loss: 1.1009 - val_accuracy: 0.5793 - val_loss: 1.1328\n",
            "Epoch 178/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5843 - loss: 1.1116 - val_accuracy: 0.5826 - val_loss: 1.1345\n",
            "Epoch 179/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5864 - loss: 1.0937 - val_accuracy: 0.5784 - val_loss: 1.1342\n",
            "Epoch 180/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5801 - loss: 1.1090 - val_accuracy: 0.5776 - val_loss: 1.1368\n",
            "Epoch 181/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5880 - loss: 1.0994 - val_accuracy: 0.5796 - val_loss: 1.1418\n",
            "Epoch 182/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5887 - loss: 1.1042 - val_accuracy: 0.5737 - val_loss: 1.1392\n",
            "Epoch 183/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5896 - loss: 1.1002 - val_accuracy: 0.5729 - val_loss: 1.1380\n",
            "Epoch 184/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5897 - loss: 1.0942 - val_accuracy: 0.5771 - val_loss: 1.1371\n",
            "Epoch 185/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5879 - loss: 1.1027 - val_accuracy: 0.5779 - val_loss: 1.1396\n",
            "Epoch 186/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5872 - loss: 1.0962 - val_accuracy: 0.5737 - val_loss: 1.1350\n",
            "Epoch 187/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5909 - loss: 1.0899 - val_accuracy: 0.5768 - val_loss: 1.1344\n",
            "Epoch 188/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5841 - loss: 1.1054 - val_accuracy: 0.5762 - val_loss: 1.1333\n",
            "Epoch 189/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5887 - loss: 1.0944 - val_accuracy: 0.5734 - val_loss: 1.1357\n",
            "Epoch 190/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5926 - loss: 1.0861 - val_accuracy: 0.5790 - val_loss: 1.1363\n",
            "Epoch 191/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5785 - loss: 1.1200 - val_accuracy: 0.5740 - val_loss: 1.1377\n",
            "Epoch 192/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5888 - loss: 1.1082 - val_accuracy: 0.5745 - val_loss: 1.1363\n",
            "Epoch 193/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5883 - loss: 1.1040 - val_accuracy: 0.5838 - val_loss: 1.1345\n",
            "Epoch 194/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5842 - loss: 1.1063 - val_accuracy: 0.5759 - val_loss: 1.1359\n",
            "Epoch 195/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5857 - loss: 1.0973 - val_accuracy: 0.5810 - val_loss: 1.1361\n",
            "Epoch 196/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5876 - loss: 1.0970 - val_accuracy: 0.5782 - val_loss: 1.1390\n",
            "Epoch 197/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5892 - loss: 1.1022 - val_accuracy: 0.5715 - val_loss: 1.1372\n",
            "Epoch 198/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5858 - loss: 1.1023 - val_accuracy: 0.5723 - val_loss: 1.1410\n",
            "Epoch 199/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5831 - loss: 1.0923 - val_accuracy: 0.5754 - val_loss: 1.1389\n",
            "Epoch 200/200\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5799 - loss: 1.1106 - val_accuracy: 0.5726 - val_loss: 1.1402\n"
          ]
        }
      ],
      "source": [
        "train = model2.fit(Xtrain, ytrain, \n",
        "                      epochs=200, \n",
        "                      batch_size=32, \n",
        "                      validation_data=(Xval, yval))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StvyZTCa2gB1"
      },
      "source": [
        "3. Utiliser ces réseaux pour faire la prédiction sur tous les exemples (apprentissage, validation, test) et rapporter les résultats (comme fait dans les TP1 à TP4) : (9%)<br>\n",
        "   3a. Rapport de classification produit avec *<font color=green>from sklearn.metrics import classification_report</font>*<br>\n",
        "   3b. taux de classification correct sur les trois (3) ensembles de données (sous la forme d'un tableau)<br>\n",
        "   3c. matrice de confusion produite avec *<font color=green> from sklearn.metrics import confusion_matrix</font>* pour les résultats sur l'ensemble de test (matrice 7 $\\times$ 7 - étiquéttes $\\times$ prédictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "a0X_B9tR58GC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step\n",
            "Classification Report for Model 1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.42      0.44       490\n",
            "           1       0.50      0.25      0.34        55\n",
            "           2       0.43      0.22      0.29       526\n",
            "           3       0.74      0.83      0.78       878\n",
            "           4       0.43      0.44      0.43       591\n",
            "           5       0.65      0.68      0.67       415\n",
            "           6       0.49      0.64      0.56       625\n",
            "\n",
            "    accuracy                           0.56      3580\n",
            "   macro avg       0.53      0.50      0.50      3580\n",
            "weighted avg       0.55      0.56      0.55      3580\n",
            "\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Classification Report for Model 2:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.46      0.46       490\n",
            "           1       0.50      0.40      0.44        55\n",
            "           2       0.49      0.25      0.33       526\n",
            "           3       0.70      0.85      0.77       878\n",
            "           4       0.44      0.43      0.44       591\n",
            "           5       0.69      0.67      0.68       415\n",
            "           6       0.51      0.61      0.56       625\n",
            "\n",
            "    accuracy                           0.57      3580\n",
            "   macro avg       0.54      0.53      0.53      3580\n",
            "weighted avg       0.56      0.57      0.56      3580\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Predictions for Model 1\n",
        "y_pred1 = model1.predict(Xtest).argmax(axis=1)\n",
        "print(\"Classification Report for Model 1:\")\n",
        "print(classification_report(ytest, y_pred1, target_names=[str(i) for i in range(7)]))\n",
        "\n",
        "# Predictions for Model 2\n",
        "y_pred2 = model2.predict(Xtest).argmax(axis=1)\n",
        "print(\"Classification Report for Model 2:\")\n",
        "print(classification_report(ytest, y_pred2, target_names=[str(i) for i in range(7)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Model  Train Accuracy  Validation Accuracy  Test Accuracy\n",
            "0  Model 1        0.619674             0.562535       0.561732\n",
            "1  Model 2        0.665178             0.572585       0.570391\n"
          ]
        }
      ],
      "source": [
        "# Calculate accuracy for Model 1\n",
        "train_acc1 = model1.evaluate(Xtrain, ytrain, verbose=0)[1]\n",
        "val_acc1 = model1.evaluate(Xval, yval, verbose=0)[1]\n",
        "test_acc1 = model1.evaluate(Xtest, ytest, verbose=0)[1]\n",
        "\n",
        "# Calculate accuracy for Model 2\n",
        "train_acc2 = model2.evaluate(Xtrain, ytrain, verbose=0)[1]\n",
        "val_acc2 = model2.evaluate(Xval, yval, verbose=0)[1]\n",
        "test_acc2 = model2.evaluate(Xtest, ytest, verbose=0)[1]\n",
        "\n",
        "# Print accuracies\n",
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Model': ['Model 1', 'Model 2'],\n",
        "    'Train Accuracy': [train_acc1, train_acc2],\n",
        "    'Validation Accuracy': [val_acc1, val_acc2],\n",
        "    'Test Accuracy': [test_acc1, test_acc2]\n",
        "}\n",
        "\n",
        "accuracy_df = pd.DataFrame(data)\n",
        "print(accuracy_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x500 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Confusion Matrix for Model 1\n",
        "conf_matrix1 = confusion_matrix(ytest, y_pred1)\n",
        "\n",
        "# Confusion Matrix for Model 2\n",
        "conf_matrix2 = confusion_matrix(ytest, y_pred2)\n",
        "\n",
        "# Plot confusion matrices\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "sns.heatmap(conf_matrix1, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
        "axes[0].set_title('Confusion Matrix for Model 1')\n",
        "axes[0].set_xlabel('Predicted')\n",
        "axes[0].set_ylabel('Actual')\n",
        "\n",
        "sns.heatmap(conf_matrix2, annot=True, fmt='d', cmap='Blues', ax=axes[1])\n",
        "axes[1].set_title('Confusion Matrix for Model 2')\n",
        "axes[1].set_xlabel('Predicted')\n",
        "axes[1].set_ylabel('Actual')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7vTSW4X5yon"
      },
      "source": [
        "4. Afficher vos résultats dans le tableau ci-dessous avec ceux des laboratoires précédents - primitives « deep » réduits (TP4), primitives « deep » (TP3), primitives globales/locales (TP2),  *template matching* (TP1) (5%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyPP7ZkzvWEq"
      },
      "source": [
        "Taux de classification:\n",
        "\n",
        "| Ensemble | modèle TM   |  AD+LBP Global  | AD+LBP Local  | modèle deep 1 | modèle deep 2 | modèle deep 1 $\\chi^2$ | modèle deep 1 PCA |                                   \n",
        "|----------|-------------|-----------------|---------------|---------------|---------------|---------------------------|-------------------|\n",
        "| App      | 99,67       |                 |               |               |               |                            |                   |                     \n",
        "| Val      | 89,77       |                 |               |               |               |                            |                   |                             \n",
        "| Test     | 77,99       |                 |               |               |               |                            |                   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENIvXp_RvWEp"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "5. Faire une analyse des résultats et présenter vos considérations et conclusions sur la pertinence / advantages / désavantages des réseaux neuronaux. (11%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY-HCB7K8U0-"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp9ckihBvWEq"
      },
      "source": [
        "# Fin"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
